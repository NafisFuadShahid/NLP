{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "a-YrFyW2cn_n",
        "outputId": "975995fc-b85b-4cb7-ea3c-364ae1e4508e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SERIAL</th>\n",
              "      <th>MESSAGE</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>re : 6 . 1100 , disc : uniformitarianism , re ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the other side of * galicismos * * galicismo *...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>re : equistar deal tickets are you still avail...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\\r\\nHello I am your hot lil horny toy.\\r\\n    ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>software at incredibly low prices ( 86 % lower...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SERIAL                                            MESSAGE  CATEGORY\n",
              "0       0  re : 6 . 1100 , disc : uniformitarianism , re ...         0\n",
              "1       1  the other side of * galicismos * * galicismo *...         0\n",
              "2       2  re : equistar deal tickets are you still avail...         0\n",
              "3       3  \\r\\nHello I am your hot lil horny toy.\\r\\n    ...         1\n",
              "4       4  software at incredibly low prices ( 86 % lower...         1"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the dataset (https://www.kaggle.com/chandramoulinaidu/spam-classification-for-basic-nlp)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Phishing_Email.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "5Brt9s9rkKYb",
        "outputId": "1b8fb1a7-af4c-4893-fead-eb71c0c887d7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SERIAL</th>\n",
              "      <th>MESSAGE</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18629</th>\n",
              "      <td>18646</td>\n",
              "      <td>date a lonely housewife always wanted to date ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18630</th>\n",
              "      <td>18647</td>\n",
              "      <td>request submitted : access request for anita ....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18631</th>\n",
              "      <td>18648</td>\n",
              "      <td>re : important - prc mtg hi dorn &amp; john , as y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18632</th>\n",
              "      <td>18649</td>\n",
              "      <td>press clippings - letter on californian utilit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18633</th>\n",
              "      <td>18650</td>\n",
              "      <td>empty</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       SERIAL                                            MESSAGE  CATEGORY\n",
              "18629   18646  date a lonely housewife always wanted to date ...         1\n",
              "18630   18647  request submitted : access request for anita ....         0\n",
              "18631   18648  re : important - prc mtg hi dorn & john , as y...         0\n",
              "18632   18649  press clippings - letter on californian utilit...         0\n",
              "18633   18650                                              empty         1"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BZJ1xgHkOOy",
        "outputId": "19b2cb60-3334-41d5-969c-6fb0fea4846f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CATEGORY\n",
              "0    11322\n",
              "1     7312\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['CATEGORY'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUoCyp8mkXsh",
        "outputId": "7bcfa229-8c68-46d0-f672-325c73c0b020"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\fuadn\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\fuadn\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWa64YhklKeT",
        "outputId": "9c407065-d1dd-46d7-d3e2-a0af97be6cfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hey',\n",
              " 'GGggGG',\n",
              " 'feet',\n",
              " 'it',\n",
              " 'going',\n",
              " 'HTML',\n",
              " 'bads',\n",
              " 'bads',\n",
              " 'randoms',\n",
              " 'badly']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "test_message = \"Hey,, GGggGG feet it going? <HTML><bads> bads 'randoms' badly\"\n",
        "\n",
        "test_message_tokenized = tokenizer.tokenize(test_message)\n",
        "test_message_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts46HslRmwlB",
        "outputId": "d48edd5e-a828-4374-bf86-7c9f4157da35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hey',\n",
              " 'gggggg',\n",
              " 'feet',\n",
              " 'it',\n",
              " 'going',\n",
              " 'html',\n",
              " 'bads',\n",
              " 'bads',\n",
              " 'randoms',\n",
              " 'badly']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_message_lowercased = [t.lower() for t in test_message_tokenized]\n",
        "test_message_lowercased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZfXmuvUn3dy",
        "outputId": "23a3a78a-c9d9-4c6d-d0ff-fa122304f23d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hey',\n",
              " 'gggggg',\n",
              " 'foot',\n",
              " 'it',\n",
              " 'going',\n",
              " 'html',\n",
              " 'bad',\n",
              " 'bad',\n",
              " 'randoms',\n",
              " 'badly']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "test_message_lemmatized_tokens = [lemmatizer.lemmatize(t) for t in test_message_lowercased]\n",
        "test_message_lemmatized_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG06k4ags0al",
        "outputId": "1fab4508-e4ad-4be7-b32d-cbb2983c02df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hey', 'gggggg', 'foot', 'going', 'html', 'bad', 'bad', 'randoms', 'badly']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "test_message_useful_tokens = [t for t in test_message_lemmatized_tokens if t not in stopwords]\n",
        "test_message_useful_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtNehJ51t6Ii",
        "outputId": "8dac74a6-f061-4fc9-a0ad-22bdf637af02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hey', 'gggggg', 'foot', 'going', 'html', 'bad', 'bad', 'randoms', 'badly']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def message_to_token_list(s):\n",
        "  tokens = tokenizer.tokenize(s)\n",
        "  lowercased_tokens = [t.lower() for t in tokens]\n",
        "  lemmatized_tokens = [lemmatizer.lemmatize(t) for t in lowercased_tokens]\n",
        "  useful_tokens = [t for t in lemmatized_tokens if t not in stopwords]\n",
        "\n",
        "  return useful_tokens\n",
        "\n",
        "message_to_token_list(test_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_InW_NurvEqq",
        "outputId": "5510f999-7e20-4d6d-8b2b-02970916b041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (14907, 3)\n",
            "Test shape: (3727, 3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(       SERIAL                                            MESSAGE  CATEGORY\n",
              " 0         128  blue horseshoe meet me dear reader : we someti...         1\n",
              " 1        4205  the national association for honesty in medici...         1\n",
              " 2        7943  web pages load 300 % faster without cable or d...         1\n",
              " 3       15029  reimbursement of individually billed items the...         0\n",
              " 4         609  lp deal bill - please come see me this morning...         0\n",
              " ...       ...                                                ...       ...\n",
              " 14902    1175  200 summary on reduplication a month before ch...         0\n",
              " 14903   11581  \\r\\nYannick Gingras wrote:>    I am wondering ...         0\n",
              " 14904   13132  URL: http://www.newsisfree.com/click/215,9,215...         0\n",
              " 14905    3430  global operations controller forum i believe n...         0\n",
              " 14906   11247  electronic pay stubs get ready . beginning in ...         0\n",
              " \n",
              " [14907 rows x 3 columns],\n",
              "       SERIAL                                            MESSAGE  CATEGORY\n",
              " 0       6208  super saturday info sally , i received your vo...         0\n",
              " 1       2817  it ' s cheating , but it works ! can you guess...         1\n",
              " 2        485  t id ( aa29536 @ julius . ling . ohio-state . ...         0\n",
              " 3       2352  global risk management operations recognizing ...         0\n",
              " 4      17190  expert web site analysis - at no charge do you...         1\n",
              " ...      ...                                                ...       ...\n",
              " 3722    3805  schedule going real time for june 1 this sched...         0\n",
              " 3723    9880  bi - weekly transmission update report energy ...         0\n",
              " 3724   10777  \\r\\nWant To Be Your Own Boss? Â  Train Now Wit...         1\n",
              " 3725   12862  activities 1 . receivables backed finance : ti...         0\n",
              " 3726   11058  H1 { } TD {  FONT-SIZE: 12px; FONT-FAMILY: Ari...         1\n",
              " \n",
              " [3727 rows x 3 columns])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,         # 20% of data will go to the test set\n",
        "    stratify=df['CATEGORY'], # Ensures proportional class distribution\n",
        "    random_state=1         # Ensures reproducibility\n",
        ")\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "print(f\"Test shape: {test_df.shape}\")\n",
        "\n",
        "train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwUuMr_0waAu",
        "outputId": "14ab0468-fdff-455f-e6a0-aebbcb7102a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "144709"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "token_counter = {}\n",
        "\n",
        "# Iterate over each message in the 'MESSAGE' column\n",
        "for message in train_df['MESSAGE']:\n",
        "    if isinstance(message, str):  # Check if message is a string\n",
        "        message_as_token_lst = message_to_token_list(message)  # Convert message to a list of tokens\n",
        "\n",
        "        # Count occurrences of each token\n",
        "        for token in message_as_token_lst:\n",
        "            if token in token_counter:\n",
        "                token_counter[token] += 1\n",
        "            else:\n",
        "                token_counter[token] = 1\n",
        "\n",
        "len(token_counter)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubi91FlbyfXJ",
        "outputId": "1ed3962a-61fd-4b1f-fd80-b3a7322438b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'blue': 228,\n",
              " 'horseshoe': 3,\n",
              " 'meet': 897,\n",
              " 'dear': 1137,\n",
              " 'reader': 878,\n",
              " 'sometimes': 434,\n",
              " 'approach': 2218,\n",
              " 'analyst': 1128,\n",
              " 'thought': 1316,\n",
              " 'emerging': 216,\n",
              " 'market': 3782,\n",
              " 'sector': 275,\n",
              " 'interested': 2324,\n",
              " 'certain': 1138,\n",
              " 'occasion': 159,\n",
              " 'come': 3012,\n",
              " 'u': 13191,\n",
              " 'intriguing': 49,\n",
              " 'insight': 264,\n",
              " 'aspect': 1778,\n",
              " 'caught': 105,\n",
              " 'attention': 853,\n",
              " 'know': 6021,\n",
              " 'track': 776,\n",
              " 'record': 1079,\n",
              " 'speaks': 80,\n",
              " 'happy': 751,\n",
              " 'bring': 907,\n",
              " 'another': 2189,\n",
              " 'situation': 893,\n",
              " 'huge': 608,\n",
              " 'upside': 52,\n",
              " 'potential': 1175,\n",
              " 'think': 3385,\n",
              " 'could': 5083,\n",
              " 'one': 14148,\n",
              " 'look': 2802,\n",
              " 'back': 3019,\n",
              " 'shortly': 175,\n",
              " 'everyone': 1038,\n",
              " 'saying': 530,\n",
              " 'info': 1714,\n",
              " 'click': 3821,\n",
              " 'remember': 1191,\n",
              " 'nothing': 1158,\n",
              " 'ventured': 7,\n",
              " 'gained': 144,\n",
              " 'national': 1589,\n",
              " 'association': 1114,\n",
              " 'honesty': 56,\n",
              " 'medicine': 191,\n",
              " 'stemcaoiwz': 1,\n",
              " 'body': 833,\n",
              " 'many': 4857,\n",
              " 'cry': 65,\n",
              " 'water': 445,\n",
              " 'dr': 1865,\n",
              " 'f': 2039,\n",
              " 'batmanghelidj': 2,\n",
              " 'title': 2118,\n",
              " 'multi': 1165,\n",
              " 'book': 4659,\n",
              " 'say': 3315,\n",
              " 'found': 1960,\n",
              " 'bookstore': 46,\n",
              " 'amazon': 83,\n",
              " 'com': 18232,\n",
              " 'view': 1683,\n",
              " 'expose': 63,\n",
              " 'scheming': 1,\n",
              " 'tactic': 49,\n",
              " 'government': 1680,\n",
              " 'pharmaceutical': 109,\n",
              " 'industry': 1308,\n",
              " 'keep': 1737,\n",
              " 'human': 1763,\n",
              " 'sick': 99,\n",
              " 'care': 621,\n",
              " 'system': 7288,\n",
              " 'perpetuate': 7,\n",
              " 'disease': 154,\n",
              " 'state': 5219,\n",
              " 'bodily': 10,\n",
              " 'condition': 791,\n",
              " 'effort': 1198,\n",
              " 'fund': 1343,\n",
              " 'mega': 98,\n",
              " 'sucked': 14,\n",
              " 'discover': 400,\n",
              " 'natural': 2475,\n",
              " 'substance': 101,\n",
              " 'make': 7313,\n",
              " 'phenomenal': 21,\n",
              " 'difference': 1008,\n",
              " 'health': 553,\n",
              " 'well': 4755,\n",
              " 'read': 2498,\n",
              " 'isbn': 506,\n",
              " '0': 12003,\n",
              " '9629942': 1,\n",
              " '3': 11956,\n",
              " '5': 9922,\n",
              " 'written': 1155,\n",
              " 'sincerely': 551,\n",
              " 'preceding': 133,\n",
              " 'advertisement': 719,\n",
              " 'wa': 13521,\n",
              " 'sent': 4191,\n",
              " 'virtue': 69,\n",
              " 'participation': 759,\n",
              " 'special': 3098,\n",
              " 'product': 3858,\n",
              " 'offering': 563,\n",
              " 'e': 17378,\n",
              " 'mail': 13109,\n",
              " 'networking': 175,\n",
              " 'service': 5287,\n",
              " 'partner': 934,\n",
              " 'unsubscribe': 1015,\n",
              " 'receiving': 846,\n",
              " 'email': 10715,\n",
              " 'please': 11884,\n",
              " 'web': 4624,\n",
              " 'page': 4264,\n",
              " 'load': 489,\n",
              " '300': 694,\n",
              " 'faster': 390,\n",
              " 'without': 2431,\n",
              " 'cable': 383,\n",
              " 'dsl': 73,\n",
              " 'named': 293,\n",
              " 'online': 2234,\n",
              " 'software': 3955,\n",
              " 'year': 7006,\n",
              " 'agi': 14,\n",
              " 'consultant': 194,\n",
              " 'free': 7127,\n",
              " '7': 4990,\n",
              " 'day': 6894,\n",
              " 'trial': 301,\n",
              " 'unique': 541,\n",
              " 'solution': 921,\n",
              " 'open': 1649,\n",
              " 'private': 915,\n",
              " 'high': 2230,\n",
              " 'speed': 543,\n",
              " 'network': 1671,\n",
              " 'connection': 753,\n",
              " 'required': 1567,\n",
              " 'amazed': 71,\n",
              " 'internet': 3973,\n",
              " 'provider': 507,\n",
              " 'perfect': 517,\n",
              " 'pc': 958,\n",
              " 'laptop': 159,\n",
              " 'dial': 260,\n",
              " 'modem': 200,\n",
              " 'testimonial': 147,\n",
              " '1': 19940,\n",
              " 'min': 278,\n",
              " 'download': 951,\n",
              " 'learn': 1095,\n",
              " 'get': 9118,\n",
              " 'permanently': 82,\n",
              " 'going': 2018,\n",
              " 'sign': 1263,\n",
              " 'want': 4530,\n",
              " '50': 4178,\n",
              " 'per': 2802,\n",
              " 'month': 3178,\n",
              " 'plus': 1465,\n",
              " 'pay': 1858,\n",
              " '120': 364,\n",
              " 'thecable': 1,\n",
              " 'paya': 1,\n",
              " 'guy': 704,\n",
              " 'hook': 77,\n",
              " 'rule': 1585,\n",
              " 'roger': 237,\n",
              " 'fromteaneck': 1,\n",
              " 'nj': 223,\n",
              " 'nice': 618,\n",
              " 'job': 1637,\n",
              " 'file': 3545,\n",
              " 'size': 1615,\n",
              " 'small': 1359,\n",
              " 'quick': 607,\n",
              " 'see': 5160,\n",
              " 'noticeable': 13,\n",
              " 'improvement': 384,\n",
              " 'access': 1939,\n",
              " 'recommending': 32,\n",
              " 'client': 784,\n",
              " 'computer': 3790,\n",
              " 'easy': 1874,\n",
              " 'use': 6902,\n",
              " 'raj': 22,\n",
              " 'patel': 36,\n",
              " 'address': 10179,\n",
              " 'obtained': 298,\n",
              " 'purchased': 253,\n",
              " 'list': 11541,\n",
              " 'reference': 2701,\n",
              " '172': 71,\n",
              " '54': 399,\n",
              " 'wish': 1781,\n",
              " 'request': 2255,\n",
              " 'honored': 60,\n",
              " 'http': 18867,\n",
              " 'xent': 659,\n",
              " 'mailman': 1637,\n",
              " 'listinfo': 2121,\n",
              " 'fork': 867,\n",
              " 'reimbursement': 30,\n",
              " 'individually': 88,\n",
              " 'billed': 42,\n",
              " 'item': 1058,\n",
              " 'memo': 131,\n",
              " 'distributed': 454,\n",
              " 'june': 1870,\n",
              " '27': 1771,\n",
              " 'requires': 438,\n",
              " 'clarification': 84,\n",
              " 'intent': 183,\n",
              " 'give': 2779,\n",
              " 'employee': 920,\n",
              " 'alternate': 152,\n",
              " 'method': 2142,\n",
              " 'paying': 354,\n",
              " 'pager': 42,\n",
              " 'cell': 486,\n",
              " 'phone': 3607,\n",
              " 'etc': 2812,\n",
              " 'continue': 1178,\n",
              " 'submit': 1367,\n",
              " 'invoice': 189,\n",
              " 'account': 2907,\n",
              " 'payable': 405,\n",
              " 'processing': 1831,\n",
              " 'corporate': 673,\n",
              " 'american': 2325,\n",
              " 'express': 697,\n",
              " 'card': 2425,\n",
              " 'expense': 577,\n",
              " 'report': 7879,\n",
              " 'either': 1795,\n",
              " 'way': 5024,\n",
              " 'acceptable': 293,\n",
              " 'process': 2674,\n",
              " 'dollar': 1789,\n",
              " 'volume': 2258,\n",
              " 'lp': 108,\n",
              " 'deal': 3377,\n",
              " 'bill': 1485,\n",
              " 'morning': 842,\n",
              " 'comment': 1609,\n",
              " 'suggestion': 533,\n",
              " 'end': 2345,\n",
              " 'thing': 2757,\n",
              " 'finish': 124,\n",
              " 'today': 3029,\n",
              " 'need': 5830,\n",
              " 'desk': 439,\n",
              " 'virginia': 263,\n",
              " 'hotlist': 20,\n",
              " 'update': 1291,\n",
              " '01': 3288,\n",
              " 'forgot': 83,\n",
              " 'attachment': 270,\n",
              " 'brillant': 1,\n",
              " 'original': 2516,\n",
              " 'message': 6044,\n",
              " 'mrha': 58,\n",
              " 'jean': 496,\n",
              " 'tuesday': 1041,\n",
              " 'may': 8950,\n",
              " '2001': 4414,\n",
              " '2': 14943,\n",
              " '29': 1671,\n",
              " 'pm': 2994,\n",
              " 'kitchen': 547,\n",
              " 'louise': 929,\n",
              " 'cc': 2837,\n",
              " 'jones': 1256,\n",
              " 'melissa': 151,\n",
              " 'schoppe': 71,\n",
              " 'tammie': 86,\n",
              " 'carter': 76,\n",
              " 'carol': 182,\n",
              " 'washington': 914,\n",
              " 'deanna': 12,\n",
              " 'subject': 11549,\n",
              " 'find': 3508,\n",
              " 'attached': 1174,\n",
              " 'revised': 366,\n",
              " 'upstream': 44,\n",
              " 'bridgeline': 43,\n",
              " 'augment': 17,\n",
              " 'transaction': 1535,\n",
              " 'sheet': 683,\n",
              " 'associated': 567,\n",
              " 'brian': 533,\n",
              " 'currently': 1262,\n",
              " 'meeting': 2440,\n",
              " 'next': 2809,\n",
              " 'week': 4608,\n",
              " 'version': 2223,\n",
              " 'include': 3278,\n",
              " 'strategy': 873,\n",
              " 'lrc': 7,\n",
              " 'crawfish': 5,\n",
              " 'asset': 1178,\n",
              " 'balance': 490,\n",
              " 'addition': 983,\n",
              " 'storage': 439,\n",
              " 'doe': 4145,\n",
              " 'monetization': 9,\n",
              " 'opportunity': 2397,\n",
              " 'utility': 737,\n",
              " 'pad': 32,\n",
              " 'gas': 2985,\n",
              " 'targeting': 66,\n",
              " 'jim': 481,\n",
              " 'steffes': 57,\n",
              " 'tomorrow': 428,\n",
              " 'paul': 1072,\n",
              " 'present': 1843,\n",
              " 'thursday': 1150,\n",
              " 'regard': 1549,\n",
              " 'credit': 3455,\n",
              " 'good': 3266,\n",
              " 'hey': 198,\n",
              " 'bruce': 306,\n",
              " 'guenter': 42,\n",
              " 'dyndns': 42,\n",
              " 'org': 2646,\n",
              " 'chosen': 190,\n",
              " 'participate': 839,\n",
              " 'invitation': 234,\n",
              " 'event': 2021,\n",
              " 'mortgage': 448,\n",
              " 'stop': 1412,\n",
              " 'help': 3285,\n",
              " 'lower': 510,\n",
              " 'answer': 1359,\n",
              " 'question': 4765,\n",
              " 'approved': 574,\n",
              " 'minute': 2307,\n",
              " 'simple': 1382,\n",
              " 'aynhgh': 2,\n",
              " '332': 28,\n",
              " '000': 7672,\n",
              " 'loan': 841,\n",
              " 'available': 4627,\n",
              " '238': 40,\n",
              " 'bad': 674,\n",
              " 'problem': 3509,\n",
              " 'saving': 530,\n",
              " 'money': 5661,\n",
              " 'time': 10521,\n",
              " 'ready': 1227,\n",
              " 'save': 1784,\n",
              " 'fill': 700,\n",
              " 'short': 1520,\n",
              " 'form': 4929,\n",
              " 'later': 1361,\n",
              " 'mayer': 41,\n",
              " 'r': 4328,\n",
              " 'tim': 424,\n",
              " 'vi': 290,\n",
              " 'mertensbreachye': 1,\n",
              " 'uymail': 2,\n",
              " 'twenty': 366,\n",
              " 'disappointed': 59,\n",
              " 'throw': 128,\n",
              " 'bowline': 7,\n",
              " 'sail': 31,\n",
              " 'away': 1042,\n",
              " 'safe': 430,\n",
              " 'harbor': 87,\n",
              " 'catch': 228,\n",
              " 'trade': 1390,\n",
              " 'wind': 248,\n",
              " 'explore': 247,\n",
              " 'dream': 460,\n",
              " 'mark': 1758,\n",
              " 'twain': 13,\n",
              " 'samuel': 111,\n",
              " 'langhornne': 5,\n",
              " 'clemens': 18,\n",
              " '1835': 14,\n",
              " '1910': 22,\n",
              " 'hear': 704,\n",
              " 'language': 22196,\n",
              " 'asked': 1145,\n",
              " 'every': 2711,\n",
              " 'pointing': 63,\n",
              " 'allowed': 307,\n",
              " 'spend': 328,\n",
              " 'noun': 849,\n",
              " 'program': 7353,\n",
              " 'talking': 619,\n",
              " 'full': 2563,\n",
              " 'sentence': 1254,\n",
              " 'staffed': 12,\n",
              " 'normal': 690,\n",
              " 'preschool': 16,\n",
              " 'missing': 253,\n",
              " 'surfing': 38,\n",
              " 'life': 2292,\n",
              " 'happiness': 93,\n",
              " 'success': 1173,\n",
              " 'able': 1693,\n",
              " 'others': 1622,\n",
              " 'absurd': 22,\n",
              " 'maddening': 3,\n",
              " 'claim': 1471,\n",
              " 'upon': 958,\n",
              " 'christopher': 255,\n",
              " 'darlington': 2,\n",
              " 'morley': 15,\n",
              " '1890': 34,\n",
              " '1957': 44,\n",
              " 'enjoying': 67,\n",
              " 'skiing': 8,\n",
              " 'among': 1089,\n",
              " 'tree': 428,\n",
              " 'moment': 530,\n",
              " 'picked': 112,\n",
              " 'patch': 177,\n",
              " 'cv': 350,\n",
              " 'eventually': 199,\n",
              " 'bug': 259,\n",
              " 'worth': 703,\n",
              " 'fixing': 33,\n",
              " 'let': 3139,\n",
              " 'fix': 217,\n",
              " 'scarborough': 6,\n",
              " 'said': 4821,\n",
              " 'tg': 14,\n",
              " 'sema': 7,\n",
              " 'se': 731,\n",
              " 'mscar': 1,\n",
              " 'biggest': 339,\n",
              " '_always_': 2,\n",
              " 'render': 53,\n",
              " 'html': 3400,\n",
              " 'possible': 2558,\n",
              " 'porno': 38,\n",
              " 'also': 8917,\n",
              " 'option': 1407,\n",
              " 'part': 3481,\n",
              " 'netscape': 218,\n",
              " 'might': 2294,\n",
              " 'fully': 618,\n",
              " 'featured': 350,\n",
              " 'viewer': 63,\n",
              " 'determine': 327,\n",
              " 'risk': 2455,\n",
              " 'try': 1509,\n",
              " 'two': 5624,\n",
              " 'exmh': 664,\n",
              " '07': 1002,\n",
              " '13': 2336,\n",
              " 'tossed': 15,\n",
              " 'together': 1370,\n",
              " 'config': 84,\n",
              " 'uri': 21,\n",
              " 'deferdisplaysinline': 1,\n",
              " 'probably': 1080,\n",
              " 'sense': 940,\n",
              " 'always': 1668,\n",
              " 'never': 1842,\n",
              " 'people': 7435,\n",
              " 'like': 7943,\n",
              " 'anyway': 369,\n",
              " 'text': 4044,\n",
              " 'defer': 13,\n",
              " 'selected': 743,\n",
              " 'display': 343,\n",
              " 'inline': 32,\n",
              " 'checking': 323,\n",
              " 'box': 1901,\n",
              " 'right': 4054,\n",
              " 'button': 339,\n",
              " 'menu': 167,\n",
              " 'tomas': 29,\n",
              " 'g': 3513,\n",
              " 'great': 2179,\n",
              " 'thank': 1907,\n",
              " 'exactly': 781,\n",
              " 'thinking': 495,\n",
              " 'best': 3590,\n",
              " 'whether': 1640,\n",
              " 'expressed': 332,\n",
              " 'couple': 573,\n",
              " 'coloring': 7,\n",
              " 'highlighting': 43,\n",
              " 'characterize': 39,\n",
              " 'yet': 1267,\n",
              " 'work': 7823,\n",
              " 'least': 2079,\n",
              " 'functionality': 106,\n",
              " 'ever': 1642,\n",
              " 'wanted': 730,\n",
              " 'choose': 718,\n",
              " 'internal': 507,\n",
              " 'engine': 639,\n",
              " 'whatever': 505,\n",
              " 'external': 280,\n",
              " 'browser': 352,\n",
              " 'defined': 271,\n",
              " 'basis': 1102,\n",
              " 'thanks': 3470,\n",
              " '_______________________________________________': 882,\n",
              " 'user': 3795,\n",
              " 'mailing': 3622,\n",
              " 'redhat': 568,\n",
              " 'listman': 138,\n",
              " 'brent': 143,\n",
              " 'welch': 56,\n",
              " 'architect': 81,\n",
              " 'panasas': 54,\n",
              " 'inc': 2824,\n",
              " 'pioneering': 37,\n",
              " 'world': 4141,\n",
              " 'scalable': 48,\n",
              " 'agile': 24,\n",
              " 'www': 11773,\n",
              " 'plan': 2258,\n",
              " 'b': 3762,\n",
              " 'smith': 667,\n",
              " 'approval': 547,\n",
              " 'go': 3818,\n",
              " 'would': 10902,\n",
              " 'extend': 235,\n",
              " 'offer': 3618,\n",
              " 'gary': 512,\n",
              " 'move': 1418,\n",
              " 'supported': 244,\n",
              " 'tom': 463,\n",
              " 'martin': 723,\n",
              " 'vickers': 35,\n",
              " 'tycholiz': 25,\n",
              " 'chi': 50,\n",
              " 'objection': 50,\n",
              " 'ryanair': 39,\n",
              " 'partnership': 944,\n",
              " 'primary': 455,\n",
              " 'insurance': 508,\n",
              " 'excellent': 386,\n",
              " 'value': 1617,\n",
              " 'travel': 883,\n",
              " 'â': 10890,\n",
              " '00gbp': 4,\n",
              " '9': 5701,\n",
              " '00': 12633,\n",
              " 'euro': 273,\n",
              " 'person': 1931,\n",
              " '31': 2088,\n",
              " 'cover': 1014,\n",
              " 'annual': 806,\n",
              " '45': 2121,\n",
              " '63': 209,\n",
              " 'includes': 1164,\n",
              " '24': 2159,\n",
              " 'winter': 247,\n",
              " 'sport': 278,\n",
              " 'provides': 770,\n",
              " 'standard': 1610,\n",
              " 'summary': 1437,\n",
              " 'medical': 433,\n",
              " 'million': 3660,\n",
              " 'personal': 1340,\n",
              " 'liability': 166,\n",
              " 'effect': 1235,\n",
              " 'baggage': 16,\n",
              " '750': 187,\n",
              " 'accident': 75,\n",
              " 'maximum': 389,\n",
              " 'benefit': 940,\n",
              " '15': 5930,\n",
              " 'hospital': 169,\n",
              " 'cancellation': 115,\n",
              " '500': 1492,\n",
              " 'curtailment': 29,\n",
              " 'delay': 334,\n",
              " '60': 1199,\n",
              " 'missed': 159,\n",
              " 'departure': 153,\n",
              " 'legal': 1352,\n",
              " '5000': 198,\n",
              " 'holiday': 355,\n",
              " 'abandonment': 11,\n",
              " '500all': 1,\n",
              " 'figure': 610,\n",
              " 'sterling': 249,\n",
              " 'poundsto': 1,\n",
              " 'policy': 965,\n",
              " 'primarytrade': 1,\n",
              " 'co': 2158,\n",
              " 'uk': 3997,\n",
              " 'internetsales': 1,\n",
              " 'call': 5936,\n",
              " 'direct': 1138,\n",
              " 'reservation': 376,\n",
              " '0871': 4,\n",
              " '246': 56,\n",
              " '0002': 4,\n",
              " '0818': 3,\n",
              " '304': 54,\n",
              " 'ireland': 213,\n",
              " 'rate': 2493,\n",
              " 'ongolf': 1,\n",
              " '19': 2472,\n",
              " 'passenger': 47,\n",
              " 'coverski': 1,\n",
              " '35': 1203,\n",
              " 'covercover': 1,\n",
              " 'habitual': 18,\n",
              " 'resident': 210,\n",
              " 'disclaimerthis': 5,\n",
              " 'transmitted': 66,\n",
              " 'confidential': 435,\n",
              " 'legally': 158,\n",
              " 'privileged': 103,\n",
              " 'intended': 830,\n",
              " 'solely': 116,\n",
              " 'recipient': 366,\n",
              " 'opinion': 667,\n",
              " 'individual': 1669,\n",
              " 'author': 2947,\n",
              " 'sender': 376,\n",
              " 'necessarily': 188,\n",
              " 'shared': 350,\n",
              " 'endorsed': 37,\n",
              " 'holding': 400,\n",
              " 'plc': 120,\n",
              " 'related': 2084,\n",
              " 'company': 9669,\n",
              " 'particular': 1329,\n",
              " 'transmission': 419,\n",
              " 'binding': 315,\n",
              " 'purpose': 855,\n",
              " 'forming': 69,\n",
              " 'contract': 1505,\n",
              " 'sell': 1272,\n",
              " 'airline': 159,\n",
              " 'seat': 93,\n",
              " 'directly': 975,\n",
              " 'via': 1966,\n",
              " 'promotion': 585,\n",
              " 'contractual': 59,\n",
              " 'obligation': 437,\n",
              " 'type': 2753,\n",
              " 'formed': 153,\n",
              " 'writing': 1166,\n",
              " 'post': 1449,\n",
              " 'fax': 5714,\n",
              " 'duly': 12,\n",
              " 'signed': 515,\n",
              " 'senior': 511,\n",
              " 'executive': 961,\n",
              " 'board': 1021,\n",
              " 'director': 1197,\n",
              " 'content': 2351,\n",
              " 'changed': 412,\n",
              " 'altered': 31,\n",
              " 'consent': 92,\n",
              " 'hereby': 67,\n",
              " 'notified': 260,\n",
              " 'review': 2341,\n",
              " 'dissemination': 75,\n",
              " 'disclosure': 259,\n",
              " 'alteration': 26,\n",
              " 'printing': 206,\n",
              " 'circulation': 85,\n",
              " 'action': 1476,\n",
              " 'taken': 780,\n",
              " 'omitted': 48,\n",
              " 'reliance': 99,\n",
              " 'prohibited': 128,\n",
              " 'unlawful': 21,\n",
              " 'received': 2953,\n",
              " 'error': 1460,\n",
              " 'notify': 140,\n",
              " 'emailing': 129,\n",
              " 'postmaster': 57,\n",
              " 'ie': 2425,\n",
              " 'contact': 4424,\n",
              " 'dublin': 186,\n",
              " 'airport': 322,\n",
              " 'subscribed': 215,\n",
              " 'customer': 2008,\n",
              " 'zzz': 1,\n",
              " 'spamassassin': 1579,\n",
              " 'taint': 266,\n",
              " 'send': 6097,\n",
              " 'blank': 252,\n",
              " 'leave': 668,\n",
              " '949326k': 3,\n",
              " 'ryanairmail': 3,\n",
              " 'lot': 1801,\n",
              " 'ahamed': 2,\n",
              " 'remove': 2007,\n",
              " 'mongoose': 1,\n",
              " 'jobholdergolden': 1,\n",
              " 'churn': 11,\n",
              " 'clubroomcascara': 1,\n",
              " 'chat': 265,\n",
              " 'scrupulousmarksman': 1,\n",
              " 'granola': 1,\n",
              " 'mildblimp': 1,\n",
              " 'chinatown': 9,\n",
              " 'cummingsfortiori': 1,\n",
              " 'keyhole': 2,\n",
              " 'brainardchevalier': 1,\n",
              " 'screechy': 5,\n",
              " 'warym': 1,\n",
              " 'respiratory': 6,\n",
              " 'vishnuclark': 1,\n",
              " 'crash': 168,\n",
              " 'gallantstatler': 1,\n",
              " 'swede': 8,\n",
              " 'moribundpuddly': 1,\n",
              " 'hoofmark': 1,\n",
              " 'threadbreed': 1,\n",
              " 'shrift': 4,\n",
              " 'greeneryalcohol': 1,\n",
              " 'anderson': 240,\n",
              " 'cherokeedillon': 1,\n",
              " 'discriminatory': 22,\n",
              " 'methanolcirculant': 1,\n",
              " 'alvarez': 82,\n",
              " 'duskshrew': 1,\n",
              " 'solecism': 1,\n",
              " 'twitchtan': 1,\n",
              " 'dexter': 14,\n",
              " 'exhalesaul': 1,\n",
              " 'depositorpusan': 1,\n",
              " 'accipiter': 3,\n",
              " 'elinorbrew': 1,\n",
              " 'mortician': 3,\n",
              " 'begottendrip': 1,\n",
              " 'hostess': 10,\n",
              " 'rallytopologize': 1,\n",
              " 'superposable': 3,\n",
              " 'miraculousclimate': 1,\n",
              " 'croon': 2,\n",
              " 'efficaciousrise': 1,\n",
              " 'filial': 2,\n",
              " 'muriatic': 2,\n",
              " 'tylernarcissus': 1,\n",
              " 'urethane': 3,\n",
              " 'pollardeasygoing': 1,\n",
              " 'pipsissewa': 3,\n",
              " 'cafeteriaavuncular': 1,\n",
              " 'disco': 14,\n",
              " 'holdenbiddy': 1,\n",
              " 'evil': 104,\n",
              " 'catastropheinquest': 1,\n",
              " 'nectareous': 2,\n",
              " 'swindlebestial': 1,\n",
              " 'anhydrite': 7,\n",
              " 'scarfgiveth': 1,\n",
              " 'bema': 4,\n",
              " 'herebysuit': 1,\n",
              " 'portulacashouldn': 1,\n",
              " 'axiology': 5,\n",
              " 'canneldisgruntle': 1,\n",
              " 'flatiron': 12,\n",
              " 'employlifestyle': 1,\n",
              " 'data': 3998,\n",
              " 'heredada': 1,\n",
              " 'larkspur': 3,\n",
              " 'cobaltinflexible': 1,\n",
              " 'write': 1279,\n",
              " 'mind': 1124,\n",
              " 'awful': 34,\n",
              " 'oh': 362,\n",
              " 'interesting': 877,\n",
              " 'yes': 1263,\n",
              " 'starlet': 5,\n",
              " 'behind': 330,\n",
              " 'bike': 22,\n",
              " 'wearing': 26,\n",
              " 'pretty': 489,\n",
              " 'innerestin': 1,\n",
              " 'modesty': 4,\n",
              " 'photo': 325,\n",
              " 'public': 1137,\n",
              " 'consumption': 61,\n",
              " 'felhelen': 1,\n",
              " 'troy': 47,\n",
              " 'yahoo': 1104,\n",
              " 'group': 4507,\n",
              " 'sponsor': 377,\n",
              " 'home': 3548,\n",
              " 'top': 1640,\n",
              " 'rrpzmc': 4,\n",
              " 'jtmeaa': 4,\n",
              " 'mvfiaa': 62,\n",
              " '7gsolb': 76,\n",
              " 'tm': 625,\n",
              " 'forteana': 131,\n",
              " 'egroups': 115,\n",
              " 'doc': 557,\n",
              " 'term': 3424,\n",
              " 'url': 1486,\n",
              " 'newsisfree': 287,\n",
              " '8015193': 1,\n",
              " '1440': 66,\n",
              " 'date': 4024,\n",
              " 'supplieda': 15,\n",
              " 'new': 11513,\n",
              " 'analysis': 3040,\n",
              " 'satellite': 211,\n",
              " 'image': 906,\n",
              " 'show': 2017,\n",
              " 'regeneration': 2,\n",
              " 'arid': 6,\n",
              " 'land': 280,\n",
              " 'across': 828,\n",
              " 'southern': 550,\n",
              " 'sahara': 7,\n",
              " 'making': 1845,\n",
              " 'farming': 10,\n",
              " 'viable': 45,\n",
              " 'boingboing': 92,\n",
              " 'net': 6084,\n",
              " '85528531': 1,\n",
              " 'supplied': 166,\n",
              " 'img': 109,\n",
              " 'craphound': 13,\n",
              " 'actlab': 3,\n",
              " 'jpg': 84,\n",
              " 'jon': 109,\n",
              " 'lebkowsky': 2,\n",
              " 'ha': 13111,\n",
              " 'posted': 772,\n",
              " 'little': 1873,\n",
              " 'gallery': 79,\n",
              " 'picture': 643,\n",
              " 'eff': 255,\n",
              " 'austin': 408,\n",
              " 'talk': 2100,\n",
              " 'university': 16258,\n",
              " 'texas': 1217,\n",
              " 'shot': 181,\n",
              " 'kick': 69,\n",
              " 'bbq': 11,\n",
              " 'ate': 71,\n",
              " 'beforehand': 15,\n",
              " 'note': 2865,\n",
              " 'atkins': 14,\n",
              " 'compliant': 49,\n",
              " 'lunch': 1129,\n",
              " 'fantastic': 134,\n",
              " 'organizer': 646,\n",
              " 'especially': 1032,\n",
              " 'putting': 283,\n",
              " 'meeet': 1,\n",
              " 'boing': 87,\n",
              " 'came': 774,\n",
              " 'link': 2970,\n",
              " 'discus': 984,\n",
              " '_thanks': 45,\n",
              " 'john': 3418,\n",
              " '_': 218970,\n",
              " 'cory': 8,\n",
              " 'quicktopic': 88,\n",
              " 'h': 2226,\n",
              " 'gkmgdxswsp7': 1,\n",
              " 'weblogsky': 2,\n",
              " 'forwarded': 1055,\n",
              " 'mon': 368,\n",
              " '23': 1643,\n",
              " 'sep': 385,\n",
              " '2002': 3507,\n",
              " '09': 1710,\n",
              " '52': 433,\n",
              " '44': 1166,\n",
              " '0700': 116,\n",
              " 'mi': 352,\n",
              " 'seiden': 3,\n",
              " 'scoot': 1,\n",
              " 'bos': 215,\n",
              " 'wife': 478,\n",
              " 'order': 8303,\n",
              " 'hit': 697,\n",
              " 'independent': 673,\n",
              " 'shopper': 51,\n",
              " 'newspaper': 255,\n",
              " 'sf': 988,\n",
              " 'bay': 143,\n",
              " 'area': 3127,\n",
              " 'operational': 209,\n",
              " 'definition': 341,\n",
              " 'medium': 1253,\n",
              " 'category': 1326,\n",
              " 'matter': 1293,\n",
              " 'hard': 1562,\n",
              " 'delivering': 66,\n",
              " 'story': 1050,\n",
              " 'aug': 565,\n",
              " 'dot': 117,\n",
              " 'downturn': 21,\n",
              " 'linked': 203,\n",
              " 'domestic': 218,\n",
              " 'violence': 100,\n",
              " 'worker': 313,\n",
              " 'kathy': 75,\n",
              " 'black': 536,\n",
              " 'remembers': 23,\n",
              " 'watching': 187,\n",
              " 'nasdaq': 89,\n",
              " 'take': 4732,\n",
              " 'nastydive': 1,\n",
              " 'msnbc': 22,\n",
              " 'march': 1738,\n",
              " '2000': 3749,\n",
              " 'knew': 311,\n",
              " 'hand': 1274,\n",
              " 'referring': 149,\n",
              " 'caseload': 1,\n",
              " 'la': 2741,\n",
              " 'casa': 33,\n",
              " 'de': 9872,\n",
              " 'madres': 1,\n",
              " 'city': 1663,\n",
              " 'largest': 632,\n",
              " 'organization': 1127,\n",
              " 'serving': 99,\n",
              " 'woman': 1200,\n",
              " 'child': 1672,\n",
              " 'affected': 143,\n",
              " 'crisis': 222,\n",
              " 'line': 3785,\n",
              " 'increased': 361,\n",
              " '33': 673,\n",
              " 'last': 3140,\n",
              " 'financial': 2487,\n",
              " 'saw': 453,\n",
              " '10': 10876,\n",
              " 'percent': 843,\n",
              " 'increase': 1175,\n",
              " 'demand': 648,\n",
              " 'bed': 254,\n",
              " '232': 56,\n",
              " '215': 463,\n",
              " 'utilizing': 75,\n",
              " 'shelter': 18,\n",
              " 'collapse': 133,\n",
              " 'growing': 598,\n",
              " 'awareness': 117,\n",
              " 'main': 1311,\n",
              " 'reason': 1390,\n",
              " 'employed': 119,\n",
              " 'utilized': 61,\n",
              " '04': 1133,\n",
              " '17pm': 7,\n",
              " '0100': 184,\n",
              " 'gordon': 134,\n",
              " 'joly': 2,\n",
              " 'wrote': 1693,\n",
              " 'news': 2810,\n",
              " 'bbc': 80,\n",
              " 'low': 1399,\n",
              " 'england': 538,\n",
              " '2276467': 1,\n",
              " 'stm': 26,\n",
              " 'admits': 26,\n",
              " 'trying': 877,\n",
              " 'hire': 128,\n",
              " 'hitman': 2,\n",
              " 'former': 510,\n",
              " 'tycoon': 6,\n",
              " 'admitted': 52,\n",
              " 'kill': 137,\n",
              " 'breakdown': 35,\n",
              " '21': 2087,\n",
              " 'marriage': 105,\n",
              " 'linux': 3312,\n",
              " '256022': 1,\n",
              " 'pobox': 24,\n",
              " 'gordo': 6,\n",
              " 'citizen': 230,\n",
              " 'griffith': 45,\n",
              " 'operation': 1422,\n",
              " 'agency': 641,\n",
              " 'operating': 663,\n",
              " 'agreement': 1433,\n",
              " 'tw': 314,\n",
              " 'taking': 772,\n",
              " 'monitoring': 105,\n",
              " 'plant': 624,\n",
              " 'behalf': 418,\n",
              " 'alarm': 42,\n",
              " 'personnel': 178,\n",
              " 'responsible': 417,\n",
              " ...}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXm6yay1yqp4",
        "outputId": "81f839da-734c-4b74-df38-8a8fa47ef160"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def keep_token(proccessed_token, threshold):\n",
        "  if proccessed_token not in token_counter:\n",
        "    return False\n",
        "  else:\n",
        "    return token_counter[proccessed_token] > threshold\n",
        "\n",
        "keep_token('random', 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMiIpz440Lco",
        "outputId": "67b5081f-595d-417f-c715-dabc1aca34b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'0',\n",
              " '00',\n",
              " '000',\n",
              " '01',\n",
              " '02',\n",
              " '03',\n",
              " '04',\n",
              " '05',\n",
              " '07',\n",
              " '08',\n",
              " '09',\n",
              " '1',\n",
              " '10',\n",
              " '100',\n",
              " '11',\n",
              " '12',\n",
              " '13',\n",
              " '14',\n",
              " '15',\n",
              " '16',\n",
              " '17',\n",
              " '18',\n",
              " '19',\n",
              " '1994',\n",
              " '1995',\n",
              " '1997',\n",
              " '1998',\n",
              " '1999',\n",
              " '2',\n",
              " '20',\n",
              " '200',\n",
              " '2000',\n",
              " '2001',\n",
              " '2002',\n",
              " '21',\n",
              " '22',\n",
              " '23',\n",
              " '24',\n",
              " '25',\n",
              " '26',\n",
              " '27',\n",
              " '28',\n",
              " '29',\n",
              " '3',\n",
              " '30',\n",
              " '31',\n",
              " '35',\n",
              " '3d',\n",
              " '4',\n",
              " '40',\n",
              " '44',\n",
              " '45',\n",
              " '49',\n",
              " '5',\n",
              " '50',\n",
              " '500',\n",
              " '6',\n",
              " '60',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " '90',\n",
              " '95',\n",
              " '97',\n",
              " '98',\n",
              " '99',\n",
              " '_',\n",
              " 'able',\n",
              " 'abstract',\n",
              " 'ac',\n",
              " 'accepted',\n",
              " 'access',\n",
              " 'account',\n",
              " 'acquisition',\n",
              " 'act',\n",
              " 'action',\n",
              " 'actually',\n",
              " 'ad',\n",
              " 'add',\n",
              " 'additional',\n",
              " 'address',\n",
              " 'ago',\n",
              " 'agreement',\n",
              " 'already',\n",
              " 'also',\n",
              " 'although',\n",
              " 'always',\n",
              " 'america',\n",
              " 'american',\n",
              " 'among',\n",
              " 'amount',\n",
              " 'analysis',\n",
              " 'analyst',\n",
              " 'announcement',\n",
              " 'another',\n",
              " 'answer',\n",
              " 'anyone',\n",
              " 'anything',\n",
              " 'application',\n",
              " 'applied',\n",
              " 'approach',\n",
              " 'april',\n",
              " 'area',\n",
              " 'argument',\n",
              " 'around',\n",
              " 'article',\n",
              " 'ask',\n",
              " 'asked',\n",
              " 'aspect',\n",
              " 'asset',\n",
              " 'association',\n",
              " 'attached',\n",
              " 'august',\n",
              " 'author',\n",
              " 'available',\n",
              " 'away',\n",
              " 'b',\n",
              " 'back',\n",
              " 'bank',\n",
              " 'based',\n",
              " 'basis',\n",
              " 'become',\n",
              " 'believe',\n",
              " 'benjamin',\n",
              " 'best',\n",
              " 'better',\n",
              " 'big',\n",
              " 'bill',\n",
              " 'billion',\n",
              " 'board',\n",
              " 'book',\n",
              " 'box',\n",
              " 'break',\n",
              " 'bulk',\n",
              " 'business',\n",
              " 'buy',\n",
              " 'c',\n",
              " 'ca',\n",
              " 'california',\n",
              " 'call',\n",
              " 'called',\n",
              " 'canada',\n",
              " 'cannot',\n",
              " 'capital',\n",
              " 'card',\n",
              " 'case',\n",
              " 'cash',\n",
              " 'category',\n",
              " 'cc',\n",
              " 'cd',\n",
              " 'center',\n",
              " 'certain',\n",
              " 'chair',\n",
              " 'change',\n",
              " 'charge',\n",
              " 'check',\n",
              " 'child',\n",
              " 'chinese',\n",
              " 'city',\n",
              " 'claim',\n",
              " 'class',\n",
              " 'clear',\n",
              " 'click',\n",
              " 'co',\n",
              " 'code',\n",
              " 'cognitive',\n",
              " 'college',\n",
              " 'color',\n",
              " 'com',\n",
              " 'come',\n",
              " 'comment',\n",
              " 'commercial',\n",
              " 'committee',\n",
              " 'common',\n",
              " 'communication',\n",
              " 'community',\n",
              " 'company',\n",
              " 'complete',\n",
              " 'computational',\n",
              " 'computer',\n",
              " 'conference',\n",
              " 'construction',\n",
              " 'contact',\n",
              " 'content',\n",
              " 'context',\n",
              " 'continue',\n",
              " 'contract',\n",
              " 'control',\n",
              " 'copy',\n",
              " 'copyright',\n",
              " 'corp',\n",
              " 'corpus',\n",
              " 'cost',\n",
              " 'could',\n",
              " 'country',\n",
              " 'course',\n",
              " 'cover',\n",
              " 'credit',\n",
              " 'current',\n",
              " 'currently',\n",
              " 'customer',\n",
              " 'data',\n",
              " 'database',\n",
              " 'date',\n",
              " 'david',\n",
              " 'day',\n",
              " 'de',\n",
              " 'deadline',\n",
              " 'deal',\n",
              " 'dear',\n",
              " 'debt',\n",
              " 'december',\n",
              " 'department',\n",
              " 'description',\n",
              " 'detail',\n",
              " 'development',\n",
              " 'dialect',\n",
              " 'difference',\n",
              " 'different',\n",
              " 'direct',\n",
              " 'director',\n",
              " 'directory',\n",
              " 'discourse',\n",
              " 'discussion',\n",
              " 'document',\n",
              " 'doe',\n",
              " 'dollar',\n",
              " 'domain',\n",
              " 'done',\n",
              " 'dr',\n",
              " 'due',\n",
              " 'dynegy',\n",
              " 'e',\n",
              " 'early',\n",
              " 'easy',\n",
              " 'ect',\n",
              " 'ed',\n",
              " 'editor',\n",
              " 'edu',\n",
              " 'education',\n",
              " 'effect',\n",
              " 'effort',\n",
              " 'either',\n",
              " 'electronic',\n",
              " 'else',\n",
              " 'email',\n",
              " 'en',\n",
              " 'end',\n",
              " 'energy',\n",
              " 'english',\n",
              " 'enough',\n",
              " 'enron',\n",
              " 'error',\n",
              " 'especially',\n",
              " 'et',\n",
              " 'etc',\n",
              " 'europe',\n",
              " 'european',\n",
              " 'evaluation',\n",
              " 'even',\n",
              " 'event',\n",
              " 'ever',\n",
              " 'every',\n",
              " 'everyone',\n",
              " 'example',\n",
              " 'exchange',\n",
              " 'experience',\n",
              " 'f',\n",
              " 'fact',\n",
              " 'family',\n",
              " 'far',\n",
              " 'fax',\n",
              " 'feature',\n",
              " 'february',\n",
              " 'fee',\n",
              " 'feel',\n",
              " 'field',\n",
              " 'file',\n",
              " 'final',\n",
              " 'financial',\n",
              " 'find',\n",
              " 'first',\n",
              " 'five',\n",
              " 'focus',\n",
              " 'follow',\n",
              " 'following',\n",
              " 'font',\n",
              " 'foreign',\n",
              " 'form',\n",
              " 'format',\n",
              " 'forward',\n",
              " 'forwarded',\n",
              " 'found',\n",
              " 'four',\n",
              " 'france',\n",
              " 'free',\n",
              " 'french',\n",
              " 'friday',\n",
              " 'friend',\n",
              " 'full',\n",
              " 'fund',\n",
              " 'future',\n",
              " 'g',\n",
              " 'gas',\n",
              " 'general',\n",
              " 'german',\n",
              " 'germany',\n",
              " 'get',\n",
              " 'getting',\n",
              " 'give',\n",
              " 'given',\n",
              " 'global',\n",
              " 'go',\n",
              " 'going',\n",
              " 'good',\n",
              " 'got',\n",
              " 'government',\n",
              " 'grammar',\n",
              " 'grant',\n",
              " 'great',\n",
              " 'group',\n",
              " 'h',\n",
              " 'ha',\n",
              " 'hand',\n",
              " 'hard',\n",
              " 'head',\n",
              " 'held',\n",
              " 'help',\n",
              " 'high',\n",
              " 'historical',\n",
              " 'history',\n",
              " 'home',\n",
              " 'hope',\n",
              " 'hotel',\n",
              " 'hou',\n",
              " 'hour',\n",
              " 'houston',\n",
              " 'however',\n",
              " 'html',\n",
              " 'http',\n",
              " 'human',\n",
              " 'hundred',\n",
              " 'id',\n",
              " 'idea',\n",
              " 'ie',\n",
              " 'ilug',\n",
              " 'immediately',\n",
              " 'important',\n",
              " 'inc',\n",
              " 'include',\n",
              " 'included',\n",
              " 'includes',\n",
              " 'including',\n",
              " 'income',\n",
              " 'increase',\n",
              " 'index',\n",
              " 'individual',\n",
              " 'industry',\n",
              " 'info',\n",
              " 'information',\n",
              " 'institute',\n",
              " 'instruction',\n",
              " 'interest',\n",
              " 'interested',\n",
              " 'international',\n",
              " 'internet',\n",
              " 'investment',\n",
              " 'investor',\n",
              " 'invited',\n",
              " 'issue',\n",
              " 'item',\n",
              " 'j',\n",
              " 'january',\n",
              " 'japan',\n",
              " 'japanese',\n",
              " 'job',\n",
              " 'john',\n",
              " 'jones',\n",
              " 'journal',\n",
              " 'july',\n",
              " 'june',\n",
              " 'k',\n",
              " 'kaminski',\n",
              " 'keep',\n",
              " 'key',\n",
              " 'kind',\n",
              " 'know',\n",
              " 'knowledge',\n",
              " 'l',\n",
              " 'la',\n",
              " 'language',\n",
              " 'large',\n",
              " 'last',\n",
              " 'later',\n",
              " 'latest',\n",
              " 'law',\n",
              " 'le',\n",
              " 'learn',\n",
              " 'learning',\n",
              " 'least',\n",
              " 'left',\n",
              " 'legal',\n",
              " 'length',\n",
              " 'less',\n",
              " 'let',\n",
              " 'letter',\n",
              " 'level',\n",
              " 'lexical',\n",
              " 'life',\n",
              " 'like',\n",
              " 'limited',\n",
              " 'line',\n",
              " 'linguist',\n",
              " 'linguistic',\n",
              " 'linguistics',\n",
              " 'link',\n",
              " 'linux',\n",
              " 'list',\n",
              " 'listinfo',\n",
              " 'little',\n",
              " 'live',\n",
              " 'local',\n",
              " 'logic',\n",
              " 'london',\n",
              " 'long',\n",
              " 'look',\n",
              " 'looking',\n",
              " 'loss',\n",
              " 'lot',\n",
              " 'low',\n",
              " 'lunch',\n",
              " 'machine',\n",
              " 'made',\n",
              " 'mail',\n",
              " 'mailing',\n",
              " 'mailman',\n",
              " 'main',\n",
              " 'major',\n",
              " 'make',\n",
              " 'making',\n",
              " 'man',\n",
              " 'management',\n",
              " 'many',\n",
              " 'march',\n",
              " 'mark',\n",
              " 'market',\n",
              " 'marketing',\n",
              " 'material',\n",
              " 'matter',\n",
              " 'may',\n",
              " 'mean',\n",
              " 'meaning',\n",
              " 'medium',\n",
              " 'meeting',\n",
              " 'member',\n",
              " 'message',\n",
              " 'method',\n",
              " 'michael',\n",
              " 'microsoft',\n",
              " 'might',\n",
              " 'million',\n",
              " 'mind',\n",
              " 'minute',\n",
              " 'model',\n",
              " 'monday',\n",
              " 'money',\n",
              " 'month',\n",
              " 'morphology',\n",
              " 'move',\n",
              " 'movement',\n",
              " 'mr',\n",
              " 'much',\n",
              " 'multi',\n",
              " 'must',\n",
              " 'n',\n",
              " 'name',\n",
              " 'national',\n",
              " 'native',\n",
              " 'natural',\n",
              " 'need',\n",
              " 'net',\n",
              " 'network',\n",
              " 'never',\n",
              " 'new',\n",
              " 'news',\n",
              " 'next',\n",
              " 'nl',\n",
              " 'non',\n",
              " 'north',\n",
              " 'note',\n",
              " 'nothing',\n",
              " 'november',\n",
              " 'number',\n",
              " 'object',\n",
              " 'october',\n",
              " 'offer',\n",
              " 'office',\n",
              " 'old',\n",
              " 'one',\n",
              " 'online',\n",
              " 'open',\n",
              " 'operation',\n",
              " 'opportunity',\n",
              " 'option',\n",
              " 'order',\n",
              " 'org',\n",
              " 'organization',\n",
              " 'original',\n",
              " 'others',\n",
              " 'p',\n",
              " 'package',\n",
              " 'page',\n",
              " 'paid',\n",
              " 'paper',\n",
              " 'part',\n",
              " 'participant',\n",
              " 'particular',\n",
              " 'party',\n",
              " 'past',\n",
              " 'paul',\n",
              " 'pay',\n",
              " 'payment',\n",
              " 'people',\n",
              " 'per',\n",
              " 'performance',\n",
              " 'person',\n",
              " 'personal',\n",
              " 'phone',\n",
              " 'phonology',\n",
              " 'place',\n",
              " 'plan',\n",
              " 'please',\n",
              " 'plus',\n",
              " 'pm',\n",
              " 'point',\n",
              " 'position',\n",
              " 'possible',\n",
              " 'post',\n",
              " 'potential',\n",
              " 'power',\n",
              " 'pp',\n",
              " 'pre',\n",
              " 'present',\n",
              " 'presentation',\n",
              " 'president',\n",
              " 'press',\n",
              " 'price',\n",
              " 'probably',\n",
              " 'problem',\n",
              " 'proceeding',\n",
              " 'process',\n",
              " 'processing',\n",
              " 'product',\n",
              " 'production',\n",
              " 'professional',\n",
              " 'program',\n",
              " 'programme',\n",
              " 'project',\n",
              " 'proposal',\n",
              " 'provide',\n",
              " 'provided',\n",
              " 'public',\n",
              " 'publication',\n",
              " 'published',\n",
              " 'purchase',\n",
              " 'put',\n",
              " 'quality',\n",
              " 'query',\n",
              " 'question',\n",
              " 'quite',\n",
              " 'r',\n",
              " 'rate',\n",
              " 'rather',\n",
              " 'razor',\n",
              " 'read',\n",
              " 'reading',\n",
              " 'ready',\n",
              " 'real',\n",
              " 'really',\n",
              " 'reason',\n",
              " 'receive',\n",
              " 'received',\n",
              " 'recent',\n",
              " 'record',\n",
              " 'reference',\n",
              " 'regard',\n",
              " 'registration',\n",
              " 'related',\n",
              " 'relation',\n",
              " 'release',\n",
              " 'remember',\n",
              " 'remove',\n",
              " 'removed',\n",
              " 'reply',\n",
              " 'report',\n",
              " 'representation',\n",
              " 'request',\n",
              " 'required',\n",
              " 'research',\n",
              " 'researcher',\n",
              " 'resource',\n",
              " 'response',\n",
              " 'result',\n",
              " 'return',\n",
              " 'review',\n",
              " 'right',\n",
              " 'risk',\n",
              " 'robert',\n",
              " 'role',\n",
              " 'room',\n",
              " 'rpm',\n",
              " 'rule',\n",
              " 'run',\n",
              " 'said',\n",
              " 'sale',\n",
              " 'save',\n",
              " 'say',\n",
              " 'schedule',\n",
              " 'school',\n",
              " 'science',\n",
              " 'search',\n",
              " 'second',\n",
              " 'section',\n",
              " 'security',\n",
              " 'see',\n",
              " 'seems',\n",
              " 'sell',\n",
              " 'semantic',\n",
              " 'semantics',\n",
              " 'send',\n",
              " 'sent',\n",
              " 'sentence',\n",
              " 'september',\n",
              " 'series',\n",
              " 'server',\n",
              " 'service',\n",
              " 'session',\n",
              " 'set',\n",
              " 'several',\n",
              " 'share',\n",
              " 'short',\n",
              " 'show',\n",
              " 'sign',\n",
              " 'simple',\n",
              " 'simply',\n",
              " 'since',\n",
              " 'single',\n",
              " 'site',\n",
              " 'size',\n",
              " 'small',\n",
              " 'social',\n",
              " 'society',\n",
              " 'software',\n",
              " 'someone',\n",
              " 'something',\n",
              " 'soon',\n",
              " 'sound',\n",
              " 'source',\n",
              " 'sourceforge',\n",
              " 'south',\n",
              " 'spam',\n",
              " 'spamassassin',\n",
              " 'spanish',\n",
              " 'speaker',\n",
              " 'special',\n",
              " 'specific',\n",
              " 'speech',\n",
              " 'spoken',\n",
              " 'st',\n",
              " 'standard',\n",
              " 'start',\n",
              " 'state',\n",
              " 'statement',\n",
              " 'step',\n",
              " 'still',\n",
              " 'stock',\n",
              " 'stop',\n",
              " 'story',\n",
              " 'street',\n",
              " 'structure',\n",
              " 'student',\n",
              " 'study',\n",
              " 'style',\n",
              " 'subject',\n",
              " 'submission',\n",
              " 'submit',\n",
              " 'subscription',\n",
              " 'success',\n",
              " 'summary',\n",
              " 'summer',\n",
              " 'support',\n",
              " 'sure',\n",
              " 'syntactic',\n",
              " 'syntax',\n",
              " 'system',\n",
              " 'take',\n",
              " 'talk',\n",
              " 'teaching',\n",
              " 'team',\n",
              " 'technology',\n",
              " 'tel',\n",
              " 'telephone',\n",
              " 'tell',\n",
              " 'term',\n",
              " 'texas',\n",
              " 'text',\n",
              " 'th',\n",
              " 'thank',\n",
              " 'thanks',\n",
              " 'theme',\n",
              " 'theoretical',\n",
              " 'theory',\n",
              " 'thing',\n",
              " 'think',\n",
              " 'third',\n",
              " 'though',\n",
              " 'thought',\n",
              " 'thousand',\n",
              " 'three',\n",
              " 'thursday',\n",
              " 'time',\n",
              " 'title',\n",
              " 'today',\n",
              " 'together',\n",
              " 'tool',\n",
              " 'top',\n",
              " 'topic',\n",
              " 'total',\n",
              " 'trade',\n",
              " 'trading',\n",
              " 'transaction',\n",
              " 'translation',\n",
              " 'try',\n",
              " 'tuesday',\n",
              " 'tutorial',\n",
              " 'two',\n",
              " 'type',\n",
              " 'u',\n",
              " 'uk',\n",
              " 'un',\n",
              " 'unit',\n",
              " 'united',\n",
              " 'university',\n",
              " 'unsubscribe',\n",
              " 'update',\n",
              " 'url',\n",
              " 'usa',\n",
              " 'use',\n",
              " 'used',\n",
              " 'user',\n",
              " 'using',\n",
              " 'v',\n",
              " 'value',\n",
              " 'various',\n",
              " 'verb',\n",
              " 'version',\n",
              " 'via',\n",
              " 'video',\n",
              " 'view',\n",
              " 'vince',\n",
              " 'visit',\n",
              " 'volume',\n",
              " 'vowel',\n",
              " 'w',\n",
              " 'wa',\n",
              " 'want',\n",
              " 'way',\n",
              " 'web',\n",
              " 'website',\n",
              " 'wednesday',\n",
              " 'week',\n",
              " 'welcome',\n",
              " 'well',\n",
              " 'whether',\n",
              " 'whole',\n",
              " 'wide',\n",
              " 'window',\n",
              " 'wish',\n",
              " 'within',\n",
              " 'without',\n",
              " 'woman',\n",
              " 'word',\n",
              " 'work',\n",
              " 'working',\n",
              " 'workshop',\n",
              " 'world',\n",
              " 'would',\n",
              " 'write',\n",
              " 'writing',\n",
              " 'written',\n",
              " 'wrote',\n",
              " 'www',\n",
              " 'x',\n",
              " 'yahoo',\n",
              " 'year',\n",
              " 'yes',\n",
              " 'yet',\n",
              " 'york',\n",
              " '½ï',\n",
              " 'â',\n",
              " 'ã',\n",
              " 'ï'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = set()\n",
        "\n",
        "for token in token_counter:\n",
        "  if keep_token(token, 1000):\n",
        "    features.add(token)\n",
        "\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLz9f1X73cwq",
        "outputId": "28b15d0d-5843-437f-b89c-bdf3abb540df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['approach',\n",
              " '14',\n",
              " 'investor',\n",
              " 'tuesday',\n",
              " 'press',\n",
              " '98',\n",
              " 'called',\n",
              " 'id',\n",
              " 'web',\n",
              " 'end',\n",
              " '200',\n",
              " 'given',\n",
              " 'january',\n",
              " 'check',\n",
              " 'code',\n",
              " '97',\n",
              " 'friday',\n",
              " 'four',\n",
              " 'communication',\n",
              " 'usa',\n",
              " '01',\n",
              " 'japan',\n",
              " 'small',\n",
              " 'currently',\n",
              " 'anyone',\n",
              " 'submission',\n",
              " 'argument',\n",
              " '1999',\n",
              " 'fund',\n",
              " 'thank',\n",
              " 'la',\n",
              " 'present',\n",
              " 'removed',\n",
              " 'name',\n",
              " 'try',\n",
              " 'student',\n",
              " 'back',\n",
              " 'german',\n",
              " 'line',\n",
              " 'member',\n",
              " 'write',\n",
              " 'certain',\n",
              " 'per',\n",
              " 'free',\n",
              " 'specific',\n",
              " 'info',\n",
              " 'level',\n",
              " 'fee',\n",
              " 'david',\n",
              " 'south',\n",
              " 'sound',\n",
              " 'including',\n",
              " 'hou',\n",
              " 'feature',\n",
              " 'j',\n",
              " 'market',\n",
              " 'commercial',\n",
              " 'linguistics',\n",
              " 'way',\n",
              " 'topic',\n",
              " 'japanese',\n",
              " 'long',\n",
              " 'big',\n",
              " 'proposal',\n",
              " 'legal',\n",
              " 'act',\n",
              " 'part',\n",
              " 'exchange',\n",
              " 'statement',\n",
              " 'representation',\n",
              " 'un',\n",
              " '16',\n",
              " '_',\n",
              " 'american',\n",
              " 'u',\n",
              " 'away',\n",
              " 'save',\n",
              " 'product',\n",
              " 'computer',\n",
              " 'item',\n",
              " 'speech',\n",
              " 'original',\n",
              " 'operation',\n",
              " 'keep',\n",
              " 'live',\n",
              " 'sourceforge',\n",
              " 'paid',\n",
              " 'dear',\n",
              " 'e',\n",
              " '1995',\n",
              " 'probably',\n",
              " 'june',\n",
              " 'seems',\n",
              " 'today',\n",
              " 'pp',\n",
              " 'customer',\n",
              " 'future',\n",
              " 'note',\n",
              " 'click',\n",
              " 'law',\n",
              " 'nothing',\n",
              " '60',\n",
              " 'management',\n",
              " 'important',\n",
              " 'capital',\n",
              " 'change',\n",
              " 'year',\n",
              " 'follow',\n",
              " 'semantic',\n",
              " 'internet',\n",
              " 'position',\n",
              " 'mean',\n",
              " 'ilug',\n",
              " 'potential',\n",
              " '95',\n",
              " 'latest',\n",
              " 'ever',\n",
              " 'additional',\n",
              " 'direct',\n",
              " 'contact',\n",
              " 'also',\n",
              " 'far',\n",
              " 'head',\n",
              " '500',\n",
              " 'support',\n",
              " '2',\n",
              " 'link',\n",
              " 'jones',\n",
              " 'february',\n",
              " 'quality',\n",
              " 'problem',\n",
              " 'make',\n",
              " 'response',\n",
              " 'share',\n",
              " 'journal',\n",
              " 'cannot',\n",
              " 'reading',\n",
              " 'course',\n",
              " 'special',\n",
              " 'page',\n",
              " 'order',\n",
              " 'learning',\n",
              " 'michael',\n",
              " '13',\n",
              " '15',\n",
              " 'benjamin',\n",
              " 'next',\n",
              " 'payment',\n",
              " 'theory',\n",
              " 'telephone',\n",
              " 'include',\n",
              " 'syntax',\n",
              " 'minute',\n",
              " 'simple',\n",
              " 'error',\n",
              " 'germany',\n",
              " 'california',\n",
              " 'transaction',\n",
              " 'following',\n",
              " 'domain',\n",
              " '25',\n",
              " 'college',\n",
              " '08',\n",
              " 'detail',\n",
              " 'department',\n",
              " 'october',\n",
              " 'united',\n",
              " 'many',\n",
              " 'object',\n",
              " 'dynegy',\n",
              " 'investment',\n",
              " 'top',\n",
              " 'result',\n",
              " 'video',\n",
              " 'limited',\n",
              " 'much',\n",
              " 'pay',\n",
              " 'start',\n",
              " 'acquisition',\n",
              " 'vince',\n",
              " 'interested',\n",
              " '10',\n",
              " 'matter',\n",
              " 'written',\n",
              " 'multi',\n",
              " 'call',\n",
              " 'short',\n",
              " 'spamassassin',\n",
              " 'color',\n",
              " 'kaminski',\n",
              " 'soon',\n",
              " 'size',\n",
              " 'co',\n",
              " 'category',\n",
              " 'razor',\n",
              " 'box',\n",
              " 'de',\n",
              " 'current',\n",
              " 'native',\n",
              " 'ha',\n",
              " 'rpm',\n",
              " 'schedule',\n",
              " 'unsubscribe',\n",
              " 'list',\n",
              " 'think',\n",
              " 'grammar',\n",
              " 'package',\n",
              " 'hope',\n",
              " 'anything',\n",
              " 'meaning',\n",
              " 'action',\n",
              " 'day',\n",
              " 'wide',\n",
              " 'spam',\n",
              " '29',\n",
              " 'great',\n",
              " 'contract',\n",
              " 'break',\n",
              " '40',\n",
              " '05',\n",
              " 'major',\n",
              " 'microsoft',\n",
              " 'job',\n",
              " 'online',\n",
              " 'lot',\n",
              " 'open',\n",
              " 'hotel',\n",
              " 'thanks',\n",
              " 'sure',\n",
              " 'researcher',\n",
              " 'email',\n",
              " 'process',\n",
              " 'material',\n",
              " 'copy',\n",
              " 'add',\n",
              " 'x',\n",
              " 'place',\n",
              " '000',\n",
              " 'available',\n",
              " 'made',\n",
              " 'evaluation',\n",
              " 'debt',\n",
              " 'sentence',\n",
              " 'let',\n",
              " 'return',\n",
              " 'website',\n",
              " 'invited',\n",
              " 'step',\n",
              " 'http',\n",
              " 'case',\n",
              " 'answer',\n",
              " 'put',\n",
              " 'help',\n",
              " 'loss',\n",
              " 'see',\n",
              " '1997',\n",
              " 'immediately',\n",
              " 'net',\n",
              " 'world',\n",
              " 'person',\n",
              " 'using',\n",
              " 'tel',\n",
              " 'cash',\n",
              " 'kind',\n",
              " 'example',\n",
              " 'software',\n",
              " '24',\n",
              " '44',\n",
              " 'simply',\n",
              " '22',\n",
              " 'among',\n",
              " 'working',\n",
              " 'grant',\n",
              " 'credit',\n",
              " 'trading',\n",
              " 'first',\n",
              " 'registration',\n",
              " 'like',\n",
              " 'still',\n",
              " 'type',\n",
              " '½ï',\n",
              " 'really',\n",
              " 'want',\n",
              " 'robert',\n",
              " '3d',\n",
              " 'presentation',\n",
              " '2001',\n",
              " 'ago',\n",
              " 'europe',\n",
              " '2000',\n",
              " 'least',\n",
              " 'march',\n",
              " 'looking',\n",
              " 'hand',\n",
              " 'increase',\n",
              " 'article',\n",
              " '9',\n",
              " 'france',\n",
              " 'included',\n",
              " 'section',\n",
              " 'issue',\n",
              " 'would',\n",
              " 'offer',\n",
              " 'received',\n",
              " 'take',\n",
              " 'effort',\n",
              " 'family',\n",
              " 'related',\n",
              " 'value',\n",
              " 'full',\n",
              " 'word',\n",
              " 'com',\n",
              " 'need',\n",
              " 'thousand',\n",
              " 'k',\n",
              " 'writing',\n",
              " 'woman',\n",
              " 'july',\n",
              " 'language',\n",
              " 'individual',\n",
              " 'find',\n",
              " 'america',\n",
              " 'project',\n",
              " 'spanish',\n",
              " 'linguistic',\n",
              " 'date',\n",
              " 'thought',\n",
              " 'high',\n",
              " 'user',\n",
              " 'idea',\n",
              " 'et',\n",
              " 'org',\n",
              " 'company',\n",
              " 'marketing',\n",
              " 'yet',\n",
              " 'read',\n",
              " 'possible',\n",
              " 'phonology',\n",
              " 'street',\n",
              " 'together',\n",
              " 'party',\n",
              " 'organization',\n",
              " 'amount',\n",
              " 'ie',\n",
              " 'might',\n",
              " 'team',\n",
              " '07',\n",
              " 'money',\n",
              " 'analyst',\n",
              " '28',\n",
              " 'abstract',\n",
              " 'spoken',\n",
              " 'work',\n",
              " 'â',\n",
              " 'method',\n",
              " 'foreign',\n",
              " 'society',\n",
              " 'give',\n",
              " 'term',\n",
              " 'window',\n",
              " 'education',\n",
              " 'v',\n",
              " 'monday',\n",
              " 'medium',\n",
              " 'mail',\n",
              " '11',\n",
              " 'personal',\n",
              " 'deadline',\n",
              " 'asked',\n",
              " 'linguist',\n",
              " 'html',\n",
              " 'thing',\n",
              " 'early',\n",
              " 'forward',\n",
              " 'ad',\n",
              " 'people',\n",
              " 'view',\n",
              " 'ready',\n",
              " 'conference',\n",
              " 'proceeding',\n",
              " 'history',\n",
              " 'asset',\n",
              " 'search',\n",
              " 'format',\n",
              " 'series',\n",
              " '26',\n",
              " 'board',\n",
              " 'via',\n",
              " 'cover',\n",
              " 'corp',\n",
              " '6',\n",
              " '27',\n",
              " 'paper',\n",
              " '20',\n",
              " 'www',\n",
              " '7',\n",
              " 'done',\n",
              " 'french',\n",
              " 'success',\n",
              " 'wish',\n",
              " 'different',\n",
              " 'inc',\n",
              " 'submit',\n",
              " '18',\n",
              " 'ect',\n",
              " '21',\n",
              " 'billion',\n",
              " 'wa',\n",
              " 'c',\n",
              " 'unit',\n",
              " 'less',\n",
              " 'en',\n",
              " 'meeting',\n",
              " 'focus',\n",
              " 'event',\n",
              " 'volume',\n",
              " 'believe',\n",
              " 'old',\n",
              " 'url',\n",
              " 'north',\n",
              " 'cd',\n",
              " 'association',\n",
              " '49',\n",
              " 'committee',\n",
              " 'interest',\n",
              " 'public',\n",
              " 'phone',\n",
              " 'never',\n",
              " 'quite',\n",
              " 'post',\n",
              " 'chinese',\n",
              " 'national',\n",
              " 'number',\n",
              " 'pm',\n",
              " 'later',\n",
              " 'access',\n",
              " 'mailman',\n",
              " 'ca',\n",
              " 'required',\n",
              " '30',\n",
              " 'published',\n",
              " 'since',\n",
              " 'class',\n",
              " 'wrote',\n",
              " '5',\n",
              " 'author',\n",
              " 'remove',\n",
              " '17',\n",
              " 'research',\n",
              " 'session',\n",
              " '4',\n",
              " 'ed',\n",
              " 'syntactic',\n",
              " '04',\n",
              " 'morphology',\n",
              " 'style',\n",
              " 'database',\n",
              " 'financial',\n",
              " 'may',\n",
              " 'international',\n",
              " '50',\n",
              " 'particular',\n",
              " 'able',\n",
              " 'power',\n",
              " 'yes',\n",
              " 'either',\n",
              " 'continue',\n",
              " 'center',\n",
              " 'buy',\n",
              " 'nl',\n",
              " 'institute',\n",
              " 'especially',\n",
              " 'dialect',\n",
              " '0',\n",
              " '31',\n",
              " 'knowledge',\n",
              " '1',\n",
              " 'participant',\n",
              " 'single',\n",
              " 'fact',\n",
              " '99',\n",
              " 'fax',\n",
              " 'hard',\n",
              " 'aspect',\n",
              " 'general',\n",
              " 'november',\n",
              " 'plus',\n",
              " 'tell',\n",
              " 'book',\n",
              " 'accepted',\n",
              " 'control',\n",
              " 'five',\n",
              " 'sell',\n",
              " 'though',\n",
              " 'font',\n",
              " 'bulk',\n",
              " 'held',\n",
              " 'plan',\n",
              " 'three',\n",
              " 'getting',\n",
              " 'science',\n",
              " 'human',\n",
              " 'low',\n",
              " 'computational',\n",
              " 'however',\n",
              " 'tutorial',\n",
              " 'yahoo',\n",
              " 'performance',\n",
              " 'hundred',\n",
              " 'application',\n",
              " 'state',\n",
              " 'second',\n",
              " 'linux',\n",
              " 'ask',\n",
              " 'structure',\n",
              " 'april',\n",
              " 'without',\n",
              " 'found',\n",
              " 'several',\n",
              " 'etc',\n",
              " 'reason',\n",
              " 'price',\n",
              " 'machine',\n",
              " 'actually',\n",
              " 'thursday',\n",
              " 'move',\n",
              " 'professional',\n",
              " 'home',\n",
              " 'h',\n",
              " '45',\n",
              " 'edu',\n",
              " 'announcement',\n",
              " 'common',\n",
              " 'could',\n",
              " 'director',\n",
              " 'option',\n",
              " 'mailing',\n",
              " 'community',\n",
              " 'area',\n",
              " 'one',\n",
              " 'directory',\n",
              " 'difference',\n",
              " 'file',\n",
              " 'london',\n",
              " 'description',\n",
              " 'already',\n",
              " 'corpus',\n",
              " 'charge',\n",
              " 'production',\n",
              " 'role',\n",
              " 'recent',\n",
              " 'model',\n",
              " 'various',\n",
              " 'relation',\n",
              " 'le',\n",
              " 'city',\n",
              " 'know',\n",
              " 'version',\n",
              " 'trade',\n",
              " 'within',\n",
              " 'g',\n",
              " 'release',\n",
              " 'always',\n",
              " 'visit',\n",
              " 'clear',\n",
              " 'claim',\n",
              " 'cognitive',\n",
              " 'comment',\n",
              " 'st',\n",
              " 'run',\n",
              " 'cost',\n",
              " 'little',\n",
              " 'european',\n",
              " 'semantics',\n",
              " 'field',\n",
              " 'editor',\n",
              " 'discussion',\n",
              " 'say',\n",
              " 'electronic',\n",
              " 'n',\n",
              " 'feel',\n",
              " 'easy',\n",
              " 'title',\n",
              " 'ac',\n",
              " 'network',\n",
              " 'show',\n",
              " 'become',\n",
              " 'around',\n",
              " 'look',\n",
              " 'non',\n",
              " 'logic',\n",
              " 'wednesday',\n",
              " 'cc',\n",
              " 'summer',\n",
              " 'please',\n",
              " 'historical',\n",
              " 'movement',\n",
              " 'income',\n",
              " 'good',\n",
              " 'business',\n",
              " 'must',\n",
              " 'th',\n",
              " 'card',\n",
              " 'stock',\n",
              " 'l',\n",
              " 'week',\n",
              " 'attached',\n",
              " 'whether',\n",
              " 'rather',\n",
              " 'new',\n",
              " 'news',\n",
              " 'others',\n",
              " 'total',\n",
              " 'energy',\n",
              " 'left',\n",
              " 'final',\n",
              " 'bill',\n",
              " 'receive',\n",
              " 'although',\n",
              " 'government',\n",
              " 'based',\n",
              " 'hour',\n",
              " 'school',\n",
              " 'york',\n",
              " 'two',\n",
              " 'source',\n",
              " 'subscription',\n",
              " 'uk',\n",
              " 'account',\n",
              " 'stop',\n",
              " 'message',\n",
              " '2002',\n",
              " 'content',\n",
              " 'includes',\n",
              " 'sale',\n",
              " 'else',\n",
              " 'best',\n",
              " 'group',\n",
              " 'university',\n",
              " 'story',\n",
              " 'room',\n",
              " 'p',\n",
              " 'letter',\n",
              " '100',\n",
              " 'update',\n",
              " 'verb',\n",
              " 'query',\n",
              " 'canada',\n",
              " 'real',\n",
              " 'deal',\n",
              " '00',\n",
              " 'office',\n",
              " 'system',\n",
              " 'purchase',\n",
              " 'server',\n",
              " 'request',\n",
              " 'standard',\n",
              " '1998',\n",
              " 'going',\n",
              " 'sign',\n",
              " 'time',\n",
              " 'site',\n",
              " 'sent',\n",
              " 'send',\n",
              " 'go',\n",
              " 'large',\n",
              " 'length',\n",
              " 'programme',\n",
              " 'pre',\n",
              " 'dr',\n",
              " 'b',\n",
              " 'remember',\n",
              " 'get',\n",
              " 'talk',\n",
              " 'address',\n",
              " 'analysis',\n",
              " 'review',\n",
              " 'industry',\n",
              " 'record',\n",
              " 'learn',\n",
              " 'houston',\n",
              " '03',\n",
              " 'friend',\n",
              " '23',\n",
              " 'processing',\n",
              " 'august',\n",
              " 'ã',\n",
              " 'workshop',\n",
              " 'mind',\n",
              " 'question',\n",
              " 'man',\n",
              " 'reply',\n",
              " 'security',\n",
              " 'come',\n",
              " 'document',\n",
              " 'john',\n",
              " 'even',\n",
              " 'applied',\n",
              " 'form',\n",
              " 'right',\n",
              " 'texas',\n",
              " 'said',\n",
              " 'something',\n",
              " 'ï',\n",
              " 'bank',\n",
              " 'technology',\n",
              " 'reference',\n",
              " 'every',\n",
              " 'lunch',\n",
              " 'december',\n",
              " '3',\n",
              " 'paul',\n",
              " 'report',\n",
              " 'enough',\n",
              " 'mr',\n",
              " 'service',\n",
              " '90',\n",
              " 'tool',\n",
              " 'data',\n",
              " 'got',\n",
              " 'study',\n",
              " 'teaching',\n",
              " 'opportunity',\n",
              " 'making',\n",
              " 'country',\n",
              " 'last',\n",
              " 'vowel',\n",
              " 'natural',\n",
              " 'doe',\n",
              " 'everyone',\n",
              " 'subject',\n",
              " 'enron',\n",
              " 'key',\n",
              " 'english',\n",
              " 'listinfo',\n",
              " 'another',\n",
              " 'forwarded',\n",
              " 'mark',\n",
              " 'month',\n",
              " 'used',\n",
              " 'dollar',\n",
              " 'president',\n",
              " 'basis',\n",
              " '35',\n",
              " 'f',\n",
              " 'well',\n",
              " 'main',\n",
              " 'local',\n",
              " 'publication',\n",
              " 'risk',\n",
              " 'global',\n",
              " 'chair',\n",
              " '02',\n",
              " 'regard',\n",
              " 'index',\n",
              " 'third',\n",
              " 'copyright',\n",
              " 'rule',\n",
              " 'w',\n",
              " 'effect',\n",
              " 'resource',\n",
              " 'r',\n",
              " 'instruction',\n",
              " 'program',\n",
              " 'construction',\n",
              " 'point',\n",
              " '12',\n",
              " 'child',\n",
              " 'complete',\n",
              " 'experience',\n",
              " 'provide',\n",
              " 'life',\n",
              " 'past',\n",
              " 'discourse',\n",
              " 'use',\n",
              " 'due',\n",
              " 'development',\n",
              " 'welcome',\n",
              " '8',\n",
              " 'gas',\n",
              " '1994',\n",
              " 'rate',\n",
              " 'context',\n",
              " 'theoretical',\n",
              " '09',\n",
              " 'information',\n",
              " 'translation',\n",
              " 'million',\n",
              " 'agreement',\n",
              " 'someone',\n",
              " 'provided',\n",
              " 'whole',\n",
              " 'set',\n",
              " 'social',\n",
              " 'lexical',\n",
              " 'september',\n",
              " 'text',\n",
              " 'speaker',\n",
              " '19',\n",
              " 'theme',\n",
              " 'summary',\n",
              " 'better']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = list(features)\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8357HG1Q3itk",
        "outputId": "188a7383-4bdb-49e5-9f40-ef14e28b6258"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'approach': 0,\n",
              " '14': 1,\n",
              " 'investor': 2,\n",
              " 'tuesday': 3,\n",
              " 'press': 4,\n",
              " '98': 5,\n",
              " 'called': 6,\n",
              " 'id': 7,\n",
              " 'web': 8,\n",
              " 'end': 9,\n",
              " '200': 10,\n",
              " 'given': 11,\n",
              " 'january': 12,\n",
              " 'check': 13,\n",
              " 'code': 14,\n",
              " '97': 15,\n",
              " 'friday': 16,\n",
              " 'four': 17,\n",
              " 'communication': 18,\n",
              " 'usa': 19,\n",
              " '01': 20,\n",
              " 'japan': 21,\n",
              " 'small': 22,\n",
              " 'currently': 23,\n",
              " 'anyone': 24,\n",
              " 'submission': 25,\n",
              " 'argument': 26,\n",
              " '1999': 27,\n",
              " 'fund': 28,\n",
              " 'thank': 29,\n",
              " 'la': 30,\n",
              " 'present': 31,\n",
              " 'removed': 32,\n",
              " 'name': 33,\n",
              " 'try': 34,\n",
              " 'student': 35,\n",
              " 'back': 36,\n",
              " 'german': 37,\n",
              " 'line': 38,\n",
              " 'member': 39,\n",
              " 'write': 40,\n",
              " 'certain': 41,\n",
              " 'per': 42,\n",
              " 'free': 43,\n",
              " 'specific': 44,\n",
              " 'info': 45,\n",
              " 'level': 46,\n",
              " 'fee': 47,\n",
              " 'david': 48,\n",
              " 'south': 49,\n",
              " 'sound': 50,\n",
              " 'including': 51,\n",
              " 'hou': 52,\n",
              " 'feature': 53,\n",
              " 'j': 54,\n",
              " 'market': 55,\n",
              " 'commercial': 56,\n",
              " 'linguistics': 57,\n",
              " 'way': 58,\n",
              " 'topic': 59,\n",
              " 'japanese': 60,\n",
              " 'long': 61,\n",
              " 'big': 62,\n",
              " 'proposal': 63,\n",
              " 'legal': 64,\n",
              " 'act': 65,\n",
              " 'part': 66,\n",
              " 'exchange': 67,\n",
              " 'statement': 68,\n",
              " 'representation': 69,\n",
              " 'un': 70,\n",
              " '16': 71,\n",
              " '_': 72,\n",
              " 'american': 73,\n",
              " 'u': 74,\n",
              " 'away': 75,\n",
              " 'save': 76,\n",
              " 'product': 77,\n",
              " 'computer': 78,\n",
              " 'item': 79,\n",
              " 'speech': 80,\n",
              " 'original': 81,\n",
              " 'operation': 82,\n",
              " 'keep': 83,\n",
              " 'live': 84,\n",
              " 'sourceforge': 85,\n",
              " 'paid': 86,\n",
              " 'dear': 87,\n",
              " 'e': 88,\n",
              " '1995': 89,\n",
              " 'probably': 90,\n",
              " 'june': 91,\n",
              " 'seems': 92,\n",
              " 'today': 93,\n",
              " 'pp': 94,\n",
              " 'customer': 95,\n",
              " 'future': 96,\n",
              " 'note': 97,\n",
              " 'click': 98,\n",
              " 'law': 99,\n",
              " 'nothing': 100,\n",
              " '60': 101,\n",
              " 'management': 102,\n",
              " 'important': 103,\n",
              " 'capital': 104,\n",
              " 'change': 105,\n",
              " 'year': 106,\n",
              " 'follow': 107,\n",
              " 'semantic': 108,\n",
              " 'internet': 109,\n",
              " 'position': 110,\n",
              " 'mean': 111,\n",
              " 'ilug': 112,\n",
              " 'potential': 113,\n",
              " '95': 114,\n",
              " 'latest': 115,\n",
              " 'ever': 116,\n",
              " 'additional': 117,\n",
              " 'direct': 118,\n",
              " 'contact': 119,\n",
              " 'also': 120,\n",
              " 'far': 121,\n",
              " 'head': 122,\n",
              " '500': 123,\n",
              " 'support': 124,\n",
              " '2': 125,\n",
              " 'link': 126,\n",
              " 'jones': 127,\n",
              " 'february': 128,\n",
              " 'quality': 129,\n",
              " 'problem': 130,\n",
              " 'make': 131,\n",
              " 'response': 132,\n",
              " 'share': 133,\n",
              " 'journal': 134,\n",
              " 'cannot': 135,\n",
              " 'reading': 136,\n",
              " 'course': 137,\n",
              " 'special': 138,\n",
              " 'page': 139,\n",
              " 'order': 140,\n",
              " 'learning': 141,\n",
              " 'michael': 142,\n",
              " '13': 143,\n",
              " '15': 144,\n",
              " 'benjamin': 145,\n",
              " 'next': 146,\n",
              " 'payment': 147,\n",
              " 'theory': 148,\n",
              " 'telephone': 149,\n",
              " 'include': 150,\n",
              " 'syntax': 151,\n",
              " 'minute': 152,\n",
              " 'simple': 153,\n",
              " 'error': 154,\n",
              " 'germany': 155,\n",
              " 'california': 156,\n",
              " 'transaction': 157,\n",
              " 'following': 158,\n",
              " 'domain': 159,\n",
              " '25': 160,\n",
              " 'college': 161,\n",
              " '08': 162,\n",
              " 'detail': 163,\n",
              " 'department': 164,\n",
              " 'october': 165,\n",
              " 'united': 166,\n",
              " 'many': 167,\n",
              " 'object': 168,\n",
              " 'dynegy': 169,\n",
              " 'investment': 170,\n",
              " 'top': 171,\n",
              " 'result': 172,\n",
              " 'video': 173,\n",
              " 'limited': 174,\n",
              " 'much': 175,\n",
              " 'pay': 176,\n",
              " 'start': 177,\n",
              " 'acquisition': 178,\n",
              " 'vince': 179,\n",
              " 'interested': 180,\n",
              " '10': 181,\n",
              " 'matter': 182,\n",
              " 'written': 183,\n",
              " 'multi': 184,\n",
              " 'call': 185,\n",
              " 'short': 186,\n",
              " 'spamassassin': 187,\n",
              " 'color': 188,\n",
              " 'kaminski': 189,\n",
              " 'soon': 190,\n",
              " 'size': 191,\n",
              " 'co': 192,\n",
              " 'category': 193,\n",
              " 'razor': 194,\n",
              " 'box': 195,\n",
              " 'de': 196,\n",
              " 'current': 197,\n",
              " 'native': 198,\n",
              " 'ha': 199,\n",
              " 'rpm': 200,\n",
              " 'schedule': 201,\n",
              " 'unsubscribe': 202,\n",
              " 'list': 203,\n",
              " 'think': 204,\n",
              " 'grammar': 205,\n",
              " 'package': 206,\n",
              " 'hope': 207,\n",
              " 'anything': 208,\n",
              " 'meaning': 209,\n",
              " 'action': 210,\n",
              " 'day': 211,\n",
              " 'wide': 212,\n",
              " 'spam': 213,\n",
              " '29': 214,\n",
              " 'great': 215,\n",
              " 'contract': 216,\n",
              " 'break': 217,\n",
              " '40': 218,\n",
              " '05': 219,\n",
              " 'major': 220,\n",
              " 'microsoft': 221,\n",
              " 'job': 222,\n",
              " 'online': 223,\n",
              " 'lot': 224,\n",
              " 'open': 225,\n",
              " 'hotel': 226,\n",
              " 'thanks': 227,\n",
              " 'sure': 228,\n",
              " 'researcher': 229,\n",
              " 'email': 230,\n",
              " 'process': 231,\n",
              " 'material': 232,\n",
              " 'copy': 233,\n",
              " 'add': 234,\n",
              " 'x': 235,\n",
              " 'place': 236,\n",
              " '000': 237,\n",
              " 'available': 238,\n",
              " 'made': 239,\n",
              " 'evaluation': 240,\n",
              " 'debt': 241,\n",
              " 'sentence': 242,\n",
              " 'let': 243,\n",
              " 'return': 244,\n",
              " 'website': 245,\n",
              " 'invited': 246,\n",
              " 'step': 247,\n",
              " 'http': 248,\n",
              " 'case': 249,\n",
              " 'answer': 250,\n",
              " 'put': 251,\n",
              " 'help': 252,\n",
              " 'loss': 253,\n",
              " 'see': 254,\n",
              " '1997': 255,\n",
              " 'immediately': 256,\n",
              " 'net': 257,\n",
              " 'world': 258,\n",
              " 'person': 259,\n",
              " 'using': 260,\n",
              " 'tel': 261,\n",
              " 'cash': 262,\n",
              " 'kind': 263,\n",
              " 'example': 264,\n",
              " 'software': 265,\n",
              " '24': 266,\n",
              " '44': 267,\n",
              " 'simply': 268,\n",
              " '22': 269,\n",
              " 'among': 270,\n",
              " 'working': 271,\n",
              " 'grant': 272,\n",
              " 'credit': 273,\n",
              " 'trading': 274,\n",
              " 'first': 275,\n",
              " 'registration': 276,\n",
              " 'like': 277,\n",
              " 'still': 278,\n",
              " 'type': 279,\n",
              " '½ï': 280,\n",
              " 'really': 281,\n",
              " 'want': 282,\n",
              " 'robert': 283,\n",
              " '3d': 284,\n",
              " 'presentation': 285,\n",
              " '2001': 286,\n",
              " 'ago': 287,\n",
              " 'europe': 288,\n",
              " '2000': 289,\n",
              " 'least': 290,\n",
              " 'march': 291,\n",
              " 'looking': 292,\n",
              " 'hand': 293,\n",
              " 'increase': 294,\n",
              " 'article': 295,\n",
              " '9': 296,\n",
              " 'france': 297,\n",
              " 'included': 298,\n",
              " 'section': 299,\n",
              " 'issue': 300,\n",
              " 'would': 301,\n",
              " 'offer': 302,\n",
              " 'received': 303,\n",
              " 'take': 304,\n",
              " 'effort': 305,\n",
              " 'family': 306,\n",
              " 'related': 307,\n",
              " 'value': 308,\n",
              " 'full': 309,\n",
              " 'word': 310,\n",
              " 'com': 311,\n",
              " 'need': 312,\n",
              " 'thousand': 313,\n",
              " 'k': 314,\n",
              " 'writing': 315,\n",
              " 'woman': 316,\n",
              " 'july': 317,\n",
              " 'language': 318,\n",
              " 'individual': 319,\n",
              " 'find': 320,\n",
              " 'america': 321,\n",
              " 'project': 322,\n",
              " 'spanish': 323,\n",
              " 'linguistic': 324,\n",
              " 'date': 325,\n",
              " 'thought': 326,\n",
              " 'high': 327,\n",
              " 'user': 328,\n",
              " 'idea': 329,\n",
              " 'et': 330,\n",
              " 'org': 331,\n",
              " 'company': 332,\n",
              " 'marketing': 333,\n",
              " 'yet': 334,\n",
              " 'read': 335,\n",
              " 'possible': 336,\n",
              " 'phonology': 337,\n",
              " 'street': 338,\n",
              " 'together': 339,\n",
              " 'party': 340,\n",
              " 'organization': 341,\n",
              " 'amount': 342,\n",
              " 'ie': 343,\n",
              " 'might': 344,\n",
              " 'team': 345,\n",
              " '07': 346,\n",
              " 'money': 347,\n",
              " 'analyst': 348,\n",
              " '28': 349,\n",
              " 'abstract': 350,\n",
              " 'spoken': 351,\n",
              " 'work': 352,\n",
              " 'â': 353,\n",
              " 'method': 354,\n",
              " 'foreign': 355,\n",
              " 'society': 356,\n",
              " 'give': 357,\n",
              " 'term': 358,\n",
              " 'window': 359,\n",
              " 'education': 360,\n",
              " 'v': 361,\n",
              " 'monday': 362,\n",
              " 'medium': 363,\n",
              " 'mail': 364,\n",
              " '11': 365,\n",
              " 'personal': 366,\n",
              " 'deadline': 367,\n",
              " 'asked': 368,\n",
              " 'linguist': 369,\n",
              " 'html': 370,\n",
              " 'thing': 371,\n",
              " 'early': 372,\n",
              " 'forward': 373,\n",
              " 'ad': 374,\n",
              " 'people': 375,\n",
              " 'view': 376,\n",
              " 'ready': 377,\n",
              " 'conference': 378,\n",
              " 'proceeding': 379,\n",
              " 'history': 380,\n",
              " 'asset': 381,\n",
              " 'search': 382,\n",
              " 'format': 383,\n",
              " 'series': 384,\n",
              " '26': 385,\n",
              " 'board': 386,\n",
              " 'via': 387,\n",
              " 'cover': 388,\n",
              " 'corp': 389,\n",
              " '6': 390,\n",
              " '27': 391,\n",
              " 'paper': 392,\n",
              " '20': 393,\n",
              " 'www': 394,\n",
              " '7': 395,\n",
              " 'done': 396,\n",
              " 'french': 397,\n",
              " 'success': 398,\n",
              " 'wish': 399,\n",
              " 'different': 400,\n",
              " 'inc': 401,\n",
              " 'submit': 402,\n",
              " '18': 403,\n",
              " 'ect': 404,\n",
              " '21': 405,\n",
              " 'billion': 406,\n",
              " 'wa': 407,\n",
              " 'c': 408,\n",
              " 'unit': 409,\n",
              " 'less': 410,\n",
              " 'en': 411,\n",
              " 'meeting': 412,\n",
              " 'focus': 413,\n",
              " 'event': 414,\n",
              " 'volume': 415,\n",
              " 'believe': 416,\n",
              " 'old': 417,\n",
              " 'url': 418,\n",
              " 'north': 419,\n",
              " 'cd': 420,\n",
              " 'association': 421,\n",
              " '49': 422,\n",
              " 'committee': 423,\n",
              " 'interest': 424,\n",
              " 'public': 425,\n",
              " 'phone': 426,\n",
              " 'never': 427,\n",
              " 'quite': 428,\n",
              " 'post': 429,\n",
              " 'chinese': 430,\n",
              " 'national': 431,\n",
              " 'number': 432,\n",
              " 'pm': 433,\n",
              " 'later': 434,\n",
              " 'access': 435,\n",
              " 'mailman': 436,\n",
              " 'ca': 437,\n",
              " 'required': 438,\n",
              " '30': 439,\n",
              " 'published': 440,\n",
              " 'since': 441,\n",
              " 'class': 442,\n",
              " 'wrote': 443,\n",
              " '5': 444,\n",
              " 'author': 445,\n",
              " 'remove': 446,\n",
              " '17': 447,\n",
              " 'research': 448,\n",
              " 'session': 449,\n",
              " '4': 450,\n",
              " 'ed': 451,\n",
              " 'syntactic': 452,\n",
              " '04': 453,\n",
              " 'morphology': 454,\n",
              " 'style': 455,\n",
              " 'database': 456,\n",
              " 'financial': 457,\n",
              " 'may': 458,\n",
              " 'international': 459,\n",
              " '50': 460,\n",
              " 'particular': 461,\n",
              " 'able': 462,\n",
              " 'power': 463,\n",
              " 'yes': 464,\n",
              " 'either': 465,\n",
              " 'continue': 466,\n",
              " 'center': 467,\n",
              " 'buy': 468,\n",
              " 'nl': 469,\n",
              " 'institute': 470,\n",
              " 'especially': 471,\n",
              " 'dialect': 472,\n",
              " '0': 473,\n",
              " '31': 474,\n",
              " 'knowledge': 475,\n",
              " '1': 476,\n",
              " 'participant': 477,\n",
              " 'single': 478,\n",
              " 'fact': 479,\n",
              " '99': 480,\n",
              " 'fax': 481,\n",
              " 'hard': 482,\n",
              " 'aspect': 483,\n",
              " 'general': 484,\n",
              " 'november': 485,\n",
              " 'plus': 486,\n",
              " 'tell': 487,\n",
              " 'book': 488,\n",
              " 'accepted': 489,\n",
              " 'control': 490,\n",
              " 'five': 491,\n",
              " 'sell': 492,\n",
              " 'though': 493,\n",
              " 'font': 494,\n",
              " 'bulk': 495,\n",
              " 'held': 496,\n",
              " 'plan': 497,\n",
              " 'three': 498,\n",
              " 'getting': 499,\n",
              " 'science': 500,\n",
              " 'human': 501,\n",
              " 'low': 502,\n",
              " 'computational': 503,\n",
              " 'however': 504,\n",
              " 'tutorial': 505,\n",
              " 'yahoo': 506,\n",
              " 'performance': 507,\n",
              " 'hundred': 508,\n",
              " 'application': 509,\n",
              " 'state': 510,\n",
              " 'second': 511,\n",
              " 'linux': 512,\n",
              " 'ask': 513,\n",
              " 'structure': 514,\n",
              " 'april': 515,\n",
              " 'without': 516,\n",
              " 'found': 517,\n",
              " 'several': 518,\n",
              " 'etc': 519,\n",
              " 'reason': 520,\n",
              " 'price': 521,\n",
              " 'machine': 522,\n",
              " 'actually': 523,\n",
              " 'thursday': 524,\n",
              " 'move': 525,\n",
              " 'professional': 526,\n",
              " 'home': 527,\n",
              " 'h': 528,\n",
              " '45': 529,\n",
              " 'edu': 530,\n",
              " 'announcement': 531,\n",
              " 'common': 532,\n",
              " 'could': 533,\n",
              " 'director': 534,\n",
              " 'option': 535,\n",
              " 'mailing': 536,\n",
              " 'community': 537,\n",
              " 'area': 538,\n",
              " 'one': 539,\n",
              " 'directory': 540,\n",
              " 'difference': 541,\n",
              " 'file': 542,\n",
              " 'london': 543,\n",
              " 'description': 544,\n",
              " 'already': 545,\n",
              " 'corpus': 546,\n",
              " 'charge': 547,\n",
              " 'production': 548,\n",
              " 'role': 549,\n",
              " 'recent': 550,\n",
              " 'model': 551,\n",
              " 'various': 552,\n",
              " 'relation': 553,\n",
              " 'le': 554,\n",
              " 'city': 555,\n",
              " 'know': 556,\n",
              " 'version': 557,\n",
              " 'trade': 558,\n",
              " 'within': 559,\n",
              " 'g': 560,\n",
              " 'release': 561,\n",
              " 'always': 562,\n",
              " 'visit': 563,\n",
              " 'clear': 564,\n",
              " 'claim': 565,\n",
              " 'cognitive': 566,\n",
              " 'comment': 567,\n",
              " 'st': 568,\n",
              " 'run': 569,\n",
              " 'cost': 570,\n",
              " 'little': 571,\n",
              " 'european': 572,\n",
              " 'semantics': 573,\n",
              " 'field': 574,\n",
              " 'editor': 575,\n",
              " 'discussion': 576,\n",
              " 'say': 577,\n",
              " 'electronic': 578,\n",
              " 'n': 579,\n",
              " 'feel': 580,\n",
              " 'easy': 581,\n",
              " 'title': 582,\n",
              " 'ac': 583,\n",
              " 'network': 584,\n",
              " 'show': 585,\n",
              " 'become': 586,\n",
              " 'around': 587,\n",
              " 'look': 588,\n",
              " 'non': 589,\n",
              " 'logic': 590,\n",
              " 'wednesday': 591,\n",
              " 'cc': 592,\n",
              " 'summer': 593,\n",
              " 'please': 594,\n",
              " 'historical': 595,\n",
              " 'movement': 596,\n",
              " 'income': 597,\n",
              " 'good': 598,\n",
              " 'business': 599,\n",
              " 'must': 600,\n",
              " 'th': 601,\n",
              " 'card': 602,\n",
              " 'stock': 603,\n",
              " 'l': 604,\n",
              " 'week': 605,\n",
              " 'attached': 606,\n",
              " 'whether': 607,\n",
              " 'rather': 608,\n",
              " 'new': 609,\n",
              " 'news': 610,\n",
              " 'others': 611,\n",
              " 'total': 612,\n",
              " 'energy': 613,\n",
              " 'left': 614,\n",
              " 'final': 615,\n",
              " 'bill': 616,\n",
              " 'receive': 617,\n",
              " 'although': 618,\n",
              " 'government': 619,\n",
              " 'based': 620,\n",
              " 'hour': 621,\n",
              " 'school': 622,\n",
              " 'york': 623,\n",
              " 'two': 624,\n",
              " 'source': 625,\n",
              " 'subscription': 626,\n",
              " 'uk': 627,\n",
              " 'account': 628,\n",
              " 'stop': 629,\n",
              " 'message': 630,\n",
              " '2002': 631,\n",
              " 'content': 632,\n",
              " 'includes': 633,\n",
              " 'sale': 634,\n",
              " 'else': 635,\n",
              " 'best': 636,\n",
              " 'group': 637,\n",
              " 'university': 638,\n",
              " 'story': 639,\n",
              " 'room': 640,\n",
              " 'p': 641,\n",
              " 'letter': 642,\n",
              " '100': 643,\n",
              " 'update': 644,\n",
              " 'verb': 645,\n",
              " 'query': 646,\n",
              " 'canada': 647,\n",
              " 'real': 648,\n",
              " 'deal': 649,\n",
              " '00': 650,\n",
              " 'office': 651,\n",
              " 'system': 652,\n",
              " 'purchase': 653,\n",
              " 'server': 654,\n",
              " 'request': 655,\n",
              " 'standard': 656,\n",
              " '1998': 657,\n",
              " 'going': 658,\n",
              " 'sign': 659,\n",
              " 'time': 660,\n",
              " 'site': 661,\n",
              " 'sent': 662,\n",
              " 'send': 663,\n",
              " 'go': 664,\n",
              " 'large': 665,\n",
              " 'length': 666,\n",
              " 'programme': 667,\n",
              " 'pre': 668,\n",
              " 'dr': 669,\n",
              " 'b': 670,\n",
              " 'remember': 671,\n",
              " 'get': 672,\n",
              " 'talk': 673,\n",
              " 'address': 674,\n",
              " 'analysis': 675,\n",
              " 'review': 676,\n",
              " 'industry': 677,\n",
              " 'record': 678,\n",
              " 'learn': 679,\n",
              " 'houston': 680,\n",
              " '03': 681,\n",
              " 'friend': 682,\n",
              " '23': 683,\n",
              " 'processing': 684,\n",
              " 'august': 685,\n",
              " 'ã': 686,\n",
              " 'workshop': 687,\n",
              " 'mind': 688,\n",
              " 'question': 689,\n",
              " 'man': 690,\n",
              " 'reply': 691,\n",
              " 'security': 692,\n",
              " 'come': 693,\n",
              " 'document': 694,\n",
              " 'john': 695,\n",
              " 'even': 696,\n",
              " 'applied': 697,\n",
              " 'form': 698,\n",
              " 'right': 699,\n",
              " 'texas': 700,\n",
              " 'said': 701,\n",
              " 'something': 702,\n",
              " 'ï': 703,\n",
              " 'bank': 704,\n",
              " 'technology': 705,\n",
              " 'reference': 706,\n",
              " 'every': 707,\n",
              " 'lunch': 708,\n",
              " 'december': 709,\n",
              " '3': 710,\n",
              " 'paul': 711,\n",
              " 'report': 712,\n",
              " 'enough': 713,\n",
              " 'mr': 714,\n",
              " 'service': 715,\n",
              " '90': 716,\n",
              " 'tool': 717,\n",
              " 'data': 718,\n",
              " 'got': 719,\n",
              " 'study': 720,\n",
              " 'teaching': 721,\n",
              " 'opportunity': 722,\n",
              " 'making': 723,\n",
              " 'country': 724,\n",
              " 'last': 725,\n",
              " 'vowel': 726,\n",
              " 'natural': 727,\n",
              " 'doe': 728,\n",
              " 'everyone': 729,\n",
              " 'subject': 730,\n",
              " 'enron': 731,\n",
              " 'key': 732,\n",
              " 'english': 733,\n",
              " 'listinfo': 734,\n",
              " 'another': 735,\n",
              " 'forwarded': 736,\n",
              " 'mark': 737,\n",
              " 'month': 738,\n",
              " 'used': 739,\n",
              " 'dollar': 740,\n",
              " 'president': 741,\n",
              " 'basis': 742,\n",
              " '35': 743,\n",
              " 'f': 744,\n",
              " 'well': 745,\n",
              " 'main': 746,\n",
              " 'local': 747,\n",
              " 'publication': 748,\n",
              " 'risk': 749,\n",
              " 'global': 750,\n",
              " 'chair': 751,\n",
              " '02': 752,\n",
              " 'regard': 753,\n",
              " 'index': 754,\n",
              " 'third': 755,\n",
              " 'copyright': 756,\n",
              " 'rule': 757,\n",
              " 'w': 758,\n",
              " 'effect': 759,\n",
              " 'resource': 760,\n",
              " 'r': 761,\n",
              " 'instruction': 762,\n",
              " 'program': 763,\n",
              " 'construction': 764,\n",
              " 'point': 765,\n",
              " '12': 766,\n",
              " 'child': 767,\n",
              " 'complete': 768,\n",
              " 'experience': 769,\n",
              " 'provide': 770,\n",
              " 'life': 771,\n",
              " 'past': 772,\n",
              " 'discourse': 773,\n",
              " 'use': 774,\n",
              " 'due': 775,\n",
              " 'development': 776,\n",
              " 'welcome': 777,\n",
              " '8': 778,\n",
              " 'gas': 779,\n",
              " '1994': 780,\n",
              " 'rate': 781,\n",
              " 'context': 782,\n",
              " 'theoretical': 783,\n",
              " '09': 784,\n",
              " 'information': 785,\n",
              " 'translation': 786,\n",
              " 'million': 787,\n",
              " 'agreement': 788,\n",
              " 'someone': 789,\n",
              " 'provided': 790,\n",
              " 'whole': 791,\n",
              " 'set': 792,\n",
              " 'social': 793,\n",
              " 'lexical': 794,\n",
              " 'september': 795,\n",
              " 'text': 796,\n",
              " 'speaker': 797,\n",
              " '19': 798,\n",
              " 'theme': 799,\n",
              " 'summary': 800,\n",
              " 'better': 801}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_to_index_mapping = {t:i for t, i in zip(features, range(len(features)))}\n",
        "token_to_index_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE6xAzIN7DY5",
        "outputId": "d8ec86ba-ea77-4e9b-b0c0-53781febc50f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['3d', 'b', 'br', 'com', 'bad', 'font', 'font', 'com', 'randoms']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message_to_token_list('3d b <br> .com bad font font com randoms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OuXO-Cjf4vNo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# \"Bag of Words\" (counts vector)\n",
        "\n",
        "# ->  http  tr  size  3d  font  br  com  td   p   b\n",
        "# ->    0    1    2    3   4    5    6    7   8   9\n",
        "# ->   [0,   0,   0,   1,  2,   1,   2,   0,  0,  1]\n",
        "\n",
        "[0.,  0.,  0.,   1., 2.,  1., 2.,  0., 0., 1.]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ3kBFPW7vpm",
        "outputId": "3280787f-4a7f-4ed2-8836-5d3152393809"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0.])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def message_to_count_vector(message):\n",
        "  count_vector = np.zeros(len(features))\n",
        "\n",
        "  processed_list_of_tokens = message_to_token_list(message)\n",
        "\n",
        "  for token in processed_list_of_tokens:\n",
        "    if token not in features:\n",
        "      continue\n",
        "    index = token_to_index_mapping[token]\n",
        "    count_vector[index] += 1\n",
        "\n",
        "  return count_vector\n",
        "\n",
        "message_to_count_vector('3d b <br> .com bad font font com randoms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvnPzPqN_kWU",
        "outputId": "2af5915b-12dd-4b9f-b40f-0eacbc4ef2ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 3., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0.])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message_to_count_vector(train_df['MESSAGE'].iloc[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We7My4so_y4P",
        "outputId": "ecdfd9ac-38a6-40be-c22e-baf528a44839"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SERIAL                                                  15029\n",
              "MESSAGE     reimbursement of individually billed items the...\n",
              "CATEGORY                                                    0\n",
              "Name: 3, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.iloc[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "w3V5tgVbB_9K"
      },
      "outputs": [],
      "source": [
        "def df_to_X_y(dff):\n",
        "  y = dff['CATEGORY'].to_numpy().astype(int)\n",
        "\n",
        "  message_col = dff['MESSAGE']\n",
        "  count_vectors = []\n",
        "\n",
        "  for message in message_col:\n",
        "    count_vector = message_to_count_vector(message)\n",
        "    count_vectors.append(count_vector)\n",
        "\n",
        "  X = np.array(count_vectors).astype(int)\n",
        "\n",
        "  return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1AB_Ehd_18I",
        "outputId": "ac1da35b-3721-441f-a386-efd12e084422"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((14907, 802), (14907,), (3727, 802), (3727,))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, y_train = df_to_X_y(train_df)\n",
        "\n",
        "X_test, y_test = df_to_X_y(test_df)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "243hURJZC7pt",
        "outputId": "843808cf-2f87-43bc-8d18-f41d8f6abc6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.00074074, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "\n",
        "X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)\n",
        "\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fuadn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# **TF-IDF Feature Extraction**\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def custom_tokenizer(message):\n",
        "    return message_to_token_list(message)\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer)\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['MESSAGE'])\n",
        "\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_df['MESSAGE'])\n",
        "\n",
        "y_train_tfidf = train_df['CATEGORY'].to_numpy().astype(int)\n",
        "y_test_tfidf = test_df['CATEGORY'].to_numpy().astype(int)\n",
        "\n",
        "\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "X_train_tfidf_dense = X_train_tfidf.toarray()\n",
        "\n",
        "# View the dense matrix (first 5 rows, for example)\n",
        "print(X_train_tfidf_dense[:1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word Vector Feature Matrix Shapes:\n",
            "Training Set: (14907, 100)\n",
            "Test Set: (3727, 100)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Prepare tokenized sentences from the training data\n",
        "train_sentences = [message_to_token_list(msg) for msg in train_df['MESSAGE'] if isinstance(msg, str)]\n",
        "test_sentences = [message_to_token_list(msg) for msg in test_df['MESSAGE'] if isinstance(msg, str)]\n",
        "\n",
        "# Train a Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4, seed=1)\n",
        "\n",
        "# Function to convert a message to a Word2Vec vector (averaged over all tokens)\n",
        "def message_to_wv_vector(message, model, vector_size):\n",
        "    tokens = message_to_token_list(message)\n",
        "    vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
        "    if len(vectors) == 0:  # If no tokens are found in the model, return a zero vector\n",
        "        return np.zeros(vector_size)\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "# Extract Word2Vec features for training and test sets\n",
        "vector_size = word2vec_model.vector_size\n",
        "wv_X_train = np.array([message_to_wv_vector(msg, word2vec_model, vector_size) for msg in train_df['MESSAGE']])\n",
        "wv_X_test = np.array([message_to_wv_vector(msg, word2vec_model, vector_size) for msg in test_df['MESSAGE']])\n",
        "\n",
        "# Labels remain the same\n",
        "wv_y_train = train_df['CATEGORY'].to_numpy().astype(int)\n",
        "wv_y_test = test_df['CATEGORY'].to_numpy().astype(int)\n",
        "\n",
        "# Verify the shape of the feature matrices\n",
        "print(\"Word Vector Feature Matrix Shapes:\")\n",
        "print(\"Training Set:\", wv_X_train.shape)\n",
        "print(\"Test Set:\", wv_X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hybrid Train Feature Shape: (14907, 144809)\n",
            "Hybrid Test Feature Shape: (3727, 144809)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Combine TF-IDF and Word Vectors into a hybrid feature\n",
        "hybrid_X_train = hstack([X_train_tfidf, wv_X_train])\n",
        "hybrid_X_test = hstack([X_test_tfidf, wv_X_test])\n",
        "\n",
        "# Ensure the data is in dense format if needed for certain classifiers\n",
        "hybrid_X_train = hybrid_X_train.toarray()\n",
        "hybrid_X_test = hybrid_X_test.toarray()\n",
        "\n",
        "print(f\"Hybrid Train Feature Shape: {hybrid_X_train.shape}\")\n",
        "print(f\"Hybrid Test Feature Shape: {hybrid_X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptZ2wUTxD1MF",
        "outputId": "b960271b-8777-4950-f2ec-0e6109446812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6209    0.9956    0.7648      2265\n",
            "           1     0.8947    0.0581    0.1092      1462\n",
            "\n",
            "    accuracy                         0.6279      3727\n",
            "   macro avg     0.7578    0.5269    0.4370      3727\n",
            "weighted avg     0.7283    0.6279    0.5076      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression using Bag of Words Feature Extraction\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "lr = LogisticRegression().fit(X_train, y_train)\n",
        "print(classification_report(y_test, lr.predict(X_test), digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZK0jMUSEOCi",
        "outputId": "578ad022-7481-43d7-a74e-a38a3afc89cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9716    0.9523    0.9619      2265\n",
            "           1     0.9283    0.9569    0.9424      1462\n",
            "\n",
            "    accuracy                         0.9541      3727\n",
            "   macro avg     0.9500    0.9546    0.9521      3727\n",
            "weighted avg     0.9546    0.9541    0.9542      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Compare logistic regression to random forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "rf = RandomForestClassifier().fit(X_train, y_train)\n",
        "print(classification_report(y_test, rf.predict(X_test), digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fuadn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:37:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9820    0.9417    0.9615      2265\n",
            "           1     0.9151    0.9733    0.9433      1462\n",
            "\n",
            "    accuracy                         0.9541      3727\n",
            "   macro avg     0.9486    0.9575    0.9524      3727\n",
            "weighted avg     0.9558    0.9541    0.9543      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "xgb_bow = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "xgb_bow.fit(X_train, y_train)\n",
        "\n",
        "xgb_predictions_bow = xgb_bow.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, xgb_predictions_bow, digits=4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### TF_IDF EXTRACTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3vhIALXMEkb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9820    0.9651    0.9735      2265\n",
            "           1     0.9474    0.9726    0.9598      1462\n",
            "\n",
            "    accuracy                         0.9681      3727\n",
            "   macro avg     0.9647    0.9689    0.9667      3727\n",
            "weighted avg     0.9684    0.9681    0.9681      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# **Logistic Regression Training and Evaluation**\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train_tfidf, y_train_tfidf)\n",
        "\n",
        "lr_predictions = lr_model.predict(X_test_tfidf)\n",
        "\n",
        "print(classification_report(y_test_tfidf, lr_predictions, digits=4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9750    0.9638    0.9694      2265\n",
            "           1     0.9449    0.9617    0.9532      1462\n",
            "\n",
            "    accuracy                         0.9630      3727\n",
            "   macro avg     0.9599    0.9627    0.9613      3727\n",
            "weighted avg     0.9632    0.9630    0.9630      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# **Random Forest Training and Evaluation**\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train_tfidf, y_train_tfidf)\n",
        "\n",
        "rf_predictions = rf_model.predict(X_test_tfidf)\n",
        "\n",
        "print(classification_report(y_test_tfidf, rf_predictions, digits=4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fuadn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:37:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9854    0.9519    0.9683      2265\n",
            "           1     0.9292    0.9781    0.9530      1462\n",
            "\n",
            "    accuracy                         0.9622      3727\n",
            "   macro avg     0.9573    0.9650    0.9607      3727\n",
            "weighted avg     0.9633    0.9622    0.9623      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import the XGBoost model\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "xgb_model.fit(X_train_tfidf, y_train_tfidf)\n",
        "\n",
        "xgb_predictions = xgb_model.predict(X_test_tfidf)\n",
        "\n",
        "print(classification_report(y_test_tfidf, xgb_predictions, digits=4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Word Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9601    0.9448    0.9524      2265\n",
            "           1     0.9166    0.9391    0.9277      1462\n",
            "\n",
            "    accuracy                         0.9426      3727\n",
            "   macro avg     0.9383    0.9420    0.9400      3727\n",
            "weighted avg     0.9430    0.9426    0.9427      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "wv_lr_model = LogisticRegression().fit(wv_X_train, wv_y_train)\n",
        "wv_predictions = wv_lr_model.predict(wv_X_test)\n",
        "\n",
        "print(classification_report(wv_y_test, wv_predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9662    0.9603    0.9632      2265\n",
            "           1     0.9390    0.9480    0.9435      1462\n",
            "\n",
            "    accuracy                         0.9555      3727\n",
            "   macro avg     0.9526    0.9541    0.9534      3727\n",
            "weighted avg     0.9556    0.9555    0.9555      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "rf_wv_model = RandomForestClassifier(random_state=1)\n",
        "rf_wv_model.fit(wv_X_train, wv_y_train)\n",
        "\n",
        "rf_wv_predictions = rf_wv_model.predict(wv_X_test)\n",
        "\n",
        "print(classification_report(wv_y_test, rf_wv_predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fuadn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:38:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9749    0.9616    0.9682      2265\n",
            "           1     0.9417    0.9617    0.9516      1462\n",
            "\n",
            "    accuracy                         0.9616      3727\n",
            "   macro avg     0.9583    0.9616    0.9599      3727\n",
            "weighted avg     0.9619    0.9616    0.9617      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "xgb_wv_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=1)\n",
        "xgb_wv_model.fit(wv_X_train, wv_y_train)\n",
        "\n",
        "xgb_wv_predictions = xgb_wv_model.predict(wv_X_test)\n",
        "\n",
        "print(classification_report(wv_y_test, xgb_wv_predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Hybrid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9726    0.9558    0.9642      2265\n",
            "           1     0.9334    0.9583    0.9457      1462\n",
            "\n",
            "    accuracy                         0.9568      3727\n",
            "   macro avg     0.9530    0.9571    0.9549      3727\n",
            "weighted avg     0.9572    0.9568    0.9569      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "lr_hybrid_model = LogisticRegression()\n",
        "lr_hybrid_model.fit(hybrid_X_train, y_train_tfidf)\n",
        "\n",
        "lr_hybrid_predictions = lr_hybrid_model.predict(hybrid_X_test)\n",
        "print(classification_report(y_test_tfidf, lr_hybrid_predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9699    0.9669    0.9684      2265\n",
            "           1     0.9489    0.9535    0.9512      1462\n",
            "\n",
            "    accuracy                         0.9616      3727\n",
            "   macro avg     0.9594    0.9602    0.9598      3727\n",
            "weighted avg     0.9617    0.9616    0.9616      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "rf_hybrid_model = RandomForestClassifier()\n",
        "rf_hybrid_model.fit(hybrid_X_train, y_train_tfidf)\n",
        "\n",
        "rf_hybrid_predictions = rf_hybrid_model.predict(hybrid_X_test)\n",
        "print(classification_report(y_test_tfidf, rf_hybrid_predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fuadn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:17:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Classification Report (Hybrid Features):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9816    0.9660    0.9737      2265\n",
            "           1     0.9486    0.9720    0.9601      1462\n",
            "\n",
            "    accuracy                         0.9683      3727\n",
            "   macro avg     0.9651    0.9690    0.9669      3727\n",
            "weighted avg     0.9687    0.9683    0.9684      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "xgb_hybrid_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_hybrid_model.fit(hybrid_X_train, y_train_tfidf)\n",
        "\n",
        "xgb_hybrid_predictions = xgb_hybrid_model.predict(hybrid_X_test)\n",
        "print(\"XGBoost Classification Report (Hybrid Features):\\n\")\n",
        "print(classification_report(y_test_tfidf, xgb_hybrid_predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4978 - loss: 0.9132 - val_accuracy: 0.4970 - val_loss: 0.7385 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4964 - loss: 0.7438 - val_accuracy: 0.4975 - val_loss: 0.7143 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4995 - loss: 0.7170 - val_accuracy: 0.4975 - val_loss: 0.7208 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4958 - loss: 0.7164 - val_accuracy: 0.4975 - val_loss: 0.7126 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4902 - loss: 0.7061 - val_accuracy: 0.4975 - val_loss: 0.7140 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4935 - loss: 0.7052 - val_accuracy: 0.4975 - val_loss: 0.7073 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4828 - loss: 0.7052 - val_accuracy: 0.4975 - val_loss: 0.7245 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4878 - loss: 0.7053 - val_accuracy: 0.4975 - val_loss: 0.7088 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4997 - loss: 0.7043\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4996 - loss: 0.7044 - val_accuracy: 0.4975 - val_loss: 0.7124 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4882 - loss: 0.7036 - val_accuracy: 0.4975 - val_loss: 0.7145 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4863 - loss: 0.7038 - val_accuracy: 0.4975 - val_loss: 0.7150 - learning_rate: 5.0000e-04\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "\n",
        "def build_improved_cnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        # First Convolutional Block - smaller number of filters\n",
        "        layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Dropout(0.1),\n",
        "        \n",
        "        # Second Convolutional Block - moderate increase in filters\n",
        "        layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.GlobalMaxPooling1D(),  # Changed to Global Max Pooling\n",
        "        layers.Dropout(0.1),\n",
        "        \n",
        "        # Dense Layers - simplified\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Data preparation improvements\n",
        "def prepare_data(X_train, X_test, y_train, y_test, max_features=10000):\n",
        "    # If working with raw text, consider using TextVectorization\n",
        "    vectorizer = tf.keras.layers.TextVectorization(\n",
        "        max_tokens=max_features,\n",
        "        output_sequence_length=X_train.shape[1]\n",
        "    )\n",
        "    \n",
        "    # Normalize features using standardization instead of MinMax\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Reshape for CNN\n",
        "    X_train_reshaped = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1)\n",
        "    X_test_reshaped = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1)\n",
        "    \n",
        "    # Convert labels\n",
        "    y_train_cat = tf.keras.utils.to_categorical(y_train)\n",
        "    y_test_cat = tf.keras.utils.to_categorical(y_test)\n",
        "    \n",
        "    return X_train_reshaped, X_test_reshaped, y_train_cat, y_test_cat\n",
        "\n",
        "# Training setup\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "\n",
        "# Create data generator with larger buffer\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_reshaped, y_train_cat))\\\n",
        "    .shuffle(buffer_size=len(X_train_reshaped))\\\n",
        "    .batch(BATCH_SIZE)\\\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_reshaped, y_test_cat))\\\n",
        "    .batch(BATCH_SIZE)\\\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Initialize and compile model\n",
        "input_shape = (X_train_reshaped.shape[1], 1)\n",
        "num_classes = y_train_cat.shape[1]\n",
        "model = build_improved_cnn_model(input_shape, num_classes)\n",
        "\n",
        "# Use a custom learning rate\n",
        "initial_learning_rate = 0.001\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Improved callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train with class weights if dataset is imbalanced\n",
        "class_weights = None\n",
        "if len(np.unique(y_train)) == 2:\n",
        "    total = len(y_train)\n",
        "    neg = np.sum(y_train == 0)\n",
        "    pos = np.sum(y_train == 1)\n",
        "    class_weights = {0: total/(2.0 * neg), 1: total/(2.0 * pos)}\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

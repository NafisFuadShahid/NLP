{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "a-YrFyW2cn_n",
        "outputId": "975995fc-b85b-4cb7-ea3c-364ae1e4508e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SERIAL</th>\n",
              "      <th>MESSAGE</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>re : 6 . 1100 , disc : uniformitarianism , re ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the other side of * galicismos * * galicismo *...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>re : equistar deal tickets are you still avail...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\\r\\nHello I am your hot lil horny toy.\\r\\n    ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>software at incredibly low prices ( 86 % lower...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SERIAL                                            MESSAGE  CATEGORY\n",
              "0       0  re : 6 . 1100 , disc : uniformitarianism , re ...         0\n",
              "1       1  the other side of * galicismos * * galicismo *...         0\n",
              "2       2  re : equistar deal tickets are you still avail...         0\n",
              "3       3  \\r\\nHello I am your hot lil horny toy.\\r\\n    ...         1\n",
              "4       4  software at incredibly low prices ( 86 % lower...         1"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the dataset (https://www.kaggle.com/chandramoulinaidu/spam-classification-for-basic-nlp)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Phishing_Email.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "5Brt9s9rkKYb",
        "outputId": "1b8fb1a7-af4c-4893-fead-eb71c0c887d7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SERIAL</th>\n",
              "      <th>MESSAGE</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18629</th>\n",
              "      <td>18646</td>\n",
              "      <td>date a lonely housewife always wanted to date ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18630</th>\n",
              "      <td>18647</td>\n",
              "      <td>request submitted : access request for anita ....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18631</th>\n",
              "      <td>18648</td>\n",
              "      <td>re : important - prc mtg hi dorn &amp; john , as y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18632</th>\n",
              "      <td>18649</td>\n",
              "      <td>press clippings - letter on californian utilit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18633</th>\n",
              "      <td>18650</td>\n",
              "      <td>empty</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       SERIAL                                            MESSAGE  CATEGORY\n",
              "18629   18646  date a lonely housewife always wanted to date ...         1\n",
              "18630   18647  request submitted : access request for anita ....         0\n",
              "18631   18648  re : important - prc mtg hi dorn & john , as y...         0\n",
              "18632   18649  press clippings - letter on californian utilit...         0\n",
              "18633   18650                                              empty         1"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BZJ1xgHkOOy",
        "outputId": "19b2cb60-3334-41d5-969c-6fb0fea4846f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CATEGORY\n",
              "0    11322\n",
              "1     7312\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['CATEGORY'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUoCyp8mkXsh",
        "outputId": "7bcfa229-8c68-46d0-f672-325c73c0b020"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\fuadn\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\fuadn\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWa64YhklKeT",
        "outputId": "9c407065-d1dd-46d7-d3e2-a0af97be6cfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hey',\n",
              " 'GGggGG',\n",
              " 'feet',\n",
              " 'it',\n",
              " 'going',\n",
              " 'HTML',\n",
              " 'bads',\n",
              " 'bads',\n",
              " 'randoms',\n",
              " 'badly']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "test_message = \"Hey,, GGggGG feet it going? <HTML><bads> bads 'randoms' badly\"\n",
        "\n",
        "test_message_tokenized = tokenizer.tokenize(test_message)\n",
        "test_message_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts46HslRmwlB",
        "outputId": "d48edd5e-a828-4374-bf86-7c9f4157da35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hey',\n",
              " 'gggggg',\n",
              " 'feet',\n",
              " 'it',\n",
              " 'going',\n",
              " 'html',\n",
              " 'bads',\n",
              " 'bads',\n",
              " 'randoms',\n",
              " 'badly']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_message_lowercased = [t.lower() for t in test_message_tokenized]\n",
        "test_message_lowercased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZfXmuvUn3dy",
        "outputId": "23a3a78a-c9d9-4c6d-d0ff-fa122304f23d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hey',\n",
              " 'gggggg',\n",
              " 'foot',\n",
              " 'it',\n",
              " 'going',\n",
              " 'html',\n",
              " 'bad',\n",
              " 'bad',\n",
              " 'randoms',\n",
              " 'badly']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "test_message_lemmatized_tokens = [lemmatizer.lemmatize(t) for t in test_message_lowercased]\n",
        "test_message_lemmatized_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG06k4ags0al",
        "outputId": "1fab4508-e4ad-4be7-b32d-cbb2983c02df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hey', 'gggggg', 'foot', 'going', 'html', 'bad', 'bad', 'randoms', 'badly']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "test_message_useful_tokens = [t for t in test_message_lemmatized_tokens if t not in stopwords]\n",
        "test_message_useful_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtNehJ51t6Ii",
        "outputId": "8dac74a6-f061-4fc9-a0ad-22bdf637af02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hey', 'gggggg', 'foot', 'going', 'html', 'bad', 'bad', 'randoms', 'badly']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def message_to_token_list(s):\n",
        "  tokens = tokenizer.tokenize(s)\n",
        "  lowercased_tokens = [t.lower() for t in tokens]\n",
        "  lemmatized_tokens = [lemmatizer.lemmatize(t) for t in lowercased_tokens]\n",
        "  useful_tokens = [t for t in lemmatized_tokens if t not in stopwords]\n",
        "\n",
        "  return useful_tokens\n",
        "\n",
        "message_to_token_list(test_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_InW_NurvEqq",
        "outputId": "5510f999-7e20-4d6d-8b2b-02970916b041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (14907, 3)\n",
            "Test shape: (3727, 3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(       SERIAL                                            MESSAGE  CATEGORY\n",
              " 0         128  blue horseshoe meet me dear reader : we someti...         1\n",
              " 1        4205  the national association for honesty in medici...         1\n",
              " 2        7943  web pages load 300 % faster without cable or d...         1\n",
              " 3       15029  reimbursement of individually billed items the...         0\n",
              " 4         609  lp deal bill - please come see me this morning...         0\n",
              " ...       ...                                                ...       ...\n",
              " 14902    1175  200 summary on reduplication a month before ch...         0\n",
              " 14903   11581  \\r\\nYannick Gingras wrote:>    I am wondering ...         0\n",
              " 14904   13132  URL: http://www.newsisfree.com/click/215,9,215...         0\n",
              " 14905    3430  global operations controller forum i believe n...         0\n",
              " 14906   11247  electronic pay stubs get ready . beginning in ...         0\n",
              " \n",
              " [14907 rows x 3 columns],\n",
              "       SERIAL                                            MESSAGE  CATEGORY\n",
              " 0       6208  super saturday info sally , i received your vo...         0\n",
              " 1       2817  it ' s cheating , but it works ! can you guess...         1\n",
              " 2        485  t id ( aa29536 @ julius . ling . ohio-state . ...         0\n",
              " 3       2352  global risk management operations recognizing ...         0\n",
              " 4      17190  expert web site analysis - at no charge do you...         1\n",
              " ...      ...                                                ...       ...\n",
              " 3722    3805  schedule going real time for june 1 this sched...         0\n",
              " 3723    9880  bi - weekly transmission update report energy ...         0\n",
              " 3724   10777  \\r\\nWant To Be Your Own Boss? Â  Train Now Wit...         1\n",
              " 3725   12862  activities 1 . receivables backed finance : ti...         0\n",
              " 3726   11058  H1 { } TD {  FONT-SIZE: 12px; FONT-FAMILY: Ari...         1\n",
              " \n",
              " [3727 rows x 3 columns])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,         # 20% of data will go to the test set\n",
        "    stratify=df['CATEGORY'], # Ensures proportional class distribution\n",
        "    random_state=1         # Ensures reproducibility\n",
        ")\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "print(f\"Test shape: {test_df.shape}\")\n",
        "\n",
        "train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwUuMr_0waAu",
        "outputId": "14ab0468-fdff-455f-e6a0-aebbcb7102a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "144709"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "token_counter = {}\n",
        "\n",
        "# Iterate over each message in the 'MESSAGE' column\n",
        "for message in train_df['MESSAGE']:\n",
        "    if isinstance(message, str):  # Check if message is a string\n",
        "        message_as_token_lst = message_to_token_list(message)  # Convert message to a list of tokens\n",
        "\n",
        "        # Count occurrences of each token\n",
        "        for token in message_as_token_lst:\n",
        "            if token in token_counter:\n",
        "                token_counter[token] += 1\n",
        "            else:\n",
        "                token_counter[token] = 1\n",
        "\n",
        "len(token_counter)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubi91FlbyfXJ",
        "outputId": "1ed3962a-61fd-4b1f-fd80-b3a7322438b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'blue': 228,\n",
              " 'horseshoe': 3,\n",
              " 'meet': 897,\n",
              " 'dear': 1137,\n",
              " 'reader': 878,\n",
              " 'sometimes': 434,\n",
              " 'approach': 2218,\n",
              " 'analyst': 1128,\n",
              " 'thought': 1316,\n",
              " 'emerging': 216,\n",
              " 'market': 3782,\n",
              " 'sector': 275,\n",
              " 'interested': 2324,\n",
              " 'certain': 1138,\n",
              " 'occasion': 159,\n",
              " 'come': 3012,\n",
              " 'u': 13191,\n",
              " 'intriguing': 49,\n",
              " 'insight': 264,\n",
              " 'aspect': 1778,\n",
              " 'caught': 105,\n",
              " 'attention': 853,\n",
              " 'know': 6021,\n",
              " 'track': 776,\n",
              " 'record': 1079,\n",
              " 'speaks': 80,\n",
              " 'happy': 751,\n",
              " 'bring': 907,\n",
              " 'another': 2189,\n",
              " 'situation': 893,\n",
              " 'huge': 608,\n",
              " 'upside': 52,\n",
              " 'potential': 1175,\n",
              " 'think': 3385,\n",
              " 'could': 5083,\n",
              " 'one': 14148,\n",
              " 'look': 2802,\n",
              " 'back': 3019,\n",
              " 'shortly': 175,\n",
              " 'everyone': 1038,\n",
              " 'saying': 530,\n",
              " 'info': 1714,\n",
              " 'click': 3821,\n",
              " 'remember': 1191,\n",
              " 'nothing': 1158,\n",
              " 'ventured': 7,\n",
              " 'gained': 144,\n",
              " 'national': 1589,\n",
              " 'association': 1114,\n",
              " 'honesty': 56,\n",
              " 'medicine': 191,\n",
              " 'stemcaoiwz': 1,\n",
              " 'body': 833,\n",
              " 'many': 4857,\n",
              " 'cry': 65,\n",
              " 'water': 445,\n",
              " 'dr': 1865,\n",
              " 'f': 2039,\n",
              " 'batmanghelidj': 2,\n",
              " 'title': 2118,\n",
              " 'multi': 1165,\n",
              " 'book': 4659,\n",
              " 'say': 3315,\n",
              " 'found': 1960,\n",
              " 'bookstore': 46,\n",
              " 'amazon': 83,\n",
              " 'com': 18232,\n",
              " 'view': 1683,\n",
              " 'expose': 63,\n",
              " 'scheming': 1,\n",
              " 'tactic': 49,\n",
              " 'government': 1680,\n",
              " 'pharmaceutical': 109,\n",
              " 'industry': 1308,\n",
              " 'keep': 1737,\n",
              " 'human': 1763,\n",
              " 'sick': 99,\n",
              " 'care': 621,\n",
              " 'system': 7288,\n",
              " 'perpetuate': 7,\n",
              " 'disease': 154,\n",
              " 'state': 5219,\n",
              " 'bodily': 10,\n",
              " 'condition': 791,\n",
              " 'effort': 1198,\n",
              " 'fund': 1343,\n",
              " 'mega': 98,\n",
              " 'sucked': 14,\n",
              " 'discover': 400,\n",
              " 'natural': 2475,\n",
              " 'substance': 101,\n",
              " 'make': 7313,\n",
              " 'phenomenal': 21,\n",
              " 'difference': 1008,\n",
              " 'health': 553,\n",
              " 'well': 4755,\n",
              " 'read': 2498,\n",
              " 'isbn': 506,\n",
              " '0': 12003,\n",
              " '9629942': 1,\n",
              " '3': 11956,\n",
              " '5': 9922,\n",
              " 'written': 1155,\n",
              " 'sincerely': 551,\n",
              " 'preceding': 133,\n",
              " 'advertisement': 719,\n",
              " 'wa': 13521,\n",
              " 'sent': 4191,\n",
              " 'virtue': 69,\n",
              " 'participation': 759,\n",
              " 'special': 3098,\n",
              " 'product': 3858,\n",
              " 'offering': 563,\n",
              " 'e': 17378,\n",
              " 'mail': 13109,\n",
              " 'networking': 175,\n",
              " 'service': 5287,\n",
              " 'partner': 934,\n",
              " 'unsubscribe': 1015,\n",
              " 'receiving': 846,\n",
              " 'email': 10715,\n",
              " 'please': 11884,\n",
              " 'web': 4624,\n",
              " 'page': 4264,\n",
              " 'load': 489,\n",
              " '300': 694,\n",
              " 'faster': 390,\n",
              " 'without': 2431,\n",
              " 'cable': 383,\n",
              " 'dsl': 73,\n",
              " 'named': 293,\n",
              " 'online': 2234,\n",
              " 'software': 3955,\n",
              " 'year': 7006,\n",
              " 'agi': 14,\n",
              " 'consultant': 194,\n",
              " 'free': 7127,\n",
              " '7': 4990,\n",
              " 'day': 6894,\n",
              " 'trial': 301,\n",
              " 'unique': 541,\n",
              " 'solution': 921,\n",
              " 'open': 1649,\n",
              " 'private': 915,\n",
              " 'high': 2230,\n",
              " 'speed': 543,\n",
              " 'network': 1671,\n",
              " 'connection': 753,\n",
              " 'required': 1567,\n",
              " 'amazed': 71,\n",
              " 'internet': 3973,\n",
              " 'provider': 507,\n",
              " 'perfect': 517,\n",
              " 'pc': 958,\n",
              " 'laptop': 159,\n",
              " 'dial': 260,\n",
              " 'modem': 200,\n",
              " 'testimonial': 147,\n",
              " '1': 19940,\n",
              " 'min': 278,\n",
              " 'download': 951,\n",
              " 'learn': 1095,\n",
              " 'get': 9118,\n",
              " 'permanently': 82,\n",
              " 'going': 2018,\n",
              " 'sign': 1263,\n",
              " 'want': 4530,\n",
              " '50': 4178,\n",
              " 'per': 2802,\n",
              " 'month': 3178,\n",
              " 'plus': 1465,\n",
              " 'pay': 1858,\n",
              " '120': 364,\n",
              " 'thecable': 1,\n",
              " 'paya': 1,\n",
              " 'guy': 704,\n",
              " 'hook': 77,\n",
              " 'rule': 1585,\n",
              " 'roger': 237,\n",
              " 'fromteaneck': 1,\n",
              " 'nj': 223,\n",
              " 'nice': 618,\n",
              " 'job': 1637,\n",
              " 'file': 3545,\n",
              " 'size': 1615,\n",
              " 'small': 1359,\n",
              " 'quick': 607,\n",
              " 'see': 5160,\n",
              " 'noticeable': 13,\n",
              " 'improvement': 384,\n",
              " 'access': 1939,\n",
              " 'recommending': 32,\n",
              " 'client': 784,\n",
              " 'computer': 3790,\n",
              " 'easy': 1874,\n",
              " 'use': 6902,\n",
              " 'raj': 22,\n",
              " 'patel': 36,\n",
              " 'address': 10179,\n",
              " 'obtained': 298,\n",
              " 'purchased': 253,\n",
              " 'list': 11541,\n",
              " 'reference': 2701,\n",
              " '172': 71,\n",
              " '54': 399,\n",
              " 'wish': 1781,\n",
              " 'request': 2255,\n",
              " 'honored': 60,\n",
              " 'http': 18867,\n",
              " 'xent': 659,\n",
              " 'mailman': 1637,\n",
              " 'listinfo': 2121,\n",
              " 'fork': 867,\n",
              " 'reimbursement': 30,\n",
              " 'individually': 88,\n",
              " 'billed': 42,\n",
              " 'item': 1058,\n",
              " 'memo': 131,\n",
              " 'distributed': 454,\n",
              " 'june': 1870,\n",
              " '27': 1771,\n",
              " 'requires': 438,\n",
              " 'clarification': 84,\n",
              " 'intent': 183,\n",
              " 'give': 2779,\n",
              " 'employee': 920,\n",
              " 'alternate': 152,\n",
              " 'method': 2142,\n",
              " 'paying': 354,\n",
              " 'pager': 42,\n",
              " 'cell': 486,\n",
              " 'phone': 3607,\n",
              " 'etc': 2812,\n",
              " 'continue': 1178,\n",
              " 'submit': 1367,\n",
              " 'invoice': 189,\n",
              " 'account': 2907,\n",
              " 'payable': 405,\n",
              " 'processing': 1831,\n",
              " 'corporate': 673,\n",
              " 'american': 2325,\n",
              " 'express': 697,\n",
              " 'card': 2425,\n",
              " 'expense': 577,\n",
              " 'report': 7879,\n",
              " 'either': 1795,\n",
              " 'way': 5024,\n",
              " 'acceptable': 293,\n",
              " 'process': 2674,\n",
              " 'dollar': 1789,\n",
              " 'volume': 2258,\n",
              " 'lp': 108,\n",
              " 'deal': 3377,\n",
              " 'bill': 1485,\n",
              " 'morning': 842,\n",
              " 'comment': 1609,\n",
              " 'suggestion': 533,\n",
              " 'end': 2345,\n",
              " 'thing': 2757,\n",
              " 'finish': 124,\n",
              " 'today': 3029,\n",
              " 'need': 5830,\n",
              " 'desk': 439,\n",
              " 'virginia': 263,\n",
              " 'hotlist': 20,\n",
              " 'update': 1291,\n",
              " '01': 3288,\n",
              " 'forgot': 83,\n",
              " 'attachment': 270,\n",
              " 'brillant': 1,\n",
              " 'original': 2516,\n",
              " 'message': 6044,\n",
              " 'mrha': 58,\n",
              " 'jean': 496,\n",
              " 'tuesday': 1041,\n",
              " 'may': 8950,\n",
              " '2001': 4414,\n",
              " '2': 14943,\n",
              " '29': 1671,\n",
              " 'pm': 2994,\n",
              " 'kitchen': 547,\n",
              " 'louise': 929,\n",
              " 'cc': 2837,\n",
              " 'jones': 1256,\n",
              " 'melissa': 151,\n",
              " 'schoppe': 71,\n",
              " 'tammie': 86,\n",
              " 'carter': 76,\n",
              " 'carol': 182,\n",
              " 'washington': 914,\n",
              " 'deanna': 12,\n",
              " 'subject': 11549,\n",
              " 'find': 3508,\n",
              " 'attached': 1174,\n",
              " 'revised': 366,\n",
              " 'upstream': 44,\n",
              " 'bridgeline': 43,\n",
              " 'augment': 17,\n",
              " 'transaction': 1535,\n",
              " 'sheet': 683,\n",
              " 'associated': 567,\n",
              " 'brian': 533,\n",
              " 'currently': 1262,\n",
              " 'meeting': 2440,\n",
              " 'next': 2809,\n",
              " 'week': 4608,\n",
              " 'version': 2223,\n",
              " 'include': 3278,\n",
              " 'strategy': 873,\n",
              " 'lrc': 7,\n",
              " 'crawfish': 5,\n",
              " 'asset': 1178,\n",
              " 'balance': 490,\n",
              " 'addition': 983,\n",
              " 'storage': 439,\n",
              " 'doe': 4145,\n",
              " 'monetization': 9,\n",
              " 'opportunity': 2397,\n",
              " 'utility': 737,\n",
              " 'pad': 32,\n",
              " 'gas': 2985,\n",
              " 'targeting': 66,\n",
              " 'jim': 481,\n",
              " 'steffes': 57,\n",
              " 'tomorrow': 428,\n",
              " 'paul': 1072,\n",
              " 'present': 1843,\n",
              " 'thursday': 1150,\n",
              " 'regard': 1549,\n",
              " 'credit': 3455,\n",
              " 'good': 3266,\n",
              " 'hey': 198,\n",
              " 'bruce': 306,\n",
              " 'guenter': 42,\n",
              " 'dyndns': 42,\n",
              " 'org': 2646,\n",
              " 'chosen': 190,\n",
              " 'participate': 839,\n",
              " 'invitation': 234,\n",
              " 'event': 2021,\n",
              " 'mortgage': 448,\n",
              " 'stop': 1412,\n",
              " 'help': 3285,\n",
              " 'lower': 510,\n",
              " 'answer': 1359,\n",
              " 'question': 4765,\n",
              " 'approved': 574,\n",
              " 'minute': 2307,\n",
              " 'simple': 1382,\n",
              " 'aynhgh': 2,\n",
              " '332': 28,\n",
              " '000': 7672,\n",
              " 'loan': 841,\n",
              " 'available': 4627,\n",
              " '238': 40,\n",
              " 'bad': 674,\n",
              " 'problem': 3509,\n",
              " 'saving': 530,\n",
              " 'money': 5661,\n",
              " 'time': 10521,\n",
              " 'ready': 1227,\n",
              " 'save': 1784,\n",
              " 'fill': 700,\n",
              " 'short': 1520,\n",
              " 'form': 4929,\n",
              " 'later': 1361,\n",
              " 'mayer': 41,\n",
              " 'r': 4328,\n",
              " 'tim': 424,\n",
              " 'vi': 290,\n",
              " 'mertensbreachye': 1,\n",
              " 'uymail': 2,\n",
              " 'twenty': 366,\n",
              " 'disappointed': 59,\n",
              " 'throw': 128,\n",
              " 'bowline': 7,\n",
              " 'sail': 31,\n",
              " 'away': 1042,\n",
              " 'safe': 430,\n",
              " 'harbor': 87,\n",
              " 'catch': 228,\n",
              " 'trade': 1390,\n",
              " 'wind': 248,\n",
              " 'explore': 247,\n",
              " 'dream': 460,\n",
              " 'mark': 1758,\n",
              " 'twain': 13,\n",
              " 'samuel': 111,\n",
              " 'langhornne': 5,\n",
              " 'clemens': 18,\n",
              " '1835': 14,\n",
              " '1910': 22,\n",
              " 'hear': 704,\n",
              " 'language': 22196,\n",
              " 'asked': 1145,\n",
              " 'every': 2711,\n",
              " 'pointing': 63,\n",
              " 'allowed': 307,\n",
              " 'spend': 328,\n",
              " 'noun': 849,\n",
              " 'program': 7353,\n",
              " 'talking': 619,\n",
              " 'full': 2563,\n",
              " 'sentence': 1254,\n",
              " 'staffed': 12,\n",
              " 'normal': 690,\n",
              " 'preschool': 16,\n",
              " 'missing': 253,\n",
              " 'surfing': 38,\n",
              " 'life': 2292,\n",
              " 'happiness': 93,\n",
              " 'success': 1173,\n",
              " 'able': 1693,\n",
              " 'others': 1622,\n",
              " 'absurd': 22,\n",
              " 'maddening': 3,\n",
              " 'claim': 1471,\n",
              " 'upon': 958,\n",
              " 'christopher': 255,\n",
              " 'darlington': 2,\n",
              " 'morley': 15,\n",
              " '1890': 34,\n",
              " '1957': 44,\n",
              " 'enjoying': 67,\n",
              " 'skiing': 8,\n",
              " 'among': 1089,\n",
              " 'tree': 428,\n",
              " 'moment': 530,\n",
              " 'picked': 112,\n",
              " 'patch': 177,\n",
              " 'cv': 350,\n",
              " 'eventually': 199,\n",
              " 'bug': 259,\n",
              " 'worth': 703,\n",
              " 'fixing': 33,\n",
              " 'let': 3139,\n",
              " 'fix': 217,\n",
              " 'scarborough': 6,\n",
              " 'said': 4821,\n",
              " 'tg': 14,\n",
              " 'sema': 7,\n",
              " 'se': 731,\n",
              " 'mscar': 1,\n",
              " 'biggest': 339,\n",
              " '_always_': 2,\n",
              " 'render': 53,\n",
              " 'html': 3400,\n",
              " 'possible': 2558,\n",
              " 'porno': 38,\n",
              " 'also': 8917,\n",
              " 'option': 1407,\n",
              " 'part': 3481,\n",
              " 'netscape': 218,\n",
              " 'might': 2294,\n",
              " 'fully': 618,\n",
              " 'featured': 350,\n",
              " 'viewer': 63,\n",
              " 'determine': 327,\n",
              " 'risk': 2455,\n",
              " 'try': 1509,\n",
              " 'two': 5624,\n",
              " 'exmh': 664,\n",
              " '07': 1002,\n",
              " '13': 2336,\n",
              " 'tossed': 15,\n",
              " 'together': 1370,\n",
              " 'config': 84,\n",
              " 'uri': 21,\n",
              " 'deferdisplaysinline': 1,\n",
              " 'probably': 1080,\n",
              " 'sense': 940,\n",
              " 'always': 1668,\n",
              " 'never': 1842,\n",
              " 'people': 7435,\n",
              " 'like': 7943,\n",
              " 'anyway': 369,\n",
              " 'text': 4044,\n",
              " 'defer': 13,\n",
              " 'selected': 743,\n",
              " 'display': 343,\n",
              " 'inline': 32,\n",
              " 'checking': 323,\n",
              " 'box': 1901,\n",
              " 'right': 4054,\n",
              " 'button': 339,\n",
              " 'menu': 167,\n",
              " 'tomas': 29,\n",
              " 'g': 3513,\n",
              " 'great': 2179,\n",
              " 'thank': 1907,\n",
              " 'exactly': 781,\n",
              " 'thinking': 495,\n",
              " 'best': 3590,\n",
              " 'whether': 1640,\n",
              " 'expressed': 332,\n",
              " 'couple': 573,\n",
              " 'coloring': 7,\n",
              " 'highlighting': 43,\n",
              " 'characterize': 39,\n",
              " 'yet': 1267,\n",
              " 'work': 7823,\n",
              " 'least': 2079,\n",
              " 'functionality': 106,\n",
              " 'ever': 1642,\n",
              " 'wanted': 730,\n",
              " 'choose': 718,\n",
              " 'internal': 507,\n",
              " 'engine': 639,\n",
              " 'whatever': 505,\n",
              " 'external': 280,\n",
              " 'browser': 352,\n",
              " 'defined': 271,\n",
              " 'basis': 1102,\n",
              " 'thanks': 3470,\n",
              " '_______________________________________________': 882,\n",
              " 'user': 3795,\n",
              " 'mailing': 3622,\n",
              " 'redhat': 568,\n",
              " 'listman': 138,\n",
              " 'brent': 143,\n",
              " 'welch': 56,\n",
              " 'architect': 81,\n",
              " 'panasas': 54,\n",
              " 'inc': 2824,\n",
              " 'pioneering': 37,\n",
              " 'world': 4141,\n",
              " 'scalable': 48,\n",
              " 'agile': 24,\n",
              " 'www': 11773,\n",
              " 'plan': 2258,\n",
              " 'b': 3762,\n",
              " 'smith': 667,\n",
              " 'approval': 547,\n",
              " 'go': 3818,\n",
              " 'would': 10902,\n",
              " 'extend': 235,\n",
              " 'offer': 3618,\n",
              " 'gary': 512,\n",
              " 'move': 1418,\n",
              " 'supported': 244,\n",
              " 'tom': 463,\n",
              " 'martin': 723,\n",
              " 'vickers': 35,\n",
              " 'tycholiz': 25,\n",
              " 'chi': 50,\n",
              " 'objection': 50,\n",
              " 'ryanair': 39,\n",
              " 'partnership': 944,\n",
              " 'primary': 455,\n",
              " 'insurance': 508,\n",
              " 'excellent': 386,\n",
              " 'value': 1617,\n",
              " 'travel': 883,\n",
              " 'â': 10890,\n",
              " '00gbp': 4,\n",
              " '9': 5701,\n",
              " '00': 12633,\n",
              " 'euro': 273,\n",
              " 'person': 1931,\n",
              " '31': 2088,\n",
              " 'cover': 1014,\n",
              " 'annual': 806,\n",
              " '45': 2121,\n",
              " '63': 209,\n",
              " 'includes': 1164,\n",
              " '24': 2159,\n",
              " 'winter': 247,\n",
              " 'sport': 278,\n",
              " 'provides': 770,\n",
              " 'standard': 1610,\n",
              " 'summary': 1437,\n",
              " 'medical': 433,\n",
              " 'million': 3660,\n",
              " 'personal': 1340,\n",
              " 'liability': 166,\n",
              " 'effect': 1235,\n",
              " 'baggage': 16,\n",
              " '750': 187,\n",
              " 'accident': 75,\n",
              " 'maximum': 389,\n",
              " 'benefit': 940,\n",
              " '15': 5930,\n",
              " 'hospital': 169,\n",
              " 'cancellation': 115,\n",
              " '500': 1492,\n",
              " 'curtailment': 29,\n",
              " 'delay': 334,\n",
              " '60': 1199,\n",
              " 'missed': 159,\n",
              " 'departure': 153,\n",
              " 'legal': 1352,\n",
              " '5000': 198,\n",
              " 'holiday': 355,\n",
              " 'abandonment': 11,\n",
              " '500all': 1,\n",
              " 'figure': 610,\n",
              " 'sterling': 249,\n",
              " 'poundsto': 1,\n",
              " 'policy': 965,\n",
              " 'primarytrade': 1,\n",
              " 'co': 2158,\n",
              " 'uk': 3997,\n",
              " 'internetsales': 1,\n",
              " 'call': 5936,\n",
              " 'direct': 1138,\n",
              " 'reservation': 376,\n",
              " '0871': 4,\n",
              " '246': 56,\n",
              " '0002': 4,\n",
              " '0818': 3,\n",
              " '304': 54,\n",
              " 'ireland': 213,\n",
              " 'rate': 2493,\n",
              " 'ongolf': 1,\n",
              " '19': 2472,\n",
              " 'passenger': 47,\n",
              " 'coverski': 1,\n",
              " '35': 1203,\n",
              " 'covercover': 1,\n",
              " 'habitual': 18,\n",
              " 'resident': 210,\n",
              " 'disclaimerthis': 5,\n",
              " 'transmitted': 66,\n",
              " 'confidential': 435,\n",
              " 'legally': 158,\n",
              " 'privileged': 103,\n",
              " 'intended': 830,\n",
              " 'solely': 116,\n",
              " 'recipient': 366,\n",
              " 'opinion': 667,\n",
              " 'individual': 1669,\n",
              " 'author': 2947,\n",
              " 'sender': 376,\n",
              " 'necessarily': 188,\n",
              " 'shared': 350,\n",
              " 'endorsed': 37,\n",
              " 'holding': 400,\n",
              " 'plc': 120,\n",
              " 'related': 2084,\n",
              " 'company': 9669,\n",
              " 'particular': 1329,\n",
              " 'transmission': 419,\n",
              " 'binding': 315,\n",
              " 'purpose': 855,\n",
              " 'forming': 69,\n",
              " 'contract': 1505,\n",
              " 'sell': 1272,\n",
              " 'airline': 159,\n",
              " 'seat': 93,\n",
              " 'directly': 975,\n",
              " 'via': 1966,\n",
              " 'promotion': 585,\n",
              " 'contractual': 59,\n",
              " 'obligation': 437,\n",
              " 'type': 2753,\n",
              " 'formed': 153,\n",
              " 'writing': 1166,\n",
              " 'post': 1449,\n",
              " 'fax': 5714,\n",
              " 'duly': 12,\n",
              " 'signed': 515,\n",
              " 'senior': 511,\n",
              " 'executive': 961,\n",
              " 'board': 1021,\n",
              " 'director': 1197,\n",
              " 'content': 2351,\n",
              " 'changed': 412,\n",
              " 'altered': 31,\n",
              " 'consent': 92,\n",
              " 'hereby': 67,\n",
              " 'notified': 260,\n",
              " 'review': 2341,\n",
              " 'dissemination': 75,\n",
              " 'disclosure': 259,\n",
              " 'alteration': 26,\n",
              " 'printing': 206,\n",
              " 'circulation': 85,\n",
              " 'action': 1476,\n",
              " 'taken': 780,\n",
              " 'omitted': 48,\n",
              " 'reliance': 99,\n",
              " 'prohibited': 128,\n",
              " 'unlawful': 21,\n",
              " 'received': 2953,\n",
              " 'error': 1460,\n",
              " 'notify': 140,\n",
              " 'emailing': 129,\n",
              " 'postmaster': 57,\n",
              " 'ie': 2425,\n",
              " 'contact': 4424,\n",
              " 'dublin': 186,\n",
              " 'airport': 322,\n",
              " 'subscribed': 215,\n",
              " 'customer': 2008,\n",
              " 'zzz': 1,\n",
              " 'spamassassin': 1579,\n",
              " 'taint': 266,\n",
              " 'send': 6097,\n",
              " 'blank': 252,\n",
              " 'leave': 668,\n",
              " '949326k': 3,\n",
              " 'ryanairmail': 3,\n",
              " 'lot': 1801,\n",
              " 'ahamed': 2,\n",
              " 'remove': 2007,\n",
              " 'mongoose': 1,\n",
              " 'jobholdergolden': 1,\n",
              " 'churn': 11,\n",
              " 'clubroomcascara': 1,\n",
              " 'chat': 265,\n",
              " 'scrupulousmarksman': 1,\n",
              " 'granola': 1,\n",
              " 'mildblimp': 1,\n",
              " 'chinatown': 9,\n",
              " 'cummingsfortiori': 1,\n",
              " 'keyhole': 2,\n",
              " 'brainardchevalier': 1,\n",
              " 'screechy': 5,\n",
              " 'warym': 1,\n",
              " 'respiratory': 6,\n",
              " 'vishnuclark': 1,\n",
              " 'crash': 168,\n",
              " 'gallantstatler': 1,\n",
              " 'swede': 8,\n",
              " 'moribundpuddly': 1,\n",
              " 'hoofmark': 1,\n",
              " 'threadbreed': 1,\n",
              " 'shrift': 4,\n",
              " 'greeneryalcohol': 1,\n",
              " 'anderson': 240,\n",
              " 'cherokeedillon': 1,\n",
              " 'discriminatory': 22,\n",
              " 'methanolcirculant': 1,\n",
              " 'alvarez': 82,\n",
              " 'duskshrew': 1,\n",
              " 'solecism': 1,\n",
              " 'twitchtan': 1,\n",
              " 'dexter': 14,\n",
              " 'exhalesaul': 1,\n",
              " 'depositorpusan': 1,\n",
              " 'accipiter': 3,\n",
              " 'elinorbrew': 1,\n",
              " 'mortician': 3,\n",
              " 'begottendrip': 1,\n",
              " 'hostess': 10,\n",
              " 'rallytopologize': 1,\n",
              " 'superposable': 3,\n",
              " 'miraculousclimate': 1,\n",
              " 'croon': 2,\n",
              " 'efficaciousrise': 1,\n",
              " 'filial': 2,\n",
              " 'muriatic': 2,\n",
              " 'tylernarcissus': 1,\n",
              " 'urethane': 3,\n",
              " 'pollardeasygoing': 1,\n",
              " 'pipsissewa': 3,\n",
              " 'cafeteriaavuncular': 1,\n",
              " 'disco': 14,\n",
              " 'holdenbiddy': 1,\n",
              " 'evil': 104,\n",
              " 'catastropheinquest': 1,\n",
              " 'nectareous': 2,\n",
              " 'swindlebestial': 1,\n",
              " 'anhydrite': 7,\n",
              " 'scarfgiveth': 1,\n",
              " 'bema': 4,\n",
              " 'herebysuit': 1,\n",
              " 'portulacashouldn': 1,\n",
              " 'axiology': 5,\n",
              " 'canneldisgruntle': 1,\n",
              " 'flatiron': 12,\n",
              " 'employlifestyle': 1,\n",
              " 'data': 3998,\n",
              " 'heredada': 1,\n",
              " 'larkspur': 3,\n",
              " 'cobaltinflexible': 1,\n",
              " 'write': 1279,\n",
              " 'mind': 1124,\n",
              " 'awful': 34,\n",
              " 'oh': 362,\n",
              " 'interesting': 877,\n",
              " 'yes': 1263,\n",
              " 'starlet': 5,\n",
              " 'behind': 330,\n",
              " 'bike': 22,\n",
              " 'wearing': 26,\n",
              " 'pretty': 489,\n",
              " 'innerestin': 1,\n",
              " 'modesty': 4,\n",
              " 'photo': 325,\n",
              " 'public': 1137,\n",
              " 'consumption': 61,\n",
              " 'felhelen': 1,\n",
              " 'troy': 47,\n",
              " 'yahoo': 1104,\n",
              " 'group': 4507,\n",
              " 'sponsor': 377,\n",
              " 'home': 3548,\n",
              " 'top': 1640,\n",
              " 'rrpzmc': 4,\n",
              " 'jtmeaa': 4,\n",
              " 'mvfiaa': 62,\n",
              " '7gsolb': 76,\n",
              " 'tm': 625,\n",
              " 'forteana': 131,\n",
              " 'egroups': 115,\n",
              " 'doc': 557,\n",
              " 'term': 3424,\n",
              " 'url': 1486,\n",
              " 'newsisfree': 287,\n",
              " '8015193': 1,\n",
              " '1440': 66,\n",
              " 'date': 4024,\n",
              " 'supplieda': 15,\n",
              " 'new': 11513,\n",
              " 'analysis': 3040,\n",
              " 'satellite': 211,\n",
              " 'image': 906,\n",
              " 'show': 2017,\n",
              " 'regeneration': 2,\n",
              " 'arid': 6,\n",
              " 'land': 280,\n",
              " 'across': 828,\n",
              " 'southern': 550,\n",
              " 'sahara': 7,\n",
              " 'making': 1845,\n",
              " 'farming': 10,\n",
              " 'viable': 45,\n",
              " 'boingboing': 92,\n",
              " 'net': 6084,\n",
              " '85528531': 1,\n",
              " 'supplied': 166,\n",
              " 'img': 109,\n",
              " 'craphound': 13,\n",
              " 'actlab': 3,\n",
              " 'jpg': 84,\n",
              " 'jon': 109,\n",
              " 'lebkowsky': 2,\n",
              " 'ha': 13111,\n",
              " 'posted': 772,\n",
              " 'little': 1873,\n",
              " 'gallery': 79,\n",
              " 'picture': 643,\n",
              " 'eff': 255,\n",
              " 'austin': 408,\n",
              " 'talk': 2100,\n",
              " 'university': 16258,\n",
              " 'texas': 1217,\n",
              " 'shot': 181,\n",
              " 'kick': 69,\n",
              " 'bbq': 11,\n",
              " 'ate': 71,\n",
              " 'beforehand': 15,\n",
              " 'note': 2865,\n",
              " 'atkins': 14,\n",
              " 'compliant': 49,\n",
              " 'lunch': 1129,\n",
              " 'fantastic': 134,\n",
              " 'organizer': 646,\n",
              " 'especially': 1032,\n",
              " 'putting': 283,\n",
              " 'meeet': 1,\n",
              " 'boing': 87,\n",
              " 'came': 774,\n",
              " 'link': 2970,\n",
              " 'discus': 984,\n",
              " '_thanks': 45,\n",
              " 'john': 3418,\n",
              " '_': 218970,\n",
              " 'cory': 8,\n",
              " 'quicktopic': 88,\n",
              " 'h': 2226,\n",
              " 'gkmgdxswsp7': 1,\n",
              " 'weblogsky': 2,\n",
              " 'forwarded': 1055,\n",
              " 'mon': 368,\n",
              " '23': 1643,\n",
              " 'sep': 385,\n",
              " '2002': 3507,\n",
              " '09': 1710,\n",
              " '52': 433,\n",
              " '44': 1166,\n",
              " '0700': 116,\n",
              " 'mi': 352,\n",
              " 'seiden': 3,\n",
              " 'scoot': 1,\n",
              " 'bos': 215,\n",
              " 'wife': 478,\n",
              " 'order': 8303,\n",
              " 'hit': 697,\n",
              " 'independent': 673,\n",
              " 'shopper': 51,\n",
              " 'newspaper': 255,\n",
              " 'sf': 988,\n",
              " 'bay': 143,\n",
              " 'area': 3127,\n",
              " 'operational': 209,\n",
              " 'definition': 341,\n",
              " 'medium': 1253,\n",
              " 'category': 1326,\n",
              " 'matter': 1293,\n",
              " 'hard': 1562,\n",
              " 'delivering': 66,\n",
              " 'story': 1050,\n",
              " 'aug': 565,\n",
              " 'dot': 117,\n",
              " 'downturn': 21,\n",
              " 'linked': 203,\n",
              " 'domestic': 218,\n",
              " 'violence': 100,\n",
              " 'worker': 313,\n",
              " 'kathy': 75,\n",
              " 'black': 536,\n",
              " 'remembers': 23,\n",
              " 'watching': 187,\n",
              " 'nasdaq': 89,\n",
              " 'take': 4732,\n",
              " 'nastydive': 1,\n",
              " 'msnbc': 22,\n",
              " 'march': 1738,\n",
              " '2000': 3749,\n",
              " 'knew': 311,\n",
              " 'hand': 1274,\n",
              " 'referring': 149,\n",
              " 'caseload': 1,\n",
              " 'la': 2741,\n",
              " 'casa': 33,\n",
              " 'de': 9872,\n",
              " 'madres': 1,\n",
              " 'city': 1663,\n",
              " 'largest': 632,\n",
              " 'organization': 1127,\n",
              " 'serving': 99,\n",
              " 'woman': 1200,\n",
              " 'child': 1672,\n",
              " 'affected': 143,\n",
              " 'crisis': 222,\n",
              " 'line': 3785,\n",
              " 'increased': 361,\n",
              " '33': 673,\n",
              " 'last': 3140,\n",
              " 'financial': 2487,\n",
              " 'saw': 453,\n",
              " '10': 10876,\n",
              " 'percent': 843,\n",
              " 'increase': 1175,\n",
              " 'demand': 648,\n",
              " 'bed': 254,\n",
              " '232': 56,\n",
              " '215': 463,\n",
              " 'utilizing': 75,\n",
              " 'shelter': 18,\n",
              " 'collapse': 133,\n",
              " 'growing': 598,\n",
              " 'awareness': 117,\n",
              " 'main': 1311,\n",
              " 'reason': 1390,\n",
              " 'employed': 119,\n",
              " 'utilized': 61,\n",
              " '04': 1133,\n",
              " '17pm': 7,\n",
              " '0100': 184,\n",
              " 'gordon': 134,\n",
              " 'joly': 2,\n",
              " 'wrote': 1693,\n",
              " 'news': 2810,\n",
              " 'bbc': 80,\n",
              " 'low': 1399,\n",
              " 'england': 538,\n",
              " '2276467': 1,\n",
              " 'stm': 26,\n",
              " 'admits': 26,\n",
              " 'trying': 877,\n",
              " 'hire': 128,\n",
              " 'hitman': 2,\n",
              " 'former': 510,\n",
              " 'tycoon': 6,\n",
              " 'admitted': 52,\n",
              " 'kill': 137,\n",
              " 'breakdown': 35,\n",
              " '21': 2087,\n",
              " 'marriage': 105,\n",
              " 'linux': 3312,\n",
              " '256022': 1,\n",
              " 'pobox': 24,\n",
              " 'gordo': 6,\n",
              " 'citizen': 230,\n",
              " 'griffith': 45,\n",
              " 'operation': 1422,\n",
              " 'agency': 641,\n",
              " 'operating': 663,\n",
              " 'agreement': 1433,\n",
              " 'tw': 314,\n",
              " 'taking': 772,\n",
              " 'monitoring': 105,\n",
              " 'plant': 624,\n",
              " 'behalf': 418,\n",
              " 'alarm': 42,\n",
              " 'personnel': 178,\n",
              " 'responsible': 417,\n",
              " ...}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXm6yay1yqp4",
        "outputId": "81f839da-734c-4b74-df38-8a8fa47ef160"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def keep_token(proccessed_token, threshold):\n",
        "  if proccessed_token not in token_counter:\n",
        "    return False\n",
        "  else:\n",
        "    return token_counter[proccessed_token] > threshold\n",
        "\n",
        "keep_token('random', 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMiIpz440Lco",
        "outputId": "67b5081f-595d-417f-c715-dabc1aca34b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'0',\n",
              " '00',\n",
              " '000',\n",
              " '01',\n",
              " '02',\n",
              " '03',\n",
              " '04',\n",
              " '05',\n",
              " '07',\n",
              " '08',\n",
              " '09',\n",
              " '1',\n",
              " '10',\n",
              " '100',\n",
              " '11',\n",
              " '12',\n",
              " '13',\n",
              " '14',\n",
              " '15',\n",
              " '16',\n",
              " '17',\n",
              " '18',\n",
              " '19',\n",
              " '1994',\n",
              " '1995',\n",
              " '1997',\n",
              " '1998',\n",
              " '1999',\n",
              " '2',\n",
              " '20',\n",
              " '200',\n",
              " '2000',\n",
              " '2001',\n",
              " '2002',\n",
              " '21',\n",
              " '22',\n",
              " '23',\n",
              " '24',\n",
              " '25',\n",
              " '26',\n",
              " '27',\n",
              " '28',\n",
              " '29',\n",
              " '3',\n",
              " '30',\n",
              " '31',\n",
              " '35',\n",
              " '3d',\n",
              " '4',\n",
              " '40',\n",
              " '44',\n",
              " '45',\n",
              " '49',\n",
              " '5',\n",
              " '50',\n",
              " '500',\n",
              " '6',\n",
              " '60',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " '90',\n",
              " '95',\n",
              " '97',\n",
              " '98',\n",
              " '99',\n",
              " '_',\n",
              " 'able',\n",
              " 'abstract',\n",
              " 'ac',\n",
              " 'accepted',\n",
              " 'access',\n",
              " 'account',\n",
              " 'acquisition',\n",
              " 'act',\n",
              " 'action',\n",
              " 'actually',\n",
              " 'ad',\n",
              " 'add',\n",
              " 'additional',\n",
              " 'address',\n",
              " 'ago',\n",
              " 'agreement',\n",
              " 'already',\n",
              " 'also',\n",
              " 'although',\n",
              " 'always',\n",
              " 'america',\n",
              " 'american',\n",
              " 'among',\n",
              " 'amount',\n",
              " 'analysis',\n",
              " 'analyst',\n",
              " 'announcement',\n",
              " 'another',\n",
              " 'answer',\n",
              " 'anyone',\n",
              " 'anything',\n",
              " 'application',\n",
              " 'applied',\n",
              " 'approach',\n",
              " 'april',\n",
              " 'area',\n",
              " 'argument',\n",
              " 'around',\n",
              " 'article',\n",
              " 'ask',\n",
              " 'asked',\n",
              " 'aspect',\n",
              " 'asset',\n",
              " 'association',\n",
              " 'attached',\n",
              " 'august',\n",
              " 'author',\n",
              " 'available',\n",
              " 'away',\n",
              " 'b',\n",
              " 'back',\n",
              " 'bank',\n",
              " 'based',\n",
              " 'basis',\n",
              " 'become',\n",
              " 'believe',\n",
              " 'benjamin',\n",
              " 'best',\n",
              " 'better',\n",
              " 'big',\n",
              " 'bill',\n",
              " 'billion',\n",
              " 'board',\n",
              " 'book',\n",
              " 'box',\n",
              " 'break',\n",
              " 'bulk',\n",
              " 'business',\n",
              " 'buy',\n",
              " 'c',\n",
              " 'ca',\n",
              " 'california',\n",
              " 'call',\n",
              " 'called',\n",
              " 'canada',\n",
              " 'cannot',\n",
              " 'capital',\n",
              " 'card',\n",
              " 'case',\n",
              " 'cash',\n",
              " 'category',\n",
              " 'cc',\n",
              " 'cd',\n",
              " 'center',\n",
              " 'certain',\n",
              " 'chair',\n",
              " 'change',\n",
              " 'charge',\n",
              " 'check',\n",
              " 'child',\n",
              " 'chinese',\n",
              " 'city',\n",
              " 'claim',\n",
              " 'class',\n",
              " 'clear',\n",
              " 'click',\n",
              " 'co',\n",
              " 'code',\n",
              " 'cognitive',\n",
              " 'college',\n",
              " 'color',\n",
              " 'com',\n",
              " 'come',\n",
              " 'comment',\n",
              " 'commercial',\n",
              " 'committee',\n",
              " 'common',\n",
              " 'communication',\n",
              " 'community',\n",
              " 'company',\n",
              " 'complete',\n",
              " 'computational',\n",
              " 'computer',\n",
              " 'conference',\n",
              " 'construction',\n",
              " 'contact',\n",
              " 'content',\n",
              " 'context',\n",
              " 'continue',\n",
              " 'contract',\n",
              " 'control',\n",
              " 'copy',\n",
              " 'copyright',\n",
              " 'corp',\n",
              " 'corpus',\n",
              " 'cost',\n",
              " 'could',\n",
              " 'country',\n",
              " 'course',\n",
              " 'cover',\n",
              " 'credit',\n",
              " 'current',\n",
              " 'currently',\n",
              " 'customer',\n",
              " 'data',\n",
              " 'database',\n",
              " 'date',\n",
              " 'david',\n",
              " 'day',\n",
              " 'de',\n",
              " 'deadline',\n",
              " 'deal',\n",
              " 'dear',\n",
              " 'debt',\n",
              " 'december',\n",
              " 'department',\n",
              " 'description',\n",
              " 'detail',\n",
              " 'development',\n",
              " 'dialect',\n",
              " 'difference',\n",
              " 'different',\n",
              " 'direct',\n",
              " 'director',\n",
              " 'directory',\n",
              " 'discourse',\n",
              " 'discussion',\n",
              " 'document',\n",
              " 'doe',\n",
              " 'dollar',\n",
              " 'domain',\n",
              " 'done',\n",
              " 'dr',\n",
              " 'due',\n",
              " 'dynegy',\n",
              " 'e',\n",
              " 'early',\n",
              " 'easy',\n",
              " 'ect',\n",
              " 'ed',\n",
              " 'editor',\n",
              " 'edu',\n",
              " 'education',\n",
              " 'effect',\n",
              " 'effort',\n",
              " 'either',\n",
              " 'electronic',\n",
              " 'else',\n",
              " 'email',\n",
              " 'en',\n",
              " 'end',\n",
              " 'energy',\n",
              " 'english',\n",
              " 'enough',\n",
              " 'enron',\n",
              " 'error',\n",
              " 'especially',\n",
              " 'et',\n",
              " 'etc',\n",
              " 'europe',\n",
              " 'european',\n",
              " 'evaluation',\n",
              " 'even',\n",
              " 'event',\n",
              " 'ever',\n",
              " 'every',\n",
              " 'everyone',\n",
              " 'example',\n",
              " 'exchange',\n",
              " 'experience',\n",
              " 'f',\n",
              " 'fact',\n",
              " 'family',\n",
              " 'far',\n",
              " 'fax',\n",
              " 'feature',\n",
              " 'february',\n",
              " 'fee',\n",
              " 'feel',\n",
              " 'field',\n",
              " 'file',\n",
              " 'final',\n",
              " 'financial',\n",
              " 'find',\n",
              " 'first',\n",
              " 'five',\n",
              " 'focus',\n",
              " 'follow',\n",
              " 'following',\n",
              " 'font',\n",
              " 'foreign',\n",
              " 'form',\n",
              " 'format',\n",
              " 'forward',\n",
              " 'forwarded',\n",
              " 'found',\n",
              " 'four',\n",
              " 'france',\n",
              " 'free',\n",
              " 'french',\n",
              " 'friday',\n",
              " 'friend',\n",
              " 'full',\n",
              " 'fund',\n",
              " 'future',\n",
              " 'g',\n",
              " 'gas',\n",
              " 'general',\n",
              " 'german',\n",
              " 'germany',\n",
              " 'get',\n",
              " 'getting',\n",
              " 'give',\n",
              " 'given',\n",
              " 'global',\n",
              " 'go',\n",
              " 'going',\n",
              " 'good',\n",
              " 'got',\n",
              " 'government',\n",
              " 'grammar',\n",
              " 'grant',\n",
              " 'great',\n",
              " 'group',\n",
              " 'h',\n",
              " 'ha',\n",
              " 'hand',\n",
              " 'hard',\n",
              " 'head',\n",
              " 'held',\n",
              " 'help',\n",
              " 'high',\n",
              " 'historical',\n",
              " 'history',\n",
              " 'home',\n",
              " 'hope',\n",
              " 'hotel',\n",
              " 'hou',\n",
              " 'hour',\n",
              " 'houston',\n",
              " 'however',\n",
              " 'html',\n",
              " 'http',\n",
              " 'human',\n",
              " 'hundred',\n",
              " 'id',\n",
              " 'idea',\n",
              " 'ie',\n",
              " 'ilug',\n",
              " 'immediately',\n",
              " 'important',\n",
              " 'inc',\n",
              " 'include',\n",
              " 'included',\n",
              " 'includes',\n",
              " 'including',\n",
              " 'income',\n",
              " 'increase',\n",
              " 'index',\n",
              " 'individual',\n",
              " 'industry',\n",
              " 'info',\n",
              " 'information',\n",
              " 'institute',\n",
              " 'instruction',\n",
              " 'interest',\n",
              " 'interested',\n",
              " 'international',\n",
              " 'internet',\n",
              " 'investment',\n",
              " 'investor',\n",
              " 'invited',\n",
              " 'issue',\n",
              " 'item',\n",
              " 'j',\n",
              " 'january',\n",
              " 'japan',\n",
              " 'japanese',\n",
              " 'job',\n",
              " 'john',\n",
              " 'jones',\n",
              " 'journal',\n",
              " 'july',\n",
              " 'june',\n",
              " 'k',\n",
              " 'kaminski',\n",
              " 'keep',\n",
              " 'key',\n",
              " 'kind',\n",
              " 'know',\n",
              " 'knowledge',\n",
              " 'l',\n",
              " 'la',\n",
              " 'language',\n",
              " 'large',\n",
              " 'last',\n",
              " 'later',\n",
              " 'latest',\n",
              " 'law',\n",
              " 'le',\n",
              " 'learn',\n",
              " 'learning',\n",
              " 'least',\n",
              " 'left',\n",
              " 'legal',\n",
              " 'length',\n",
              " 'less',\n",
              " 'let',\n",
              " 'letter',\n",
              " 'level',\n",
              " 'lexical',\n",
              " 'life',\n",
              " 'like',\n",
              " 'limited',\n",
              " 'line',\n",
              " 'linguist',\n",
              " 'linguistic',\n",
              " 'linguistics',\n",
              " 'link',\n",
              " 'linux',\n",
              " 'list',\n",
              " 'listinfo',\n",
              " 'little',\n",
              " 'live',\n",
              " 'local',\n",
              " 'logic',\n",
              " 'london',\n",
              " 'long',\n",
              " 'look',\n",
              " 'looking',\n",
              " 'loss',\n",
              " 'lot',\n",
              " 'low',\n",
              " 'lunch',\n",
              " 'machine',\n",
              " 'made',\n",
              " 'mail',\n",
              " 'mailing',\n",
              " 'mailman',\n",
              " 'main',\n",
              " 'major',\n",
              " 'make',\n",
              " 'making',\n",
              " 'man',\n",
              " 'management',\n",
              " 'many',\n",
              " 'march',\n",
              " 'mark',\n",
              " 'market',\n",
              " 'marketing',\n",
              " 'material',\n",
              " 'matter',\n",
              " 'may',\n",
              " 'mean',\n",
              " 'meaning',\n",
              " 'medium',\n",
              " 'meeting',\n",
              " 'member',\n",
              " 'message',\n",
              " 'method',\n",
              " 'michael',\n",
              " 'microsoft',\n",
              " 'might',\n",
              " 'million',\n",
              " 'mind',\n",
              " 'minute',\n",
              " 'model',\n",
              " 'monday',\n",
              " 'money',\n",
              " 'month',\n",
              " 'morphology',\n",
              " 'move',\n",
              " 'movement',\n",
              " 'mr',\n",
              " 'much',\n",
              " 'multi',\n",
              " 'must',\n",
              " 'n',\n",
              " 'name',\n",
              " 'national',\n",
              " 'native',\n",
              " 'natural',\n",
              " 'need',\n",
              " 'net',\n",
              " 'network',\n",
              " 'never',\n",
              " 'new',\n",
              " 'news',\n",
              " 'next',\n",
              " 'nl',\n",
              " 'non',\n",
              " 'north',\n",
              " 'note',\n",
              " 'nothing',\n",
              " 'november',\n",
              " 'number',\n",
              " 'object',\n",
              " 'october',\n",
              " 'offer',\n",
              " 'office',\n",
              " 'old',\n",
              " 'one',\n",
              " 'online',\n",
              " 'open',\n",
              " 'operation',\n",
              " 'opportunity',\n",
              " 'option',\n",
              " 'order',\n",
              " 'org',\n",
              " 'organization',\n",
              " 'original',\n",
              " 'others',\n",
              " 'p',\n",
              " 'package',\n",
              " 'page',\n",
              " 'paid',\n",
              " 'paper',\n",
              " 'part',\n",
              " 'participant',\n",
              " 'particular',\n",
              " 'party',\n",
              " 'past',\n",
              " 'paul',\n",
              " 'pay',\n",
              " 'payment',\n",
              " 'people',\n",
              " 'per',\n",
              " 'performance',\n",
              " 'person',\n",
              " 'personal',\n",
              " 'phone',\n",
              " 'phonology',\n",
              " 'place',\n",
              " 'plan',\n",
              " 'please',\n",
              " 'plus',\n",
              " 'pm',\n",
              " 'point',\n",
              " 'position',\n",
              " 'possible',\n",
              " 'post',\n",
              " 'potential',\n",
              " 'power',\n",
              " 'pp',\n",
              " 'pre',\n",
              " 'present',\n",
              " 'presentation',\n",
              " 'president',\n",
              " 'press',\n",
              " 'price',\n",
              " 'probably',\n",
              " 'problem',\n",
              " 'proceeding',\n",
              " 'process',\n",
              " 'processing',\n",
              " 'product',\n",
              " 'production',\n",
              " 'professional',\n",
              " 'program',\n",
              " 'programme',\n",
              " 'project',\n",
              " 'proposal',\n",
              " 'provide',\n",
              " 'provided',\n",
              " 'public',\n",
              " 'publication',\n",
              " 'published',\n",
              " 'purchase',\n",
              " 'put',\n",
              " 'quality',\n",
              " 'query',\n",
              " 'question',\n",
              " 'quite',\n",
              " 'r',\n",
              " 'rate',\n",
              " 'rather',\n",
              " 'razor',\n",
              " 'read',\n",
              " 'reading',\n",
              " 'ready',\n",
              " 'real',\n",
              " 'really',\n",
              " 'reason',\n",
              " 'receive',\n",
              " 'received',\n",
              " 'recent',\n",
              " 'record',\n",
              " 'reference',\n",
              " 'regard',\n",
              " 'registration',\n",
              " 'related',\n",
              " 'relation',\n",
              " 'release',\n",
              " 'remember',\n",
              " 'remove',\n",
              " 'removed',\n",
              " 'reply',\n",
              " 'report',\n",
              " 'representation',\n",
              " 'request',\n",
              " 'required',\n",
              " 'research',\n",
              " 'researcher',\n",
              " 'resource',\n",
              " 'response',\n",
              " 'result',\n",
              " 'return',\n",
              " 'review',\n",
              " 'right',\n",
              " 'risk',\n",
              " 'robert',\n",
              " 'role',\n",
              " 'room',\n",
              " 'rpm',\n",
              " 'rule',\n",
              " 'run',\n",
              " 'said',\n",
              " 'sale',\n",
              " 'save',\n",
              " 'say',\n",
              " 'schedule',\n",
              " 'school',\n",
              " 'science',\n",
              " 'search',\n",
              " 'second',\n",
              " 'section',\n",
              " 'security',\n",
              " 'see',\n",
              " 'seems',\n",
              " 'sell',\n",
              " 'semantic',\n",
              " 'semantics',\n",
              " 'send',\n",
              " 'sent',\n",
              " 'sentence',\n",
              " 'september',\n",
              " 'series',\n",
              " 'server',\n",
              " 'service',\n",
              " 'session',\n",
              " 'set',\n",
              " 'several',\n",
              " 'share',\n",
              " 'short',\n",
              " 'show',\n",
              " 'sign',\n",
              " 'simple',\n",
              " 'simply',\n",
              " 'since',\n",
              " 'single',\n",
              " 'site',\n",
              " 'size',\n",
              " 'small',\n",
              " 'social',\n",
              " 'society',\n",
              " 'software',\n",
              " 'someone',\n",
              " 'something',\n",
              " 'soon',\n",
              " 'sound',\n",
              " 'source',\n",
              " 'sourceforge',\n",
              " 'south',\n",
              " 'spam',\n",
              " 'spamassassin',\n",
              " 'spanish',\n",
              " 'speaker',\n",
              " 'special',\n",
              " 'specific',\n",
              " 'speech',\n",
              " 'spoken',\n",
              " 'st',\n",
              " 'standard',\n",
              " 'start',\n",
              " 'state',\n",
              " 'statement',\n",
              " 'step',\n",
              " 'still',\n",
              " 'stock',\n",
              " 'stop',\n",
              " 'story',\n",
              " 'street',\n",
              " 'structure',\n",
              " 'student',\n",
              " 'study',\n",
              " 'style',\n",
              " 'subject',\n",
              " 'submission',\n",
              " 'submit',\n",
              " 'subscription',\n",
              " 'success',\n",
              " 'summary',\n",
              " 'summer',\n",
              " 'support',\n",
              " 'sure',\n",
              " 'syntactic',\n",
              " 'syntax',\n",
              " 'system',\n",
              " 'take',\n",
              " 'talk',\n",
              " 'teaching',\n",
              " 'team',\n",
              " 'technology',\n",
              " 'tel',\n",
              " 'telephone',\n",
              " 'tell',\n",
              " 'term',\n",
              " 'texas',\n",
              " 'text',\n",
              " 'th',\n",
              " 'thank',\n",
              " 'thanks',\n",
              " 'theme',\n",
              " 'theoretical',\n",
              " 'theory',\n",
              " 'thing',\n",
              " 'think',\n",
              " 'third',\n",
              " 'though',\n",
              " 'thought',\n",
              " 'thousand',\n",
              " 'three',\n",
              " 'thursday',\n",
              " 'time',\n",
              " 'title',\n",
              " 'today',\n",
              " 'together',\n",
              " 'tool',\n",
              " 'top',\n",
              " 'topic',\n",
              " 'total',\n",
              " 'trade',\n",
              " 'trading',\n",
              " 'transaction',\n",
              " 'translation',\n",
              " 'try',\n",
              " 'tuesday',\n",
              " 'tutorial',\n",
              " 'two',\n",
              " 'type',\n",
              " 'u',\n",
              " 'uk',\n",
              " 'un',\n",
              " 'unit',\n",
              " 'united',\n",
              " 'university',\n",
              " 'unsubscribe',\n",
              " 'update',\n",
              " 'url',\n",
              " 'usa',\n",
              " 'use',\n",
              " 'used',\n",
              " 'user',\n",
              " 'using',\n",
              " 'v',\n",
              " 'value',\n",
              " 'various',\n",
              " 'verb',\n",
              " 'version',\n",
              " 'via',\n",
              " 'video',\n",
              " 'view',\n",
              " 'vince',\n",
              " 'visit',\n",
              " 'volume',\n",
              " 'vowel',\n",
              " 'w',\n",
              " 'wa',\n",
              " 'want',\n",
              " 'way',\n",
              " 'web',\n",
              " 'website',\n",
              " 'wednesday',\n",
              " 'week',\n",
              " 'welcome',\n",
              " 'well',\n",
              " 'whether',\n",
              " 'whole',\n",
              " 'wide',\n",
              " 'window',\n",
              " 'wish',\n",
              " 'within',\n",
              " 'without',\n",
              " 'woman',\n",
              " 'word',\n",
              " 'work',\n",
              " 'working',\n",
              " 'workshop',\n",
              " 'world',\n",
              " 'would',\n",
              " 'write',\n",
              " 'writing',\n",
              " 'written',\n",
              " 'wrote',\n",
              " 'www',\n",
              " 'x',\n",
              " 'yahoo',\n",
              " 'year',\n",
              " 'yes',\n",
              " 'yet',\n",
              " 'york',\n",
              " '½ï',\n",
              " 'â',\n",
              " 'ã',\n",
              " 'ï'}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = set()\n",
        "\n",
        "for token in token_counter:\n",
        "  if keep_token(token, 1000):\n",
        "    features.add(token)\n",
        "\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLz9f1X73cwq",
        "outputId": "28b15d0d-5843-437f-b89c-bdf3abb540df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['access',\n",
              " 'error',\n",
              " 'type',\n",
              " 'hour',\n",
              " 'real',\n",
              " 'listinfo',\n",
              " 'topic',\n",
              " 'institute',\n",
              " 'researcher',\n",
              " 'statement',\n",
              " 'system',\n",
              " 'series',\n",
              " 'native',\n",
              " '05',\n",
              " 'day',\n",
              " 'editor',\n",
              " 'www',\n",
              " 'role',\n",
              " 'power',\n",
              " 'grant',\n",
              " 'c',\n",
              " 'enron',\n",
              " 'publication',\n",
              " 'idea',\n",
              " 'show',\n",
              " 'stop',\n",
              " 'microsoft',\n",
              " 'america',\n",
              " 'january',\n",
              " 'multi',\n",
              " 'experience',\n",
              " 'buy',\n",
              " 'semantic',\n",
              " 'also',\n",
              " 'center',\n",
              " '11',\n",
              " 'various',\n",
              " 'analyst',\n",
              " '2001',\n",
              " 'education',\n",
              " 'come',\n",
              " 'left',\n",
              " 'thing',\n",
              " 'write',\n",
              " 'particular',\n",
              " 'billion',\n",
              " 'step',\n",
              " 'market',\n",
              " 'additional',\n",
              " 'v',\n",
              " 'without',\n",
              " 'event',\n",
              " 'current',\n",
              " 'subject',\n",
              " 'st',\n",
              " 'general',\n",
              " 'best',\n",
              " 'houston',\n",
              " 'fund',\n",
              " 'u',\n",
              " 'september',\n",
              " 'session',\n",
              " 'never',\n",
              " 'bill',\n",
              " 'check',\n",
              " 'much',\n",
              " 'schedule',\n",
              " 'discourse',\n",
              " 'ã',\n",
              " 'quality',\n",
              " 'ad',\n",
              " 'child',\n",
              " 'potential',\n",
              " 'public',\n",
              " 'getting',\n",
              " 'box',\n",
              " 'value',\n",
              " 'ie',\n",
              " 'investment',\n",
              " 'spanish',\n",
              " 'last',\n",
              " 'thought',\n",
              " 'industry',\n",
              " 'ï',\n",
              " 'room',\n",
              " 'international',\n",
              " 'already',\n",
              " 'model',\n",
              " '3d',\n",
              " 'thanks',\n",
              " 'attached',\n",
              " 'mind',\n",
              " 'h',\n",
              " 'proposal',\n",
              " 'author',\n",
              " 'operation',\n",
              " 'historical',\n",
              " 'view',\n",
              " '10',\n",
              " 'clear',\n",
              " '500',\n",
              " 'immediately',\n",
              " 'lot',\n",
              " 'global',\n",
              " 'seems',\n",
              " 'right',\n",
              " 'february',\n",
              " 'trade',\n",
              " 'difference',\n",
              " 'home',\n",
              " 'thank',\n",
              " 'around',\n",
              " 'standard',\n",
              " '2',\n",
              " 'f',\n",
              " 'united',\n",
              " 'syntactic',\n",
              " 'fax',\n",
              " 'four',\n",
              " '60',\n",
              " 'full',\n",
              " 'ilug',\n",
              " 'knowledge',\n",
              " 'length',\n",
              " 'forward',\n",
              " 'time',\n",
              " 'analysis',\n",
              " 'video',\n",
              " 'opportunity',\n",
              " 'california',\n",
              " 'search',\n",
              " 'level',\n",
              " 'style',\n",
              " 'start',\n",
              " 'description',\n",
              " 'include',\n",
              " 'investor',\n",
              " 'high',\n",
              " 'theory',\n",
              " 'national',\n",
              " 'info',\n",
              " 'machine',\n",
              " '1994',\n",
              " 'simply',\n",
              " 'member',\n",
              " 'simple',\n",
              " 'texas',\n",
              " 'run',\n",
              " 'registration',\n",
              " 'thursday',\n",
              " 'still',\n",
              " 'discussion',\n",
              " 'workshop',\n",
              " 'kaminski',\n",
              " 'deadline',\n",
              " '19',\n",
              " 'relation',\n",
              " 'line',\n",
              " '03',\n",
              " 'tuesday',\n",
              " 'chinese',\n",
              " 'something',\n",
              " 'france',\n",
              " 'category',\n",
              " 'within',\n",
              " 'ready',\n",
              " 'great',\n",
              " 'field',\n",
              " 'via',\n",
              " 'hard',\n",
              " 'method',\n",
              " 'order',\n",
              " 'student',\n",
              " 'people',\n",
              " 'evaluation',\n",
              " 'kind',\n",
              " 'review',\n",
              " 'ha',\n",
              " 'department',\n",
              " 'word',\n",
              " 'natural',\n",
              " 'recent',\n",
              " 'participant',\n",
              " 'government',\n",
              " '99',\n",
              " 'far',\n",
              " 'remember',\n",
              " 'learn',\n",
              " 'move',\n",
              " 'present',\n",
              " 'following',\n",
              " 'long',\n",
              " 'give',\n",
              " 'office',\n",
              " 'received',\n",
              " 'window',\n",
              " 'le',\n",
              " '200',\n",
              " 'team',\n",
              " 'logic',\n",
              " '29',\n",
              " 'university',\n",
              " 'think',\n",
              " 'site',\n",
              " 'individual',\n",
              " 'ect',\n",
              " 'content',\n",
              " 'direct',\n",
              " 'common',\n",
              " 'five',\n",
              " 'published',\n",
              " 'stock',\n",
              " '2002',\n",
              " 'development',\n",
              " 'cc',\n",
              " 'service',\n",
              " 'morphology',\n",
              " 'back',\n",
              " 'object',\n",
              " 'family',\n",
              " 'computational',\n",
              " 'part',\n",
              " '24',\n",
              " 'someone',\n",
              " 'class',\n",
              " 'committee',\n",
              " 'telephone',\n",
              " 'among',\n",
              " 'though',\n",
              " 'query',\n",
              " 'party',\n",
              " 'tutorial',\n",
              " 'human',\n",
              " 'story',\n",
              " 'said',\n",
              " 'go',\n",
              " 'history',\n",
              " '15',\n",
              " 'program',\n",
              " 'customer',\n",
              " 'link',\n",
              " 'en',\n",
              " 'lexical',\n",
              " 'later',\n",
              " '21',\n",
              " '1999',\n",
              " 'lunch',\n",
              " 'top',\n",
              " 'language',\n",
              " 'wide',\n",
              " 'volume',\n",
              " 'life',\n",
              " 'third',\n",
              " '3',\n",
              " '44',\n",
              " 'away',\n",
              " 'credit',\n",
              " 'linguistic',\n",
              " 'wish',\n",
              " 'original',\n",
              " 'study',\n",
              " 'summary',\n",
              " 'currently',\n",
              " 'president',\n",
              " 'matter',\n",
              " 'made',\n",
              " 'even',\n",
              " 'mail',\n",
              " 'co',\n",
              " 'european',\n",
              " '25',\n",
              " 'date',\n",
              " 'new',\n",
              " 'dr',\n",
              " 'product',\n",
              " 'online',\n",
              " 'syntax',\n",
              " '_',\n",
              " 'contract',\n",
              " 'enough',\n",
              " 'electronic',\n",
              " 'street',\n",
              " 'plan',\n",
              " 'index',\n",
              " 'else',\n",
              " 'plus',\n",
              " 'risk',\n",
              " 'wa',\n",
              " 'rate',\n",
              " 'help',\n",
              " 'continue',\n",
              " 'cognitive',\n",
              " 'pp',\n",
              " 'dollar',\n",
              " 'put',\n",
              " '07',\n",
              " 'number',\n",
              " 'quite',\n",
              " 'reason',\n",
              " 'translation',\n",
              " 'everyone',\n",
              " 'interest',\n",
              " 'argument',\n",
              " 'technology',\n",
              " '4',\n",
              " 'way',\n",
              " 'code',\n",
              " 'canada',\n",
              " 'large',\n",
              " 'keep',\n",
              " '9',\n",
              " '7',\n",
              " 'anyone',\n",
              " 'small',\n",
              " 'october',\n",
              " 'submit',\n",
              " 'example',\n",
              " 'communication',\n",
              " 'key',\n",
              " 'mailing',\n",
              " 'august',\n",
              " 'since',\n",
              " 'past',\n",
              " '22',\n",
              " 'grammar',\n",
              " 'information',\n",
              " 'url',\n",
              " 'looking',\n",
              " 'software',\n",
              " 'applied',\n",
              " 'mark',\n",
              " 'set',\n",
              " 'reply',\n",
              " 'uk',\n",
              " 'reading',\n",
              " 'hope',\n",
              " 'address',\n",
              " 'york',\n",
              " 'always',\n",
              " 'agreement',\n",
              " 'try',\n",
              " 'id',\n",
              " 'speech',\n",
              " 'aspect',\n",
              " 'world',\n",
              " 'letter',\n",
              " 'sell',\n",
              " 'edu',\n",
              " 'sound',\n",
              " 'record',\n",
              " 'offer',\n",
              " 'sent',\n",
              " 'probably',\n",
              " 'copy',\n",
              " 'get',\n",
              " 'used',\n",
              " 'capital',\n",
              " 'feature',\n",
              " 'database',\n",
              " 'thousand',\n",
              " 'japanese',\n",
              " 'including',\n",
              " 'possible',\n",
              " 'organization',\n",
              " 'production',\n",
              " 'de',\n",
              " 'like',\n",
              " 'proceeding',\n",
              " 'save',\n",
              " 'either',\n",
              " 'director',\n",
              " 'city',\n",
              " 'working',\n",
              " 'main',\n",
              " 'personal',\n",
              " 'invited',\n",
              " 'linguist',\n",
              " 'next',\n",
              " '1997',\n",
              " '00',\n",
              " 'make',\n",
              " '97',\n",
              " 'report',\n",
              " 'related',\n",
              " 'position',\n",
              " 'note',\n",
              " 'area',\n",
              " 'directory',\n",
              " 'professional',\n",
              " 'org',\n",
              " 'anything',\n",
              " 'l',\n",
              " 'update',\n",
              " '31',\n",
              " 'copyright',\n",
              " 'internet',\n",
              " 'teaching',\n",
              " '95',\n",
              " 'package',\n",
              " 'email',\n",
              " 'read',\n",
              " 'michael',\n",
              " 'today',\n",
              " '35',\n",
              " '12',\n",
              " 'major',\n",
              " 'issue',\n",
              " 'cash',\n",
              " 'friday',\n",
              " 'file',\n",
              " 'computer',\n",
              " 'server',\n",
              " 'dear',\n",
              " 'different',\n",
              " 'sale',\n",
              " 'whether',\n",
              " 'complete',\n",
              " 'french',\n",
              " 'e',\n",
              " 'might',\n",
              " 'country',\n",
              " 'provide',\n",
              " 'american',\n",
              " 'benjamin',\n",
              " 'chair',\n",
              " 'robert',\n",
              " 'based',\n",
              " 'europe',\n",
              " 'effort',\n",
              " 'month',\n",
              " 'programme',\n",
              " 'act',\n",
              " 'john',\n",
              " 'marketing',\n",
              " 'list',\n",
              " 'take',\n",
              " 'big',\n",
              " 'good',\n",
              " '000',\n",
              " 'live',\n",
              " 'wednesday',\n",
              " '98',\n",
              " 'news',\n",
              " 'account',\n",
              " 'person',\n",
              " 'want',\n",
              " 'corp',\n",
              " 'monday',\n",
              " 'material',\n",
              " 'follow',\n",
              " 'p',\n",
              " '08',\n",
              " 'semantics',\n",
              " 'vowel',\n",
              " 'together',\n",
              " 'friend',\n",
              " 'bank',\n",
              " 'source',\n",
              " 'written',\n",
              " 'specific',\n",
              " 'focus',\n",
              " 'section',\n",
              " 'question',\n",
              " 'really',\n",
              " 'research',\n",
              " 'however',\n",
              " 'sign',\n",
              " 'rather',\n",
              " 'cost',\n",
              " 'december',\n",
              " '14',\n",
              " 'paid',\n",
              " 'page',\n",
              " 'visit',\n",
              " 'north',\n",
              " '16',\n",
              " '1995',\n",
              " 'term',\n",
              " 'point',\n",
              " 'article',\n",
              " 'domain',\n",
              " 'found',\n",
              " 'wrote',\n",
              " 'latest',\n",
              " 'asked',\n",
              " 'construction',\n",
              " 'control',\n",
              " 'r',\n",
              " 'business',\n",
              " 'html',\n",
              " 'case',\n",
              " 'journal',\n",
              " 'free',\n",
              " '18',\n",
              " 'tel',\n",
              " 'held',\n",
              " '13',\n",
              " 'price',\n",
              " 'final',\n",
              " 'reference',\n",
              " 'gas',\n",
              " '28',\n",
              " 'press',\n",
              " 'non',\n",
              " 'announcement',\n",
              " '1',\n",
              " 'success',\n",
              " 'ca',\n",
              " 'dynegy',\n",
              " 'hotel',\n",
              " 'april',\n",
              " 'dialect',\n",
              " 'document',\n",
              " '0',\n",
              " 'minute',\n",
              " 'available',\n",
              " '90',\n",
              " 'website',\n",
              " 'single',\n",
              " 'nothing',\n",
              " 'year',\n",
              " 'association',\n",
              " 'submission',\n",
              " 'representation',\n",
              " '27',\n",
              " 'doe',\n",
              " 'could',\n",
              " 'change',\n",
              " 'exchange',\n",
              " 'contact',\n",
              " 'several',\n",
              " 'english',\n",
              " '04',\n",
              " 'book',\n",
              " 'amount',\n",
              " 'ac',\n",
              " 'may',\n",
              " 'verb',\n",
              " 'request',\n",
              " 'includes',\n",
              " 'increase',\n",
              " 'paper',\n",
              " 'web',\n",
              " 'summer',\n",
              " 'vince',\n",
              " 'meaning',\n",
              " 'resource',\n",
              " 'although',\n",
              " 'hand',\n",
              " 'especially',\n",
              " 'short',\n",
              " 'pm',\n",
              " 'many',\n",
              " 'special',\n",
              " 'would',\n",
              " 'see',\n",
              " 'job',\n",
              " '02',\n",
              " 'total',\n",
              " 'yes',\n",
              " 'course',\n",
              " 'sentence',\n",
              " 'financial',\n",
              " 'unit',\n",
              " 'tool',\n",
              " 'legal',\n",
              " 'rule',\n",
              " 'payment',\n",
              " '17',\n",
              " 'jones',\n",
              " 'future',\n",
              " 'corpus',\n",
              " 'june',\n",
              " 'structure',\n",
              " 'color',\n",
              " 'fact',\n",
              " 'look',\n",
              " '8',\n",
              " 'ed',\n",
              " 'text',\n",
              " 'community',\n",
              " 'conference',\n",
              " '45',\n",
              " 'find',\n",
              " 'learning',\n",
              " 'loss',\n",
              " 'instruction',\n",
              " 'spoken',\n",
              " 'paul',\n",
              " 'g',\n",
              " 'cover',\n",
              " 'net',\n",
              " 'nl',\n",
              " 'tell',\n",
              " 'w',\n",
              " 'result',\n",
              " 'social',\n",
              " 'need',\n",
              " 'three',\n",
              " 'limited',\n",
              " 'included',\n",
              " 'german',\n",
              " 'form',\n",
              " 'forwarded',\n",
              " 'removed',\n",
              " 'accepted',\n",
              " 'provided',\n",
              " 'say',\n",
              " 'abstract',\n",
              " 'know',\n",
              " 'david',\n",
              " 'local',\n",
              " 'debt',\n",
              " '23',\n",
              " '50',\n",
              " 'ask',\n",
              " 'old',\n",
              " 'management',\n",
              " 'must',\n",
              " 'foreign',\n",
              " 'use',\n",
              " 'share',\n",
              " 'pay',\n",
              " 'application',\n",
              " 'london',\n",
              " 'purchase',\n",
              " 'society',\n",
              " 'theme',\n",
              " 'cannot',\n",
              " 'problem',\n",
              " 'unsubscribe',\n",
              " 'required',\n",
              " 'speaker',\n",
              " 'presentation',\n",
              " 'version',\n",
              " 'asset',\n",
              " 'using',\n",
              " 'easy',\n",
              " 'movement',\n",
              " '2000',\n",
              " 'yet',\n",
              " 'school',\n",
              " 'woman',\n",
              " 'effect',\n",
              " 'security',\n",
              " 'first',\n",
              " 'man',\n",
              " 'claim',\n",
              " 'project',\n",
              " 'click',\n",
              " 'welcome',\n",
              " 'option',\n",
              " 'theoretical',\n",
              " 'open',\n",
              " 'able',\n",
              " 'law',\n",
              " 'got',\n",
              " 'x',\n",
              " 'state',\n",
              " 'http',\n",
              " 'trading',\n",
              " 'company',\n",
              " 'important',\n",
              " 'font',\n",
              " '01',\n",
              " 'ever',\n",
              " 'early',\n",
              " 'break',\n",
              " 'call',\n",
              " 'detail',\n",
              " 'size',\n",
              " 'phone',\n",
              " 'title',\n",
              " 'week',\n",
              " 'college',\n",
              " 'linux',\n",
              " 'etc',\n",
              " 'believe',\n",
              " 'work',\n",
              " 'hou',\n",
              " 'k',\n",
              " 'approach',\n",
              " 'soon',\n",
              " 'march',\n",
              " 'interested',\n",
              " 'com',\n",
              " 'germany',\n",
              " 'income',\n",
              " 'whole',\n",
              " 'action',\n",
              " 'acquisition',\n",
              " 'mean',\n",
              " '100',\n",
              " 'please',\n",
              " 'meeting',\n",
              " 'feel',\n",
              " 'energy',\n",
              " 'yahoo',\n",
              " 'process',\n",
              " 'called',\n",
              " '½ï',\n",
              " 'science',\n",
              " '49',\n",
              " '26',\n",
              " 'november',\n",
              " 'cd',\n",
              " 'b',\n",
              " 'spamassassin',\n",
              " 'et',\n",
              " 'razor',\n",
              " '20',\n",
              " 'two',\n",
              " 'remove',\n",
              " 'least',\n",
              " 'performance',\n",
              " 'user',\n",
              " 'â',\n",
              " 'south',\n",
              " 'japan',\n",
              " 'post',\n",
              " 'writing',\n",
              " 'medium',\n",
              " 'sure',\n",
              " '5',\n",
              " 'end',\n",
              " 'context',\n",
              " 'spam',\n",
              " 'well',\n",
              " 'second',\n",
              " 'mr',\n",
              " 'board',\n",
              " 'regard',\n",
              " 'data',\n",
              " 'response',\n",
              " 'mailman',\n",
              " 'card',\n",
              " 'given',\n",
              " 'rpm',\n",
              " 'every',\n",
              " 'going',\n",
              " 'add',\n",
              " '09',\n",
              " 'la',\n",
              " 'j',\n",
              " '1998',\n",
              " 'message',\n",
              " '30',\n",
              " 'head',\n",
              " 'commercial',\n",
              " 'better',\n",
              " 'let',\n",
              " 'others',\n",
              " 'one',\n",
              " 'july',\n",
              " 'due',\n",
              " 'actually',\n",
              " 'ago',\n",
              " 'comment',\n",
              " 'become',\n",
              " 'pre',\n",
              " 'item',\n",
              " 'send',\n",
              " 'making',\n",
              " 'done',\n",
              " 'transaction',\n",
              " 'support',\n",
              " '6',\n",
              " 'less',\n",
              " 'inc',\n",
              " 'un',\n",
              " 'another',\n",
              " 'return',\n",
              " 'receive',\n",
              " 'th',\n",
              " 'little',\n",
              " 'network',\n",
              " 'money',\n",
              " 'basis',\n",
              " 'group',\n",
              " '40',\n",
              " 'subscription',\n",
              " 'release',\n",
              " 'usa',\n",
              " 'answer',\n",
              " 'charge',\n",
              " 'certain',\n",
              " 'name',\n",
              " 'hundred',\n",
              " 'per',\n",
              " 'bulk',\n",
              " 'format',\n",
              " 'phonology',\n",
              " 'place',\n",
              " 'linguistics',\n",
              " 'processing',\n",
              " 'talk',\n",
              " 'fee',\n",
              " 'sourceforge',\n",
              " 'deal',\n",
              " 'million',\n",
              " 'low',\n",
              " 'n']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = list(features)\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8357HG1Q3itk",
        "outputId": "188a7383-4bdb-49e5-9f40-ef14e28b6258"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'access': 0,\n",
              " 'error': 1,\n",
              " 'type': 2,\n",
              " 'hour': 3,\n",
              " 'real': 4,\n",
              " 'listinfo': 5,\n",
              " 'topic': 6,\n",
              " 'institute': 7,\n",
              " 'researcher': 8,\n",
              " 'statement': 9,\n",
              " 'system': 10,\n",
              " 'series': 11,\n",
              " 'native': 12,\n",
              " '05': 13,\n",
              " 'day': 14,\n",
              " 'editor': 15,\n",
              " 'www': 16,\n",
              " 'role': 17,\n",
              " 'power': 18,\n",
              " 'grant': 19,\n",
              " 'c': 20,\n",
              " 'enron': 21,\n",
              " 'publication': 22,\n",
              " 'idea': 23,\n",
              " 'show': 24,\n",
              " 'stop': 25,\n",
              " 'microsoft': 26,\n",
              " 'america': 27,\n",
              " 'january': 28,\n",
              " 'multi': 29,\n",
              " 'experience': 30,\n",
              " 'buy': 31,\n",
              " 'semantic': 32,\n",
              " 'also': 33,\n",
              " 'center': 34,\n",
              " '11': 35,\n",
              " 'various': 36,\n",
              " 'analyst': 37,\n",
              " '2001': 38,\n",
              " 'education': 39,\n",
              " 'come': 40,\n",
              " 'left': 41,\n",
              " 'thing': 42,\n",
              " 'write': 43,\n",
              " 'particular': 44,\n",
              " 'billion': 45,\n",
              " 'step': 46,\n",
              " 'market': 47,\n",
              " 'additional': 48,\n",
              " 'v': 49,\n",
              " 'without': 50,\n",
              " 'event': 51,\n",
              " 'current': 52,\n",
              " 'subject': 53,\n",
              " 'st': 54,\n",
              " 'general': 55,\n",
              " 'best': 56,\n",
              " 'houston': 57,\n",
              " 'fund': 58,\n",
              " 'u': 59,\n",
              " 'september': 60,\n",
              " 'session': 61,\n",
              " 'never': 62,\n",
              " 'bill': 63,\n",
              " 'check': 64,\n",
              " 'much': 65,\n",
              " 'schedule': 66,\n",
              " 'discourse': 67,\n",
              " 'ã': 68,\n",
              " 'quality': 69,\n",
              " 'ad': 70,\n",
              " 'child': 71,\n",
              " 'potential': 72,\n",
              " 'public': 73,\n",
              " 'getting': 74,\n",
              " 'box': 75,\n",
              " 'value': 76,\n",
              " 'ie': 77,\n",
              " 'investment': 78,\n",
              " 'spanish': 79,\n",
              " 'last': 80,\n",
              " 'thought': 81,\n",
              " 'industry': 82,\n",
              " 'ï': 83,\n",
              " 'room': 84,\n",
              " 'international': 85,\n",
              " 'already': 86,\n",
              " 'model': 87,\n",
              " '3d': 88,\n",
              " 'thanks': 89,\n",
              " 'attached': 90,\n",
              " 'mind': 91,\n",
              " 'h': 92,\n",
              " 'proposal': 93,\n",
              " 'author': 94,\n",
              " 'operation': 95,\n",
              " 'historical': 96,\n",
              " 'view': 97,\n",
              " '10': 98,\n",
              " 'clear': 99,\n",
              " '500': 100,\n",
              " 'immediately': 101,\n",
              " 'lot': 102,\n",
              " 'global': 103,\n",
              " 'seems': 104,\n",
              " 'right': 105,\n",
              " 'february': 106,\n",
              " 'trade': 107,\n",
              " 'difference': 108,\n",
              " 'home': 109,\n",
              " 'thank': 110,\n",
              " 'around': 111,\n",
              " 'standard': 112,\n",
              " '2': 113,\n",
              " 'f': 114,\n",
              " 'united': 115,\n",
              " 'syntactic': 116,\n",
              " 'fax': 117,\n",
              " 'four': 118,\n",
              " '60': 119,\n",
              " 'full': 120,\n",
              " 'ilug': 121,\n",
              " 'knowledge': 122,\n",
              " 'length': 123,\n",
              " 'forward': 124,\n",
              " 'time': 125,\n",
              " 'analysis': 126,\n",
              " 'video': 127,\n",
              " 'opportunity': 128,\n",
              " 'california': 129,\n",
              " 'search': 130,\n",
              " 'level': 131,\n",
              " 'style': 132,\n",
              " 'start': 133,\n",
              " 'description': 134,\n",
              " 'include': 135,\n",
              " 'investor': 136,\n",
              " 'high': 137,\n",
              " 'theory': 138,\n",
              " 'national': 139,\n",
              " 'info': 140,\n",
              " 'machine': 141,\n",
              " '1994': 142,\n",
              " 'simply': 143,\n",
              " 'member': 144,\n",
              " 'simple': 145,\n",
              " 'texas': 146,\n",
              " 'run': 147,\n",
              " 'registration': 148,\n",
              " 'thursday': 149,\n",
              " 'still': 150,\n",
              " 'discussion': 151,\n",
              " 'workshop': 152,\n",
              " 'kaminski': 153,\n",
              " 'deadline': 154,\n",
              " '19': 155,\n",
              " 'relation': 156,\n",
              " 'line': 157,\n",
              " '03': 158,\n",
              " 'tuesday': 159,\n",
              " 'chinese': 160,\n",
              " 'something': 161,\n",
              " 'france': 162,\n",
              " 'category': 163,\n",
              " 'within': 164,\n",
              " 'ready': 165,\n",
              " 'great': 166,\n",
              " 'field': 167,\n",
              " 'via': 168,\n",
              " 'hard': 169,\n",
              " 'method': 170,\n",
              " 'order': 171,\n",
              " 'student': 172,\n",
              " 'people': 173,\n",
              " 'evaluation': 174,\n",
              " 'kind': 175,\n",
              " 'review': 176,\n",
              " 'ha': 177,\n",
              " 'department': 178,\n",
              " 'word': 179,\n",
              " 'natural': 180,\n",
              " 'recent': 181,\n",
              " 'participant': 182,\n",
              " 'government': 183,\n",
              " '99': 184,\n",
              " 'far': 185,\n",
              " 'remember': 186,\n",
              " 'learn': 187,\n",
              " 'move': 188,\n",
              " 'present': 189,\n",
              " 'following': 190,\n",
              " 'long': 191,\n",
              " 'give': 192,\n",
              " 'office': 193,\n",
              " 'received': 194,\n",
              " 'window': 195,\n",
              " 'le': 196,\n",
              " '200': 197,\n",
              " 'team': 198,\n",
              " 'logic': 199,\n",
              " '29': 200,\n",
              " 'university': 201,\n",
              " 'think': 202,\n",
              " 'site': 203,\n",
              " 'individual': 204,\n",
              " 'ect': 205,\n",
              " 'content': 206,\n",
              " 'direct': 207,\n",
              " 'common': 208,\n",
              " 'five': 209,\n",
              " 'published': 210,\n",
              " 'stock': 211,\n",
              " '2002': 212,\n",
              " 'development': 213,\n",
              " 'cc': 214,\n",
              " 'service': 215,\n",
              " 'morphology': 216,\n",
              " 'back': 217,\n",
              " 'object': 218,\n",
              " 'family': 219,\n",
              " 'computational': 220,\n",
              " 'part': 221,\n",
              " '24': 222,\n",
              " 'someone': 223,\n",
              " 'class': 224,\n",
              " 'committee': 225,\n",
              " 'telephone': 226,\n",
              " 'among': 227,\n",
              " 'though': 228,\n",
              " 'query': 229,\n",
              " 'party': 230,\n",
              " 'tutorial': 231,\n",
              " 'human': 232,\n",
              " 'story': 233,\n",
              " 'said': 234,\n",
              " 'go': 235,\n",
              " 'history': 236,\n",
              " '15': 237,\n",
              " 'program': 238,\n",
              " 'customer': 239,\n",
              " 'link': 240,\n",
              " 'en': 241,\n",
              " 'lexical': 242,\n",
              " 'later': 243,\n",
              " '21': 244,\n",
              " '1999': 245,\n",
              " 'lunch': 246,\n",
              " 'top': 247,\n",
              " 'language': 248,\n",
              " 'wide': 249,\n",
              " 'volume': 250,\n",
              " 'life': 251,\n",
              " 'third': 252,\n",
              " '3': 253,\n",
              " '44': 254,\n",
              " 'away': 255,\n",
              " 'credit': 256,\n",
              " 'linguistic': 257,\n",
              " 'wish': 258,\n",
              " 'original': 259,\n",
              " 'study': 260,\n",
              " 'summary': 261,\n",
              " 'currently': 262,\n",
              " 'president': 263,\n",
              " 'matter': 264,\n",
              " 'made': 265,\n",
              " 'even': 266,\n",
              " 'mail': 267,\n",
              " 'co': 268,\n",
              " 'european': 269,\n",
              " '25': 270,\n",
              " 'date': 271,\n",
              " 'new': 272,\n",
              " 'dr': 273,\n",
              " 'product': 274,\n",
              " 'online': 275,\n",
              " 'syntax': 276,\n",
              " '_': 277,\n",
              " 'contract': 278,\n",
              " 'enough': 279,\n",
              " 'electronic': 280,\n",
              " 'street': 281,\n",
              " 'plan': 282,\n",
              " 'index': 283,\n",
              " 'else': 284,\n",
              " 'plus': 285,\n",
              " 'risk': 286,\n",
              " 'wa': 287,\n",
              " 'rate': 288,\n",
              " 'help': 289,\n",
              " 'continue': 290,\n",
              " 'cognitive': 291,\n",
              " 'pp': 292,\n",
              " 'dollar': 293,\n",
              " 'put': 294,\n",
              " '07': 295,\n",
              " 'number': 296,\n",
              " 'quite': 297,\n",
              " 'reason': 298,\n",
              " 'translation': 299,\n",
              " 'everyone': 300,\n",
              " 'interest': 301,\n",
              " 'argument': 302,\n",
              " 'technology': 303,\n",
              " '4': 304,\n",
              " 'way': 305,\n",
              " 'code': 306,\n",
              " 'canada': 307,\n",
              " 'large': 308,\n",
              " 'keep': 309,\n",
              " '9': 310,\n",
              " '7': 311,\n",
              " 'anyone': 312,\n",
              " 'small': 313,\n",
              " 'october': 314,\n",
              " 'submit': 315,\n",
              " 'example': 316,\n",
              " 'communication': 317,\n",
              " 'key': 318,\n",
              " 'mailing': 319,\n",
              " 'august': 320,\n",
              " 'since': 321,\n",
              " 'past': 322,\n",
              " '22': 323,\n",
              " 'grammar': 324,\n",
              " 'information': 325,\n",
              " 'url': 326,\n",
              " 'looking': 327,\n",
              " 'software': 328,\n",
              " 'applied': 329,\n",
              " 'mark': 330,\n",
              " 'set': 331,\n",
              " 'reply': 332,\n",
              " 'uk': 333,\n",
              " 'reading': 334,\n",
              " 'hope': 335,\n",
              " 'address': 336,\n",
              " 'york': 337,\n",
              " 'always': 338,\n",
              " 'agreement': 339,\n",
              " 'try': 340,\n",
              " 'id': 341,\n",
              " 'speech': 342,\n",
              " 'aspect': 343,\n",
              " 'world': 344,\n",
              " 'letter': 345,\n",
              " 'sell': 346,\n",
              " 'edu': 347,\n",
              " 'sound': 348,\n",
              " 'record': 349,\n",
              " 'offer': 350,\n",
              " 'sent': 351,\n",
              " 'probably': 352,\n",
              " 'copy': 353,\n",
              " 'get': 354,\n",
              " 'used': 355,\n",
              " 'capital': 356,\n",
              " 'feature': 357,\n",
              " 'database': 358,\n",
              " 'thousand': 359,\n",
              " 'japanese': 360,\n",
              " 'including': 361,\n",
              " 'possible': 362,\n",
              " 'organization': 363,\n",
              " 'production': 364,\n",
              " 'de': 365,\n",
              " 'like': 366,\n",
              " 'proceeding': 367,\n",
              " 'save': 368,\n",
              " 'either': 369,\n",
              " 'director': 370,\n",
              " 'city': 371,\n",
              " 'working': 372,\n",
              " 'main': 373,\n",
              " 'personal': 374,\n",
              " 'invited': 375,\n",
              " 'linguist': 376,\n",
              " 'next': 377,\n",
              " '1997': 378,\n",
              " '00': 379,\n",
              " 'make': 380,\n",
              " '97': 381,\n",
              " 'report': 382,\n",
              " 'related': 383,\n",
              " 'position': 384,\n",
              " 'note': 385,\n",
              " 'area': 386,\n",
              " 'directory': 387,\n",
              " 'professional': 388,\n",
              " 'org': 389,\n",
              " 'anything': 390,\n",
              " 'l': 391,\n",
              " 'update': 392,\n",
              " '31': 393,\n",
              " 'copyright': 394,\n",
              " 'internet': 395,\n",
              " 'teaching': 396,\n",
              " '95': 397,\n",
              " 'package': 398,\n",
              " 'email': 399,\n",
              " 'read': 400,\n",
              " 'michael': 401,\n",
              " 'today': 402,\n",
              " '35': 403,\n",
              " '12': 404,\n",
              " 'major': 405,\n",
              " 'issue': 406,\n",
              " 'cash': 407,\n",
              " 'friday': 408,\n",
              " 'file': 409,\n",
              " 'computer': 410,\n",
              " 'server': 411,\n",
              " 'dear': 412,\n",
              " 'different': 413,\n",
              " 'sale': 414,\n",
              " 'whether': 415,\n",
              " 'complete': 416,\n",
              " 'french': 417,\n",
              " 'e': 418,\n",
              " 'might': 419,\n",
              " 'country': 420,\n",
              " 'provide': 421,\n",
              " 'american': 422,\n",
              " 'benjamin': 423,\n",
              " 'chair': 424,\n",
              " 'robert': 425,\n",
              " 'based': 426,\n",
              " 'europe': 427,\n",
              " 'effort': 428,\n",
              " 'month': 429,\n",
              " 'programme': 430,\n",
              " 'act': 431,\n",
              " 'john': 432,\n",
              " 'marketing': 433,\n",
              " 'list': 434,\n",
              " 'take': 435,\n",
              " 'big': 436,\n",
              " 'good': 437,\n",
              " '000': 438,\n",
              " 'live': 439,\n",
              " 'wednesday': 440,\n",
              " '98': 441,\n",
              " 'news': 442,\n",
              " 'account': 443,\n",
              " 'person': 444,\n",
              " 'want': 445,\n",
              " 'corp': 446,\n",
              " 'monday': 447,\n",
              " 'material': 448,\n",
              " 'follow': 449,\n",
              " 'p': 450,\n",
              " '08': 451,\n",
              " 'semantics': 452,\n",
              " 'vowel': 453,\n",
              " 'together': 454,\n",
              " 'friend': 455,\n",
              " 'bank': 456,\n",
              " 'source': 457,\n",
              " 'written': 458,\n",
              " 'specific': 459,\n",
              " 'focus': 460,\n",
              " 'section': 461,\n",
              " 'question': 462,\n",
              " 'really': 463,\n",
              " 'research': 464,\n",
              " 'however': 465,\n",
              " 'sign': 466,\n",
              " 'rather': 467,\n",
              " 'cost': 468,\n",
              " 'december': 469,\n",
              " '14': 470,\n",
              " 'paid': 471,\n",
              " 'page': 472,\n",
              " 'visit': 473,\n",
              " 'north': 474,\n",
              " '16': 475,\n",
              " '1995': 476,\n",
              " 'term': 477,\n",
              " 'point': 478,\n",
              " 'article': 479,\n",
              " 'domain': 480,\n",
              " 'found': 481,\n",
              " 'wrote': 482,\n",
              " 'latest': 483,\n",
              " 'asked': 484,\n",
              " 'construction': 485,\n",
              " 'control': 486,\n",
              " 'r': 487,\n",
              " 'business': 488,\n",
              " 'html': 489,\n",
              " 'case': 490,\n",
              " 'journal': 491,\n",
              " 'free': 492,\n",
              " '18': 493,\n",
              " 'tel': 494,\n",
              " 'held': 495,\n",
              " '13': 496,\n",
              " 'price': 497,\n",
              " 'final': 498,\n",
              " 'reference': 499,\n",
              " 'gas': 500,\n",
              " '28': 501,\n",
              " 'press': 502,\n",
              " 'non': 503,\n",
              " 'announcement': 504,\n",
              " '1': 505,\n",
              " 'success': 506,\n",
              " 'ca': 507,\n",
              " 'dynegy': 508,\n",
              " 'hotel': 509,\n",
              " 'april': 510,\n",
              " 'dialect': 511,\n",
              " 'document': 512,\n",
              " '0': 513,\n",
              " 'minute': 514,\n",
              " 'available': 515,\n",
              " '90': 516,\n",
              " 'website': 517,\n",
              " 'single': 518,\n",
              " 'nothing': 519,\n",
              " 'year': 520,\n",
              " 'association': 521,\n",
              " 'submission': 522,\n",
              " 'representation': 523,\n",
              " '27': 524,\n",
              " 'doe': 525,\n",
              " 'could': 526,\n",
              " 'change': 527,\n",
              " 'exchange': 528,\n",
              " 'contact': 529,\n",
              " 'several': 530,\n",
              " 'english': 531,\n",
              " '04': 532,\n",
              " 'book': 533,\n",
              " 'amount': 534,\n",
              " 'ac': 535,\n",
              " 'may': 536,\n",
              " 'verb': 537,\n",
              " 'request': 538,\n",
              " 'includes': 539,\n",
              " 'increase': 540,\n",
              " 'paper': 541,\n",
              " 'web': 542,\n",
              " 'summer': 543,\n",
              " 'vince': 544,\n",
              " 'meaning': 545,\n",
              " 'resource': 546,\n",
              " 'although': 547,\n",
              " 'hand': 548,\n",
              " 'especially': 549,\n",
              " 'short': 550,\n",
              " 'pm': 551,\n",
              " 'many': 552,\n",
              " 'special': 553,\n",
              " 'would': 554,\n",
              " 'see': 555,\n",
              " 'job': 556,\n",
              " '02': 557,\n",
              " 'total': 558,\n",
              " 'yes': 559,\n",
              " 'course': 560,\n",
              " 'sentence': 561,\n",
              " 'financial': 562,\n",
              " 'unit': 563,\n",
              " 'tool': 564,\n",
              " 'legal': 565,\n",
              " 'rule': 566,\n",
              " 'payment': 567,\n",
              " '17': 568,\n",
              " 'jones': 569,\n",
              " 'future': 570,\n",
              " 'corpus': 571,\n",
              " 'june': 572,\n",
              " 'structure': 573,\n",
              " 'color': 574,\n",
              " 'fact': 575,\n",
              " 'look': 576,\n",
              " '8': 577,\n",
              " 'ed': 578,\n",
              " 'text': 579,\n",
              " 'community': 580,\n",
              " 'conference': 581,\n",
              " '45': 582,\n",
              " 'find': 583,\n",
              " 'learning': 584,\n",
              " 'loss': 585,\n",
              " 'instruction': 586,\n",
              " 'spoken': 587,\n",
              " 'paul': 588,\n",
              " 'g': 589,\n",
              " 'cover': 590,\n",
              " 'net': 591,\n",
              " 'nl': 592,\n",
              " 'tell': 593,\n",
              " 'w': 594,\n",
              " 'result': 595,\n",
              " 'social': 596,\n",
              " 'need': 597,\n",
              " 'three': 598,\n",
              " 'limited': 599,\n",
              " 'included': 600,\n",
              " 'german': 601,\n",
              " 'form': 602,\n",
              " 'forwarded': 603,\n",
              " 'removed': 604,\n",
              " 'accepted': 605,\n",
              " 'provided': 606,\n",
              " 'say': 607,\n",
              " 'abstract': 608,\n",
              " 'know': 609,\n",
              " 'david': 610,\n",
              " 'local': 611,\n",
              " 'debt': 612,\n",
              " '23': 613,\n",
              " '50': 614,\n",
              " 'ask': 615,\n",
              " 'old': 616,\n",
              " 'management': 617,\n",
              " 'must': 618,\n",
              " 'foreign': 619,\n",
              " 'use': 620,\n",
              " 'share': 621,\n",
              " 'pay': 622,\n",
              " 'application': 623,\n",
              " 'london': 624,\n",
              " 'purchase': 625,\n",
              " 'society': 626,\n",
              " 'theme': 627,\n",
              " 'cannot': 628,\n",
              " 'problem': 629,\n",
              " 'unsubscribe': 630,\n",
              " 'required': 631,\n",
              " 'speaker': 632,\n",
              " 'presentation': 633,\n",
              " 'version': 634,\n",
              " 'asset': 635,\n",
              " 'using': 636,\n",
              " 'easy': 637,\n",
              " 'movement': 638,\n",
              " '2000': 639,\n",
              " 'yet': 640,\n",
              " 'school': 641,\n",
              " 'woman': 642,\n",
              " 'effect': 643,\n",
              " 'security': 644,\n",
              " 'first': 645,\n",
              " 'man': 646,\n",
              " 'claim': 647,\n",
              " 'project': 648,\n",
              " 'click': 649,\n",
              " 'welcome': 650,\n",
              " 'option': 651,\n",
              " 'theoretical': 652,\n",
              " 'open': 653,\n",
              " 'able': 654,\n",
              " 'law': 655,\n",
              " 'got': 656,\n",
              " 'x': 657,\n",
              " 'state': 658,\n",
              " 'http': 659,\n",
              " 'trading': 660,\n",
              " 'company': 661,\n",
              " 'important': 662,\n",
              " 'font': 663,\n",
              " '01': 664,\n",
              " 'ever': 665,\n",
              " 'early': 666,\n",
              " 'break': 667,\n",
              " 'call': 668,\n",
              " 'detail': 669,\n",
              " 'size': 670,\n",
              " 'phone': 671,\n",
              " 'title': 672,\n",
              " 'week': 673,\n",
              " 'college': 674,\n",
              " 'linux': 675,\n",
              " 'etc': 676,\n",
              " 'believe': 677,\n",
              " 'work': 678,\n",
              " 'hou': 679,\n",
              " 'k': 680,\n",
              " 'approach': 681,\n",
              " 'soon': 682,\n",
              " 'march': 683,\n",
              " 'interested': 684,\n",
              " 'com': 685,\n",
              " 'germany': 686,\n",
              " 'income': 687,\n",
              " 'whole': 688,\n",
              " 'action': 689,\n",
              " 'acquisition': 690,\n",
              " 'mean': 691,\n",
              " '100': 692,\n",
              " 'please': 693,\n",
              " 'meeting': 694,\n",
              " 'feel': 695,\n",
              " 'energy': 696,\n",
              " 'yahoo': 697,\n",
              " 'process': 698,\n",
              " 'called': 699,\n",
              " '½ï': 700,\n",
              " 'science': 701,\n",
              " '49': 702,\n",
              " '26': 703,\n",
              " 'november': 704,\n",
              " 'cd': 705,\n",
              " 'b': 706,\n",
              " 'spamassassin': 707,\n",
              " 'et': 708,\n",
              " 'razor': 709,\n",
              " '20': 710,\n",
              " 'two': 711,\n",
              " 'remove': 712,\n",
              " 'least': 713,\n",
              " 'performance': 714,\n",
              " 'user': 715,\n",
              " 'â': 716,\n",
              " 'south': 717,\n",
              " 'japan': 718,\n",
              " 'post': 719,\n",
              " 'writing': 720,\n",
              " 'medium': 721,\n",
              " 'sure': 722,\n",
              " '5': 723,\n",
              " 'end': 724,\n",
              " 'context': 725,\n",
              " 'spam': 726,\n",
              " 'well': 727,\n",
              " 'second': 728,\n",
              " 'mr': 729,\n",
              " 'board': 730,\n",
              " 'regard': 731,\n",
              " 'data': 732,\n",
              " 'response': 733,\n",
              " 'mailman': 734,\n",
              " 'card': 735,\n",
              " 'given': 736,\n",
              " 'rpm': 737,\n",
              " 'every': 738,\n",
              " 'going': 739,\n",
              " 'add': 740,\n",
              " '09': 741,\n",
              " 'la': 742,\n",
              " 'j': 743,\n",
              " '1998': 744,\n",
              " 'message': 745,\n",
              " '30': 746,\n",
              " 'head': 747,\n",
              " 'commercial': 748,\n",
              " 'better': 749,\n",
              " 'let': 750,\n",
              " 'others': 751,\n",
              " 'one': 752,\n",
              " 'july': 753,\n",
              " 'due': 754,\n",
              " 'actually': 755,\n",
              " 'ago': 756,\n",
              " 'comment': 757,\n",
              " 'become': 758,\n",
              " 'pre': 759,\n",
              " 'item': 760,\n",
              " 'send': 761,\n",
              " 'making': 762,\n",
              " 'done': 763,\n",
              " 'transaction': 764,\n",
              " 'support': 765,\n",
              " '6': 766,\n",
              " 'less': 767,\n",
              " 'inc': 768,\n",
              " 'un': 769,\n",
              " 'another': 770,\n",
              " 'return': 771,\n",
              " 'receive': 772,\n",
              " 'th': 773,\n",
              " 'little': 774,\n",
              " 'network': 775,\n",
              " 'money': 776,\n",
              " 'basis': 777,\n",
              " 'group': 778,\n",
              " '40': 779,\n",
              " 'subscription': 780,\n",
              " 'release': 781,\n",
              " 'usa': 782,\n",
              " 'answer': 783,\n",
              " 'charge': 784,\n",
              " 'certain': 785,\n",
              " 'name': 786,\n",
              " 'hundred': 787,\n",
              " 'per': 788,\n",
              " 'bulk': 789,\n",
              " 'format': 790,\n",
              " 'phonology': 791,\n",
              " 'place': 792,\n",
              " 'linguistics': 793,\n",
              " 'processing': 794,\n",
              " 'talk': 795,\n",
              " 'fee': 796,\n",
              " 'sourceforge': 797,\n",
              " 'deal': 798,\n",
              " 'million': 799,\n",
              " 'low': 800,\n",
              " 'n': 801}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_to_index_mapping = {t:i for t, i in zip(features, range(len(features)))}\n",
        "token_to_index_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE6xAzIN7DY5",
        "outputId": "d8ec86ba-ea77-4e9b-b0c0-53781febc50f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['3d', 'b', 'br', 'com', 'bad', 'font', 'font', 'com', 'randoms']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message_to_token_list('3d b <br> .com bad font font com randoms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OuXO-Cjf4vNo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# \"Bag of Words\" (counts vector)\n",
        "\n",
        "# ->  http  tr  size  3d  font  br  com  td   p   b\n",
        "# ->    0    1    2    3   4    5    6    7   8   9\n",
        "# ->   [0,   0,   0,   1,  2,   1,   2,   0,  0,  1]\n",
        "\n",
        "[0.,  0.,  0.,   1., 2.,  1., 2.,  0., 0., 1.]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ3kBFPW7vpm",
        "outputId": "3280787f-4a7f-4ed2-8836-5d3152393809"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0.])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def message_to_count_vector(message):\n",
        "  count_vector = np.zeros(len(features))\n",
        "\n",
        "  processed_list_of_tokens = message_to_token_list(message)\n",
        "\n",
        "  for token in processed_list_of_tokens:\n",
        "    if token not in features:\n",
        "      continue\n",
        "    index = token_to_index_mapping[token]\n",
        "    count_vector[index] += 1\n",
        "\n",
        "  return count_vector\n",
        "\n",
        "message_to_count_vector('3d b <br> .com bad font font com randoms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvnPzPqN_kWU",
        "outputId": "2af5915b-12dd-4b9f-b40f-0eacbc4ef2ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0.])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message_to_count_vector(train_df['MESSAGE'].iloc[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We7My4so_y4P",
        "outputId": "ecdfd9ac-38a6-40be-c22e-baf528a44839"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SERIAL                                                  15029\n",
              "MESSAGE     reimbursement of individually billed items the...\n",
              "CATEGORY                                                    0\n",
              "Name: 3, dtype: object"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.iloc[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "w3V5tgVbB_9K"
      },
      "outputs": [],
      "source": [
        "def df_to_X_y(dff):\n",
        "  y = dff['CATEGORY'].to_numpy().astype(int)\n",
        "\n",
        "  message_col = dff['MESSAGE']\n",
        "  count_vectors = []\n",
        "\n",
        "  for message in message_col:\n",
        "    count_vector = message_to_count_vector(message)\n",
        "    count_vectors.append(count_vector)\n",
        "\n",
        "  X = np.array(count_vectors).astype(int)\n",
        "\n",
        "  return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1AB_Ehd_18I",
        "outputId": "ac1da35b-3721-441f-a386-efd12e084422"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((14907, 802), (14907,), (3727, 802), (3727,))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, y_train = df_to_X_y(train_df)\n",
        "\n",
        "X_test, y_test = df_to_X_y(test_df)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "243hURJZC7pt",
        "outputId": "843808cf-2f87-43bc-8d18-f41d8f6abc6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.00184502, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "\n",
        "X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)\n",
        "\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fuadn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# **TF-IDF Feature Extraction**\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def custom_tokenizer(message):\n",
        "    return message_to_token_list(message)\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer)\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['MESSAGE'])\n",
        "\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_df['MESSAGE'])\n",
        "\n",
        "y_train_tfidf = train_df['CATEGORY'].to_numpy().astype(int)\n",
        "y_test_tfidf = test_df['CATEGORY'].to_numpy().astype(int)\n",
        "\n",
        "\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "X_train_tfidf_dense = X_train_tfidf.toarray()\n",
        "\n",
        "# View the dense matrix (first 5 rows, for example)\n",
        "print(X_train_tfidf_dense[:1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word Vector Feature Matrix Shapes:\n",
            "Training Set: (14907, 100)\n",
            "Test Set: (3727, 100)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Prepare tokenized sentences from the training data\n",
        "train_sentences = [message_to_token_list(msg) for msg in train_df['MESSAGE'] if isinstance(msg, str)]\n",
        "test_sentences = [message_to_token_list(msg) for msg in test_df['MESSAGE'] if isinstance(msg, str)]\n",
        "\n",
        "# Train a Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4, seed=1)\n",
        "\n",
        "# Function to convert a message to a Word2Vec vector (averaged over all tokens)\n",
        "def message_to_wv_vector(message, model, vector_size):\n",
        "    tokens = message_to_token_list(message)\n",
        "    vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
        "    if len(vectors) == 0:  # If no tokens are found in the model, return a zero vector\n",
        "        return np.zeros(vector_size)\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "# Extract Word2Vec features for training and test sets\n",
        "vector_size = word2vec_model.vector_size\n",
        "wv_X_train = np.array([message_to_wv_vector(msg, word2vec_model, vector_size) for msg in train_df['MESSAGE']])\n",
        "wv_X_test = np.array([message_to_wv_vector(msg, word2vec_model, vector_size) for msg in test_df['MESSAGE']])\n",
        "\n",
        "# Labels remain the same\n",
        "wv_y_train = train_df['CATEGORY'].to_numpy().astype(int)\n",
        "wv_y_test = test_df['CATEGORY'].to_numpy().astype(int)\n",
        "\n",
        "# Verify the shape of the feature matrices\n",
        "print(\"Word Vector Feature Matrix Shapes:\")\n",
        "print(\"Training Set:\", wv_X_train.shape)\n",
        "print(\"Test Set:\", wv_X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hybrid Train Feature Shape: (14907, 144809)\n",
            "Hybrid Test Feature Shape: (3727, 144809)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Combine TF-IDF and Word Vectors into a hybrid feature\n",
        "hybrid_X_train = hstack([X_train_tfidf, wv_X_train])\n",
        "hybrid_X_test = hstack([X_test_tfidf, wv_X_test])\n",
        "\n",
        "# Ensure the data is in dense format if needed for certain classifiers\n",
        "hybrid_X_train = hybrid_X_train.toarray()\n",
        "hybrid_X_test = hybrid_X_test.toarray()\n",
        "\n",
        "print(f\"Hybrid Train Feature Shape: {hybrid_X_train.shape}\")\n",
        "print(f\"Hybrid Test Feature Shape: {hybrid_X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptZ2wUTxD1MF",
        "outputId": "b960271b-8777-4950-f2ec-0e6109446812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6209    0.9956    0.7648      2265\n",
            "           1     0.8947    0.0581    0.1092      1462\n",
            "\n",
            "    accuracy                         0.6279      3727\n",
            "   macro avg     0.7578    0.5269    0.4370      3727\n",
            "weighted avg     0.7283    0.6279    0.5076      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression using Bag of Words Feature Extraction\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "lr = LogisticRegression().fit(X_train, y_train)\n",
        "print(classification_report(y_test, lr.predict(X_test), digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZK0jMUSEOCi",
        "outputId": "578ad022-7481-43d7-a74e-a38a3afc89cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9712    0.9536    0.9624      2265\n",
            "           1     0.9301    0.9562    0.9430      1462\n",
            "\n",
            "    accuracy                         0.9547      3727\n",
            "   macro avg     0.9507    0.9549    0.9527      3727\n",
            "weighted avg     0.9551    0.9547    0.9548      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Compare logistic regression to random forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "rf = RandomForestClassifier().fit(X_train, y_train)\n",
        "print(classification_report(y_test, rf.predict(X_test), digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fuadn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:45:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9820    0.9417    0.9615      2265\n",
            "           1     0.9151    0.9733    0.9433      1462\n",
            "\n",
            "    accuracy                         0.9541      3727\n",
            "   macro avg     0.9486    0.9575    0.9524      3727\n",
            "weighted avg     0.9558    0.9541    0.9543      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "xgb_bow = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "xgb_bow.fit(X_train, y_train)\n",
        "\n",
        "xgb_predictions_bow = xgb_bow.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, xgb_predictions_bow, digits=4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### TF_IDF EXTRACTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "3vhIALXMEkb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9820    0.9651    0.9735      2265\n",
            "           1     0.9474    0.9726    0.9598      1462\n",
            "\n",
            "    accuracy                         0.9681      3727\n",
            "   macro avg     0.9647    0.9689    0.9667      3727\n",
            "weighted avg     0.9684    0.9681    0.9681      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# **Logistic Regression Training and Evaluation**\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train_tfidf, y_train_tfidf)\n",
        "\n",
        "lr_predictions = lr_model.predict(X_test_tfidf)\n",
        "\n",
        "print(classification_report(y_test_tfidf, lr_predictions, digits=4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9746    0.9651    0.9698      2265\n",
            "           1     0.9468    0.9610    0.9538      1462\n",
            "\n",
            "    accuracy                         0.9635      3727\n",
            "   macro avg     0.9607    0.9631    0.9618      3727\n",
            "weighted avg     0.9637    0.9635    0.9636      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# **Random Forest Training and Evaluation**\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train_tfidf, y_train_tfidf)\n",
        "\n",
        "rf_predictions = rf_model.predict(X_test_tfidf)\n",
        "\n",
        "print(classification_report(y_test_tfidf, rf_predictions, digits=4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fuadn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:46:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9854    0.9519    0.9683      2265\n",
            "           1     0.9292    0.9781    0.9530      1462\n",
            "\n",
            "    accuracy                         0.9622      3727\n",
            "   macro avg     0.9573    0.9650    0.9607      3727\n",
            "weighted avg     0.9633    0.9622    0.9623      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import the XGBoost model\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "xgb_model.fit(X_train_tfidf, y_train_tfidf)\n",
        "\n",
        "xgb_predictions = xgb_model.predict(X_test_tfidf)\n",
        "\n",
        "print(classification_report(y_test_tfidf, xgb_predictions, digits=4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Word Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9588    0.9457    0.9522      2265\n",
            "           1     0.9176    0.9371    0.9272      1462\n",
            "\n",
            "    accuracy                         0.9423      3727\n",
            "   macro avg     0.9382    0.9414    0.9397      3727\n",
            "weighted avg     0.9427    0.9423    0.9424      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "wv_lr_model = LogisticRegression().fit(wv_X_train, wv_y_train)\n",
        "wv_predictions = wv_lr_model.predict(wv_X_test)\n",
        "\n",
        "print(classification_report(wv_y_test, wv_predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9710    0.9607    0.9658      2265\n",
            "           1     0.9401    0.9555    0.9478      1462\n",
            "\n",
            "    accuracy                         0.9587      3727\n",
            "   macro avg     0.9556    0.9581    0.9568      3727\n",
            "weighted avg     0.9589    0.9587    0.9587      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "rf_wv_model = RandomForestClassifier(random_state=1)\n",
        "rf_wv_model.fit(wv_X_train, wv_y_train)\n",
        "\n",
        "rf_wv_predictions = rf_wv_model.predict(wv_X_test)\n",
        "\n",
        "print(classification_report(wv_y_test, rf_wv_predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fuadn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:46:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9732    0.9611    0.9671      2265\n",
            "           1     0.9409    0.9590    0.9499      1462\n",
            "\n",
            "    accuracy                         0.9603      3727\n",
            "   macro avg     0.9571    0.9601    0.9585      3727\n",
            "weighted avg     0.9605    0.9603    0.9604      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "xgb_wv_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=1)\n",
        "xgb_wv_model.fit(wv_X_train, wv_y_train)\n",
        "\n",
        "xgb_wv_predictions = xgb_wv_model.predict(wv_X_test)\n",
        "\n",
        "print(classification_report(wv_y_test, xgb_wv_predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Hybrid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9717    0.9563    0.9640      2265\n",
            "           1     0.9339    0.9569    0.9453      1462\n",
            "\n",
            "    accuracy                         0.9565      3727\n",
            "   macro avg     0.9528    0.9566    0.9546      3727\n",
            "weighted avg     0.9569    0.9565    0.9566      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "lr_hybrid_model = LogisticRegression()\n",
        "lr_hybrid_model.fit(hybrid_X_train, y_train_tfidf)\n",
        "\n",
        "lr_hybrid_predictions = lr_hybrid_model.predict(hybrid_X_test)\n",
        "print(classification_report(y_test_tfidf, lr_hybrid_predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9724    0.9647    0.9685      2265\n",
            "           1     0.9459    0.9576    0.9517      1462\n",
            "\n",
            "    accuracy                         0.9619      3727\n",
            "   macro avg     0.9592    0.9611    0.9601      3727\n",
            "weighted avg     0.9620    0.9619    0.9619      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "rf_hybrid_model = RandomForestClassifier()\n",
        "rf_hybrid_model.fit(hybrid_X_train, y_train_tfidf)\n",
        "\n",
        "rf_hybrid_predictions = rf_hybrid_model.predict(hybrid_X_test)\n",
        "print(classification_report(y_test_tfidf, rf_hybrid_predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fuadn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:25:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Classification Report (Hybrid Features):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9829    0.9642    0.9735      2265\n",
            "           1     0.9462    0.9740    0.9599      1462\n",
            "\n",
            "    accuracy                         0.9681      3727\n",
            "   macro avg     0.9645    0.9691    0.9667      3727\n",
            "weighted avg     0.9685    0.9681    0.9681      3727\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "xgb_hybrid_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_hybrid_model.fit(hybrid_X_train, y_train_tfidf)\n",
        "\n",
        "xgb_hybrid_predictions = xgb_hybrid_model.predict(hybrid_X_test)\n",
        "print(\"XGBoost Classification Report (Hybrid Features):\\n\")\n",
        "print(classification_report(y_test_tfidf, xgb_hybrid_predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fuadn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 8.04 GiB for an array with shape (14907, 144809, 1) and data type float32",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[31], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Build and train CNN on hybrid data\u001b[39;00m\n\u001b[0;32m     31\u001b[0m cnn_hybrid_model \u001b[38;5;241m=\u001b[39m build_cnn_model(hybrid_X_train_cnn\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m---> 32\u001b[0m \u001b[43mcnn_hybrid_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhybrid_X_train_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhybrid_X_test_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_cnn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Evaluate CNN model\u001b[39;00m\n\u001b[0;32m     35\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m cnn_hybrid_model\u001b[38;5;241m.\u001b[39mevaluate(hybrid_X_test_cnn, y_test_cnn)\n",
            "File \u001b[1;32mc:\\Users\\fuadn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\fuadn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:96\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to an `EagerTensor`.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mNote that this function could return cached copies of created constants for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m  TypeError: if `dtype` is not compatible with the type of t.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     93\u001b[0m   \u001b[38;5;66;03m# Make a copy explicitly because the EagerTensor might share the underlying\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;66;03m# memory with the input array. Without this copy, users will be able to\u001b[39;00m\n\u001b[0;32m     95\u001b[0m   \u001b[38;5;66;03m# modify the EagerTensor after its creation by changing the input array.\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ops\u001b[38;5;241m.\u001b[39mEagerTensor):\n\u001b[0;32m     98\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.04 GiB for an array with shape (14907, 144809, 1) and data type float32"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert labels to categorical format\n",
        "num_classes = len(set(y_train_tfidf))  # Adjust based on the number of categories\n",
        "y_train_cnn = to_categorical(y_train_tfidf, num_classes)\n",
        "y_test_cnn = to_categorical(y_test_tfidf, num_classes)\n",
        "\n",
        "# Reshape hybrid dataset for CNN\n",
        "hybrid_X_train_cnn = hybrid_X_train.reshape(hybrid_X_train.shape[0], hybrid_X_train.shape[1], 1)\n",
        "hybrid_X_test_cnn = hybrid_X_test.reshape(hybrid_X_test.shape[0], hybrid_X_test.shape[1], 1)\n",
        "\n",
        "# Define CNN model\n",
        "def build_cnn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.5),\n",
        "        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Build and train CNN on hybrid data\n",
        "cnn_hybrid_model = build_cnn_model(hybrid_X_train_cnn.shape[1:])\n",
        "cnn_hybrid_model.fit(hybrid_X_train_cnn, y_train_cnn, epochs=10, batch_size=32, validation_data=(hybrid_X_test_cnn, y_test_cnn))\n",
        "\n",
        "# Evaluate CNN model\n",
        "loss, accuracy = cnn_hybrid_model.evaluate(hybrid_X_test_cnn, y_test_cnn)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
